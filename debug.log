2025-03-19 04:48:13,567 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 04:48:13,571 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 04:48:13,571 - process - INFO - Start time: 2025-03-19 04:48:13
2025-03-19 04:48:13,571 - process - ERROR - Error processing request: No module named 'anthropic'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 309, in process_llm_request
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-03-19 04:48:13,571 - process - INFO - End time: 2025-03-19 04:48:13
2025-03-19 04:48:13,571 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 04:48:13,571 - process - INFO - Start time: 2025-03-19 04:48:13
2025-03-19 04:48:13,571 - process - ERROR - Error processing request: No module named 'anthropic'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 309, in process_llm_request
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-03-19 04:48:13,572 - process - INFO - End time: 2025-03-19 04:48:13
2025-03-19 04:48:13,572 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:48:13,572 - process - INFO - Start time: 2025-03-19 04:48:13
2025-03-19 04:48:13,572 - process - ERROR - Error processing request: No module named 'anthropic'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 309, in process_llm_request
    import anthropic
ModuleNotFoundError: No module named 'anthropic'
2025-03-19 04:48:13,572 - process - INFO - End time: 2025-03-19 04:48:13
2025-03-19 04:48:58,232 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 04:48:58,236 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 04:48:58,236 - process - INFO - Start time: 2025-03-19 04:48:58
2025-03-19 04:48:58,236 - registry - DEBUG - Created MockRegistry
2025-03-19 04:48:58,236 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:48:58,273 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:48:58,273 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:48:58,273 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 04:48:58,275 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "What's the weather like in Paris today?"}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 04:48:58,294 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 04:48:58,295 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 04:48:58,345 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10558a900>
2025-03-19 04:48:58,345 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105542330> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 04:48:58,363 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10538efd0>
2025-03-19 04:48:58,363 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 04:48:58,363 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 04:48:58,363 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 04:48:58,363 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 04:48:58,363 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 04:48:59,740 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 20:48:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T20:48:58Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T20:48:58Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T20:48:59Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T20:48:58Z'), (b'request-id', b'req_016DuSStUEvPAoS1DqeVJ5tL'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227980d1e06fa4b-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 04:48:59,741 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 04:48:59,741 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 04:48:59,741 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 04:48:59,741 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 04:48:59,741 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 04:48:59,742 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 20:48:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T20:48:58Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T20:48:58Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T20:48:59Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T20:48:58Z', 'request-id': 'req_016DuSStUEvPAoS1DqeVJ5tL', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227980d1e06fa4b-KUL', 'content-encoding': 'gzip'})
2025-03-19 04:48:59,742 - anthropic._base_client - DEBUG - request_id: req_016DuSStUEvPAoS1DqeVJ5tL
2025-03-19 04:48:59,749 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_lookup",
    "parameters": {
        "location": "Paris",
        "forecast_type": "current"
    }
}
```
2025-03-19 04:48:59,749 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_lookup', 'parameters': {'location': 'Paris', 'forecast_type': 'current'}}
2025-03-19 04:48:59,749 - process - ERROR - Error processing request: 'Connector' object has no attribute 'find_server_for_capability'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 333, in process_llm_request
    response = await adapter.process_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 243, in process_request
    server = await self.connector.find_server_for_capability(capability)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Connector' object has no attribute 'find_server_for_capability'
2025-03-19 04:48:59,752 - process - INFO - End time: 2025-03-19 04:48:59
2025-03-19 04:48:59,752 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 04:48:59,752 - process - INFO - Start time: 2025-03-19 04:48:59
2025-03-19 04:48:59,752 - registry - DEBUG - Created MockRegistry
2025-03-19 04:48:59,752 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:48:59,780 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:48:59,781 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:48:59,781 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 04:48:59,782 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': 'Can you tell me the current weather in London?'}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 04:48:59,782 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 04:48:59,782 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 04:48:59,794 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1055fa350>
2025-03-19 04:48:59,795 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105542c30> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 04:48:59,819 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105590e90>
2025-03-19 04:48:59,819 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 04:48:59,820 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 04:48:59,820 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 04:48:59,820 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 04:48:59,820 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 04:49:01,013 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 20:49:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T20:49:00Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T20:49:00Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T20:49:00Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T20:49:00Z'), (b'request-id', b'req_012RDTh4j9a5fv2bP5D6uY3D'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922798163ae7d89d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 04:49:01,016 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 04:49:01,017 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 04:49:01,017 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 04:49:01,017 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 04:49:01,017 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 04:49:01,018 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 20:49:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T20:49:00Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T20:49:00Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T20:49:00Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T20:49:00Z', 'request-id': 'req_012RDTh4j9a5fv2bP5D6uY3D', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922798163ae7d89d-KUL', 'content-encoding': 'gzip'})
2025-03-19 04:49:01,018 - anthropic._base_client - DEBUG - request_id: req_012RDTh4j9a5fv2bP5D6uY3D
2025-03-19 04:49:01,019 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_api",
    "parameters": {
        "location": "London"
    }
}
```
2025-03-19 04:49:01,019 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_api', 'parameters': {'location': 'London'}}
2025-03-19 04:49:01,019 - process - ERROR - Error processing request: 'Connector' object has no attribute 'find_server_for_capability'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 333, in process_llm_request
    response = await adapter.process_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 243, in process_request
    server = await self.connector.find_server_for_capability(capability)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Connector' object has no attribute 'find_server_for_capability'
2025-03-19 04:49:01,020 - process - INFO - End time: 2025-03-19 04:49:01
2025-03-19 04:49:01,020 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:49:01,020 - process - INFO - Start time: 2025-03-19 04:49:01
2025-03-19 04:49:01,020 - registry - DEBUG - Created MockRegistry
2025-03-19 04:49:01,020 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:49:01,052 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:49:01,052 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:49:01,053 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:49:01,054 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "I'd like to know the weather conditions in Tokyo."}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 04:49:01,054 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 04:49:01,054 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 04:49:01,069 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105591220>
2025-03-19 04:49:01,069 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105543530> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 04:49:01,100 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10556e570>
2025-03-19 04:49:01,100 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 04:49:01,100 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 04:49:01,100 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 04:49:01,100 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 04:49:01,100 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 04:49:02,246 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 20:49:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T20:49:01Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T20:49:01Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T20:49:02Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T20:49:01Z'), (b'request-id', b'req_019yyqXaEPVe5kwQi335yS34'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227981e3e25e580-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 04:49:02,248 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 04:49:02,249 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 04:49:02,249 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 04:49:02,249 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 04:49:02,249 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 04:49:02,250 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 20:49:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T20:49:01Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T20:49:01Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T20:49:02Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T20:49:01Z', 'request-id': 'req_019yyqXaEPVe5kwQi335yS34', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227981e3e25e580-KUL', 'content-encoding': 'gzip'})
2025-03-19 04:49:02,250 - anthropic._base_client - DEBUG - request_id: req_019yyqXaEPVe5kwQi335yS34
2025-03-19 04:49:02,251 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_lookup",
    "parameters": {
        "location": "Tokyo"
    }
}
```
2025-03-19 04:49:02,251 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_lookup', 'parameters': {'location': 'Tokyo'}}
2025-03-19 04:49:02,252 - process - ERROR - Error processing request: 'Connector' object has no attribute 'find_server_for_capability'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 333, in process_llm_request
    response = await adapter.process_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 243, in process_request
    server = await self.connector.find_server_for_capability(capability)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Connector' object has no attribute 'find_server_for_capability'
2025-03-19 04:49:02,253 - process - INFO - End time: 2025-03-19 04:49:02
2025-03-19 04:49:02,291 - httpcore.connection - DEBUG - close.started
2025-03-19 04:49:02,292 - httpcore.connection - DEBUG - close.complete
2025-03-19 04:49:02,292 - httpcore.connection - DEBUG - close.started
2025-03-19 04:49:02,292 - httpcore.connection - DEBUG - close.complete
2025-03-19 04:49:02,292 - httpcore.connection - DEBUG - close.started
2025-03-19 04:49:02,292 - httpcore.connection - DEBUG - close.complete
2025-03-19 04:52:36,925 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 04:52:36,929 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 04:52:36,929 - process - INFO - Start time: 2025-03-19 04:52:36
2025-03-19 04:52:36,929 - registry - DEBUG - Created MockRegistry
2025-03-19 04:52:36,929 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:52:36,929 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 344, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 66, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 04:52:36,930 - process - INFO - End time: 2025-03-19 04:52:36
2025-03-19 04:52:36,930 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 04:52:36,930 - process - INFO - Start time: 2025-03-19 04:52:36
2025-03-19 04:52:36,930 - registry - DEBUG - Created MockRegistry
2025-03-19 04:52:36,930 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:52:36,930 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 344, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 66, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 04:52:36,931 - process - INFO - End time: 2025-03-19 04:52:36
2025-03-19 04:52:36,931 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:52:36,931 - process - INFO - Start time: 2025-03-19 04:52:36
2025-03-19 04:52:36,931 - registry - DEBUG - Created MockRegistry
2025-03-19 04:52:36,931 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:52:36,931 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 344, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 66, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 04:52:36,931 - process - INFO - End time: 2025-03-19 04:52:36
2025-03-19 04:53:14,988 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 04:53:14,992 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 04:53:14,992 - process - INFO - Start time: 2025-03-19 04:53:14
2025-03-19 04:53:14,992 - registry - DEBUG - Created MockRegistry
2025-03-19 04:53:14,992 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:53:14,992 - process - ERROR - Error processing request: MockAnthropicClient.__init__() got an unexpected keyword argument 'api_key'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 347, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 77, in setup
    self.client = anthropic.Anthropic(api_key=api_key)
                  ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
TypeError: MockAnthropicClient.__init__() got an unexpected keyword argument 'api_key'
2025-03-19 04:53:14,993 - process - INFO - End time: 2025-03-19 04:53:14
2025-03-19 04:53:14,993 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 04:53:14,993 - process - INFO - Start time: 2025-03-19 04:53:14
2025-03-19 04:53:14,993 - registry - DEBUG - Created MockRegistry
2025-03-19 04:53:14,993 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:53:14,993 - process - ERROR - Error processing request: MockAnthropicClient.__init__() got an unexpected keyword argument 'api_key'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 347, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 77, in setup
    self.client = anthropic.Anthropic(api_key=api_key)
                  ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
TypeError: MockAnthropicClient.__init__() got an unexpected keyword argument 'api_key'
2025-03-19 04:53:14,993 - process - INFO - End time: 2025-03-19 04:53:14
2025-03-19 04:53:14,993 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:53:14,993 - process - INFO - Start time: 2025-03-19 04:53:14
2025-03-19 04:53:14,993 - registry - DEBUG - Created MockRegistry
2025-03-19 04:53:14,993 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:53:14,993 - process - ERROR - Error processing request: MockAnthropicClient.__init__() got an unexpected keyword argument 'api_key'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 347, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 77, in setup
    self.client = anthropic.Anthropic(api_key=api_key)
                  ~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
TypeError: MockAnthropicClient.__init__() got an unexpected keyword argument 'api_key'
2025-03-19 04:53:14,993 - process - INFO - End time: 2025-03-19 04:53:14
2025-03-19 04:53:45,206 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 04:53:45,209 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 04:53:45,210 - process - INFO - Start time: 2025-03-19 04:53:45
2025-03-19 04:53:45,210 - registry - DEBUG - Created MockRegistry
2025-03-19 04:53:45,210 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:53:45,210 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:53:45,210 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:53:45,210 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:53:45,210 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 04:53:45,210 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:53:45,210 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:53:45,210 - interpret - DEBUG - User message: What's the weather like in Paris today?
2025-03-19 04:53:45,210 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Paris"}}
2025-03-19 04:53:45,210 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Paris"}}
```
2025-03-19 04:53:45,210 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris'}}
2025-03-19 04:53:45,210 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:53:45,210 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:53:45,210 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:53:45,210 - state_of_mika.adapters.claude - ERROR - Error executing tool: 'MockRegistry' object has no attribute 'search_by_capability'
2025-03-19 04:53:45,210 - result - INFO - Request processing completed successfully
2025-03-19 04:53:45,210 - result - DEBUG - Final result: {
  "success": false,
  "error": "Error executing tool: 'MockRegistry' object has no attribute 'search_by_capability'"
}
2025-03-19 04:53:45,210 - process - INFO - End time: 2025-03-19 04:53:45
2025-03-19 04:53:45,210 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 04:53:45,210 - process - INFO - Start time: 2025-03-19 04:53:45
2025-03-19 04:53:45,210 - registry - DEBUG - Created MockRegistry
2025-03-19 04:53:45,210 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:53:45,210 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:53:45,210 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:53:45,210 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:53:45,210 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 04:53:45,210 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:53:45,210 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:53:45,211 - interpret - DEBUG - User message: Can you tell me the current weather in London?
2025-03-19 04:53:45,211 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "London"}}
2025-03-19 04:53:45,211 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "London"}}
```
2025-03-19 04:53:45,211 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 04:53:45,211 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:53:45,211 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:53:45,211 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:53:45,211 - state_of_mika.adapters.claude - ERROR - Error executing tool: 'MockRegistry' object has no attribute 'search_by_capability'
2025-03-19 04:53:45,211 - result - INFO - Request processing completed successfully
2025-03-19 04:53:45,211 - result - DEBUG - Final result: {
  "success": false,
  "error": "Error executing tool: 'MockRegistry' object has no attribute 'search_by_capability'"
}
2025-03-19 04:53:45,211 - process - INFO - End time: 2025-03-19 04:53:45
2025-03-19 04:53:45,211 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:53:45,211 - process - INFO - Start time: 2025-03-19 04:53:45
2025-03-19 04:53:45,211 - registry - DEBUG - Created MockRegistry
2025-03-19 04:53:45,211 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:53:45,211 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:53:45,211 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:53:45,211 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:53:45,211 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:53:45,211 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:53:45,211 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:53:45,211 - interpret - DEBUG - User message: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:53:45,211 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Tokyo"}}
2025-03-19 04:53:45,211 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Tokyo"}}
```
2025-03-19 04:53:45,211 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 04:53:45,211 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:53:45,211 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:53:45,211 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:53:45,211 - state_of_mika.adapters.claude - ERROR - Error executing tool: 'MockRegistry' object has no attribute 'search_by_capability'
2025-03-19 04:53:45,211 - result - INFO - Request processing completed successfully
2025-03-19 04:53:45,211 - result - DEBUG - Final result: {
  "success": false,
  "error": "Error executing tool: 'MockRegistry' object has no attribute 'search_by_capability'"
}
2025-03-19 04:53:45,211 - process - INFO - End time: 2025-03-19 04:53:45
2025-03-19 04:55:31,405 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 04:55:31,409 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 04:55:31,409 - process - INFO - Start time: 2025-03-19 04:55:31
2025-03-19 04:55:31,409 - registry - DEBUG - Created MockRegistry
2025-03-19 04:55:31,409 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:55:31,409 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:55:31,409 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:55:31,409 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:55:31,409 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 04:55:31,409 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:55:31,409 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:55:31,409 - interpret - DEBUG - User message: What's the weather like in Paris today?
2025-03-19 04:55:31,409 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Paris"}}
2025-03-19 04:55:31,410 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Paris"}}
```
2025-03-19 04:55:31,410 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris'}}
2025-03-19 04:55:31,410 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:55:31,410 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:55:31,410 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:55:31,410 - registry - DEBUG - Search by capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:31,410 - registry - DEBUG - Finding servers for capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:31,410 - state_of_mika.adapters.claude - ERROR - Error executing tool: No MCP server found for capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:31,410 - state_of_mika.adapters.claude - DEBUG - Trying fallback execution method for capability: weather
2025-03-19 04:55:31,410 - execute - DEBUG - Executing capability: weather, tool: get_weather, parameters: {'location': 'Paris'}
2025-03-19 04:55:31,410 - result - INFO - Request processing completed successfully
2025-03-19 04:55:31,410 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "get_weather",
  "parameters": {
    "location": "Paris"
  },
  "result": {
    "temperature": 22,
    "condition": "Sunny",
    "humidity": 65,
    "location": "Paris"
  }
}
2025-03-19 04:55:31,410 - process - INFO - End time: 2025-03-19 04:55:31
2025-03-19 04:55:31,410 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 04:55:31,410 - process - INFO - Start time: 2025-03-19 04:55:31
2025-03-19 04:55:31,410 - registry - DEBUG - Created MockRegistry
2025-03-19 04:55:31,410 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:55:31,410 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:55:31,410 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:55:31,410 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:55:31,410 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 04:55:31,410 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:55:31,410 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:55:31,411 - interpret - DEBUG - User message: Can you tell me the current weather in London?
2025-03-19 04:55:31,411 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "London"}}
2025-03-19 04:55:31,411 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "London"}}
```
2025-03-19 04:55:31,411 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 04:55:31,411 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:55:31,411 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:55:31,411 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:55:31,411 - registry - DEBUG - Search by capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:31,411 - registry - DEBUG - Finding servers for capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:31,411 - state_of_mika.adapters.claude - ERROR - Error executing tool: No MCP server found for capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:31,412 - state_of_mika.adapters.claude - DEBUG - Trying fallback execution method for capability: weather
2025-03-19 04:55:31,412 - execute - DEBUG - Executing capability: weather, tool: get_weather, parameters: {'location': 'London'}
2025-03-19 04:55:31,412 - result - INFO - Request processing completed successfully
2025-03-19 04:55:31,412 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "get_weather",
  "parameters": {
    "location": "London"
  },
  "result": {
    "temperature": 18,
    "condition": "Cloudy",
    "humidity": 75,
    "location": "London"
  }
}
2025-03-19 04:55:31,412 - process - INFO - End time: 2025-03-19 04:55:31
2025-03-19 04:55:31,412 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:55:31,412 - process - INFO - Start time: 2025-03-19 04:55:31
2025-03-19 04:55:31,412 - registry - DEBUG - Created MockRegistry
2025-03-19 04:55:31,412 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:55:31,412 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:55:31,412 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:55:31,412 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:55:31,412 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:55:31,412 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:55:31,412 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:55:31,412 - interpret - DEBUG - User message: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:55:31,412 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Tokyo"}}
2025-03-19 04:55:31,412 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Tokyo"}}
```
2025-03-19 04:55:31,412 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 04:55:31,412 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:55:31,412 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:55:31,412 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:55:31,412 - registry - DEBUG - Search by capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:31,412 - registry - DEBUG - Finding servers for capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:31,412 - state_of_mika.adapters.claude - ERROR - Error executing tool: No MCP server found for capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:31,413 - state_of_mika.adapters.claude - DEBUG - Trying fallback execution method for capability: weather
2025-03-19 04:55:31,413 - execute - DEBUG - Executing capability: weather, tool: get_weather, parameters: {'location': 'Tokyo'}
2025-03-19 04:55:31,413 - result - INFO - Request processing completed successfully
2025-03-19 04:55:31,413 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "get_weather",
  "parameters": {
    "location": "Tokyo"
  },
  "result": {
    "temperature": 28,
    "condition": "Partly Cloudy",
    "humidity": 60,
    "location": "Tokyo"
  }
}
2025-03-19 04:55:31,413 - process - INFO - End time: 2025-03-19 04:55:31
2025-03-19 04:55:54,138 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 04:55:54,142 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 04:55:54,142 - process - INFO - Start time: 2025-03-19 04:55:54
2025-03-19 04:55:54,142 - registry - DEBUG - Created MockRegistry
2025-03-19 04:55:54,142 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:55:54,142 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:55:54,142 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:55:54,142 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:55:54,142 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 04:55:54,142 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:55:54,142 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:55:54,142 - interpret - DEBUG - User message: What's the weather like in Paris today?
2025-03-19 04:55:54,142 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Paris"}}
2025-03-19 04:55:54,142 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Paris"}}
```
2025-03-19 04:55:54,142 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris'}}
2025-03-19 04:55:54,142 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:55:54,142 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:55:54,142 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:55:54,142 - registry - DEBUG - Search by capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:54,142 - state_of_mika.connector - WARNING - Failed to connect to mcp_weather: 'MockRegistry' object has no attribute 'get_server_by_name'
2025-03-19 04:55:54,143 - state_of_mika.adapters.claude - ERROR - Error executing tool: Failed to connect to any server for capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:54,143 - state_of_mika.adapters.claude - DEBUG - Trying fallback execution method for capability: weather
2025-03-19 04:55:54,143 - execute - DEBUG - Executing capability: weather, tool: get_weather, parameters: {'location': 'Paris'}
2025-03-19 04:55:54,143 - result - INFO - Request processing completed successfully
2025-03-19 04:55:54,143 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "get_weather",
  "parameters": {
    "location": "Paris"
  },
  "result": {
    "temperature": 22,
    "condition": "Sunny",
    "humidity": 65,
    "location": "Paris"
  }
}
2025-03-19 04:55:54,143 - process - INFO - End time: 2025-03-19 04:55:54
2025-03-19 04:55:54,143 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 04:55:54,143 - process - INFO - Start time: 2025-03-19 04:55:54
2025-03-19 04:55:54,143 - registry - DEBUG - Created MockRegistry
2025-03-19 04:55:54,143 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:55:54,143 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:55:54,143 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:55:54,143 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:55:54,143 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 04:55:54,143 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:55:54,143 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:55:54,143 - interpret - DEBUG - User message: Can you tell me the current weather in London?
2025-03-19 04:55:54,143 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "London"}}
2025-03-19 04:55:54,143 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "London"}}
```
2025-03-19 04:55:54,143 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 04:55:54,143 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:55:54,143 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:55:54,143 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:55:54,143 - registry - DEBUG - Search by capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:54,143 - state_of_mika.connector - WARNING - Failed to connect to mcp_weather: 'MockRegistry' object has no attribute 'get_server_by_name'
2025-03-19 04:55:54,143 - state_of_mika.adapters.claude - ERROR - Error executing tool: Failed to connect to any server for capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:54,143 - state_of_mika.adapters.claude - DEBUG - Trying fallback execution method for capability: weather
2025-03-19 04:55:54,143 - execute - DEBUG - Executing capability: weather, tool: get_weather, parameters: {'location': 'London'}
2025-03-19 04:55:54,143 - result - INFO - Request processing completed successfully
2025-03-19 04:55:54,143 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "get_weather",
  "parameters": {
    "location": "London"
  },
  "result": {
    "temperature": 18,
    "condition": "Cloudy",
    "humidity": 75,
    "location": "London"
  }
}
2025-03-19 04:55:54,143 - process - INFO - End time: 2025-03-19 04:55:54
2025-03-19 04:55:54,143 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:55:54,143 - process - INFO - Start time: 2025-03-19 04:55:54
2025-03-19 04:55:54,143 - registry - DEBUG - Created MockRegistry
2025-03-19 04:55:54,143 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:55:54,143 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:55:54,143 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:55:54,143 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:55:54,143 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:55:54,143 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:55:54,143 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:55:54,143 - interpret - DEBUG - User message: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:55:54,144 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Tokyo"}}
2025-03-19 04:55:54,144 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Tokyo"}}
```
2025-03-19 04:55:54,144 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 04:55:54,144 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:55:54,144 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:55:54,144 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:55:54,144 - registry - DEBUG - Search by capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:54,144 - state_of_mika.connector - WARNING - Failed to connect to mcp_weather: 'MockRegistry' object has no attribute 'get_server_by_name'
2025-03-19 04:55:54,144 - state_of_mika.adapters.claude - ERROR - Error executing tool: Failed to connect to any server for capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:55:54,144 - state_of_mika.adapters.claude - DEBUG - Trying fallback execution method for capability: weather
2025-03-19 04:55:54,144 - execute - DEBUG - Executing capability: weather, tool: get_weather, parameters: {'location': 'Tokyo'}
2025-03-19 04:55:54,144 - result - INFO - Request processing completed successfully
2025-03-19 04:55:54,144 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "get_weather",
  "parameters": {
    "location": "Tokyo"
  },
  "result": {
    "temperature": 28,
    "condition": "Partly Cloudy",
    "humidity": 60,
    "location": "Tokyo"
  }
}
2025-03-19 04:55:54,144 - process - INFO - End time: 2025-03-19 04:55:54
2025-03-19 04:56:21,037 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 04:56:21,041 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 04:56:21,041 - process - INFO - Start time: 2025-03-19 04:56:21
2025-03-19 04:56:21,041 - registry - DEBUG - Created MockRegistry
2025-03-19 04:56:21,041 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:56:21,041 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:56:21,041 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:56:21,041 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:56:21,041 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 04:56:21,041 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:56:21,041 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:56:21,041 - interpret - DEBUG - User message: What's the weather like in Paris today?
2025-03-19 04:56:21,041 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Paris"}}
2025-03-19 04:56:21,041 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Paris"}}
```
2025-03-19 04:56:21,041 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris'}}
2025-03-19 04:56:21,041 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:56:21,041 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:56:21,041 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:56:21,041 - process - ERROR - Error processing request: 'MockRegistry' object has no attribute 'is_server_installed'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 394, in process_llm_request
    response = await adapter.process_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 250, in process_request
    server = await self.connector.find_server_for_capability(capability)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/connector.py", line 361, in find_server_for_capability
    if not self.registry.is_server_installed(server_name):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'MockRegistry' object has no attribute 'is_server_installed'
2025-03-19 04:56:21,042 - process - INFO - End time: 2025-03-19 04:56:21
2025-03-19 04:56:21,042 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 04:56:21,042 - process - INFO - Start time: 2025-03-19 04:56:21
2025-03-19 04:56:21,042 - registry - DEBUG - Created MockRegistry
2025-03-19 04:56:21,042 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:56:21,042 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:56:21,042 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:56:21,042 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:56:21,042 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 04:56:21,042 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:56:21,042 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:56:21,042 - interpret - DEBUG - User message: Can you tell me the current weather in London?
2025-03-19 04:56:21,042 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "London"}}
2025-03-19 04:56:21,042 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "London"}}
```
2025-03-19 04:56:21,042 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 04:56:21,042 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:56:21,043 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:56:21,043 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:56:21,043 - process - ERROR - Error processing request: 'MockRegistry' object has no attribute 'is_server_installed'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 394, in process_llm_request
    response = await adapter.process_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 250, in process_request
    server = await self.connector.find_server_for_capability(capability)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/connector.py", line 361, in find_server_for_capability
    if not self.registry.is_server_installed(server_name):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'MockRegistry' object has no attribute 'is_server_installed'
2025-03-19 04:56:21,043 - process - INFO - End time: 2025-03-19 04:56:21
2025-03-19 04:56:21,043 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:56:21,043 - process - INFO - Start time: 2025-03-19 04:56:21
2025-03-19 04:56:21,043 - registry - DEBUG - Created MockRegistry
2025-03-19 04:56:21,043 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:56:21,043 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:56:21,043 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:56:21,043 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:56:21,043 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:56:21,043 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:56:21,043 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:56:21,043 - interpret - DEBUG - User message: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:56:21,043 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Tokyo"}}
2025-03-19 04:56:21,043 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Tokyo"}}
```
2025-03-19 04:56:21,043 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 04:56:21,043 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:56:21,044 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:56:21,044 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:56:21,044 - process - ERROR - Error processing request: 'MockRegistry' object has no attribute 'is_server_installed'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 394, in process_llm_request
    response = await adapter.process_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 250, in process_request
    server = await self.connector.find_server_for_capability(capability)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/connector.py", line 361, in find_server_for_capability
    if not self.registry.is_server_installed(server_name):
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'MockRegistry' object has no attribute 'is_server_installed'
2025-03-19 04:56:21,044 - process - INFO - End time: 2025-03-19 04:56:21
2025-03-19 04:57:11,255 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 04:57:11,260 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 04:57:11,260 - process - INFO - Start time: 2025-03-19 04:57:11
2025-03-19 04:57:11,260 - registry - DEBUG - Created MockRegistry
2025-03-19 04:57:11,260 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:57:11,262 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:57:11,262 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:57:11,262 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:57:11,263 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 04:57:11,263 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:57:11,263 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:57:11,264 - interpret - DEBUG - User message: What's the weather like in Paris today?
2025-03-19 04:57:11,264 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Paris"}}
2025-03-19 04:57:11,264 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Paris"}}
```
2025-03-19 04:57:11,265 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris'}}
2025-03-19 04:57:11,265 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:57:11,265 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:57:11,265 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:57:11,265 - registry - DEBUG - Checking if server mcp_weather is installed
2025-03-19 04:57:11,265 - registry - DEBUG - Search by capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:57:11,265 - registry - DEBUG - Getting server by name: mcp_weather
2025-03-19 04:57:11,265 - registry - DEBUG - Checking if server mcp_weather is installed
2025-03-19 04:57:11,265 - state_of_mika.connector - ERROR - Failed to connect to server mcp_weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 04:57:11,265 - state_of_mika.connector - WARNING - Failed to connect to mcp_weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 04:57:11,265 - state_of_mika.adapters.claude - ERROR - Error executing tool: Failed to connect to any server for capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:57:11,265 - state_of_mika.adapters.claude - DEBUG - Trying fallback execution method for capability: weather
2025-03-19 04:57:11,265 - execute - DEBUG - Executing capability: weather, tool: get_weather, parameters: {'location': 'Paris'}
2025-03-19 04:57:11,265 - result - INFO - Request processing completed successfully
2025-03-19 04:57:11,265 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "get_weather",
  "parameters": {
    "location": "Paris"
  },
  "result": {
    "temperature": 22,
    "condition": "Sunny",
    "humidity": 65,
    "location": "Paris"
  }
}
2025-03-19 04:57:11,265 - process - INFO - End time: 2025-03-19 04:57:11
2025-03-19 04:57:11,265 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 04:57:11,265 - process - INFO - Start time: 2025-03-19 04:57:11
2025-03-19 04:57:11,265 - registry - DEBUG - Created MockRegistry
2025-03-19 04:57:11,265 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:57:11,265 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:57:11,265 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:57:11,265 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:57:11,265 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 04:57:11,265 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:57:11,265 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:57:11,265 - interpret - DEBUG - User message: Can you tell me the current weather in London?
2025-03-19 04:57:11,265 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "London"}}
2025-03-19 04:57:11,265 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "London"}}
```
2025-03-19 04:57:11,265 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 04:57:11,265 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:57:11,265 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:57:11,266 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:57:11,266 - registry - DEBUG - Checking if server mcp_weather is installed
2025-03-19 04:57:11,266 - registry - DEBUG - Search by capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:57:11,266 - registry - DEBUG - Getting server by name: mcp_weather
2025-03-19 04:57:11,266 - registry - DEBUG - Checking if server mcp_weather is installed
2025-03-19 04:57:11,266 - state_of_mika.connector - ERROR - Failed to connect to server mcp_weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 04:57:11,266 - state_of_mika.connector - WARNING - Failed to connect to mcp_weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 04:57:11,266 - state_of_mika.adapters.claude - ERROR - Error executing tool: Failed to connect to any server for capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:57:11,266 - state_of_mika.adapters.claude - DEBUG - Trying fallback execution method for capability: weather
2025-03-19 04:57:11,266 - execute - DEBUG - Executing capability: weather, tool: get_weather, parameters: {'location': 'London'}
2025-03-19 04:57:11,266 - result - INFO - Request processing completed successfully
2025-03-19 04:57:11,266 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "get_weather",
  "parameters": {
    "location": "London"
  },
  "result": {
    "temperature": 18,
    "condition": "Cloudy",
    "humidity": 75,
    "location": "London"
  }
}
2025-03-19 04:57:11,266 - process - INFO - End time: 2025-03-19 04:57:11
2025-03-19 04:57:11,266 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:57:11,266 - process - INFO - Start time: 2025-03-19 04:57:11
2025-03-19 04:57:11,266 - registry - DEBUG - Created MockRegistry
2025-03-19 04:57:11,266 - install - DEBUG - Created MockInstaller with registry
2025-03-19 04:57:11,266 - interpret - DEBUG - Created MockAnthropicClient
2025-03-19 04:57:11,266 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 04:57:11,266 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 04:57:11,266 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:57:11,266 - interpret - DEBUG - Claude interpreting request with 1 messages
2025-03-19 04:57:11,266 - interpret - DEBUG - System prompt: 
        You are an assistant that helps interpret natural language requests into structured commands.
        
        First, determine the capability needed for the request (weather, search, etc.).
        Then, identify the specific tool needed and required parameters.
        
        Format your response as JSON with these fields:
        {
            "capability": "the capability name",
            "tool_name": "the tool name",
            "parameters": {
                "param1": "value1",
                "param2": "value2"
            }
        }
        
        Think carefully about what the user is actually asking for and format your response
        precisely as JSON inside ```json code blocks.
        
2025-03-19 04:57:11,266 - interpret - DEBUG - User message: I'd like to know the weather conditions in Tokyo.
2025-03-19 04:57:11,266 - interpret - DEBUG - Claude interpretation: {"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Tokyo"}}
2025-03-19 04:57:11,267 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{"capability": "weather", "tool_name": "get_weather", "parameters": {"location": "Tokyo"}}
```
2025-03-19 04:57:11,267 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 04:57:11,267 - registry - DEBUG - Finding servers for capability: weather
2025-03-19 04:57:11,267 - registry - DEBUG - Found server mcp_weather for capability weather
2025-03-19 04:57:11,267 - registry - DEBUG - Checking if server mcp_weather is installed: True
2025-03-19 04:57:11,267 - registry - DEBUG - Checking if server mcp_weather is installed
2025-03-19 04:57:11,267 - registry - DEBUG - Search by capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:57:11,267 - registry - DEBUG - Getting server by name: mcp_weather
2025-03-19 04:57:11,267 - registry - DEBUG - Checking if server mcp_weather is installed
2025-03-19 04:57:11,267 - state_of_mika.connector - ERROR - Failed to connect to server mcp_weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 04:57:11,267 - state_of_mika.connector - WARNING - Failed to connect to mcp_weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 04:57:11,267 - state_of_mika.adapters.claude - ERROR - Error executing tool: Failed to connect to any server for capability: {'name': 'mcp_weather', 'description': 'MCP server for weather information', 'capabilities': ['weather', 'forecast', 'temperature'], 'version': '0.1.0', 'installation': {'type': 'pip', 'package': 'mcp-weather'}, 'launch': {'command': 'mcp-weather', 'args': ['--port', '8080']}}
2025-03-19 04:57:11,267 - state_of_mika.adapters.claude - DEBUG - Trying fallback execution method for capability: weather
2025-03-19 04:57:11,267 - execute - DEBUG - Executing capability: weather, tool: get_weather, parameters: {'location': 'Tokyo'}
2025-03-19 04:57:11,267 - result - INFO - Request processing completed successfully
2025-03-19 04:57:11,267 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "get_weather",
  "parameters": {
    "location": "Tokyo"
  },
  "result": {
    "temperature": 28,
    "condition": "Partly Cloudy",
    "humidity": 60,
    "location": "Tokyo"
  }
}
2025-03-19 04:57:11,268 - process - INFO - End time: 2025-03-19 04:57:11
2025-03-19 05:01:54,489 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:01:54,490 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:01:54,491 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:01:54,494 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:01:54,494 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:01:54,495 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:01:54,495 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:01:54,495 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:01:54,495 - process - INFO - Start time: 2025-03-19 05:01:54
2025-03-19 05:01:54,496 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:01:54,496 - process - ERROR - Error processing request: 'Registry' object has no attribute 'load'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 99, in process_llm_request
    await registry.load()
          ^^^^^^^^^^^^^
AttributeError: 'Registry' object has no attribute 'load'
2025-03-19 05:01:54,496 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:01:54,496 - process - INFO - End time: 2025-03-19 05:01:54
2025-03-19 05:01:54,496 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:01:54,496 - process - INFO - Start time: 2025-03-19 05:01:54
2025-03-19 05:01:54,496 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:01:54,496 - process - ERROR - Error processing request: 'Registry' object has no attribute 'load'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 99, in process_llm_request
    await registry.load()
          ^^^^^^^^^^^^^
AttributeError: 'Registry' object has no attribute 'load'
2025-03-19 05:01:54,496 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:01:54,496 - process - INFO - End time: 2025-03-19 05:01:54
2025-03-19 05:01:54,496 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:01:54,496 - process - INFO - Start time: 2025-03-19 05:01:54
2025-03-19 05:01:54,496 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:01:54,496 - process - ERROR - Error processing request: 'Registry' object has no attribute 'load'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 99, in process_llm_request
    await registry.load()
          ^^^^^^^^^^^^^
AttributeError: 'Registry' object has no attribute 'load'
2025-03-19 05:01:54,497 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:01:54,497 - process - INFO - End time: 2025-03-19 05:01:54
2025-03-19 05:02:54,922 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:02:54,923 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:02:54,924 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:02:54,926 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:02:54,927 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:02:54,927 - process - INFO - Start time: 2025-03-19 05:02:54
2025-03-19 05:02:54,927 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:02:54,927 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 103, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 69, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:02:54,928 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:02:54,928 - process - INFO - End time: 2025-03-19 05:02:54
2025-03-19 05:02:54,928 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:02:54,928 - process - INFO - Start time: 2025-03-19 05:02:54
2025-03-19 05:02:54,928 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:02:54,928 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 103, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 69, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:02:54,928 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:02:54,928 - process - INFO - End time: 2025-03-19 05:02:54
2025-03-19 05:02:54,928 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:02:54,928 - process - INFO - Start time: 2025-03-19 05:02:54
2025-03-19 05:02:54,929 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:02:54,929 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 103, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 69, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:02:54,929 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:02:54,929 - process - INFO - End time: 2025-03-19 05:02:54
2025-03-19 05:04:06,040 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:04:06,042 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:04:06,080 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:04:06,080 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:04:06,081 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "What's the weather like in Paris today?"}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:04:06,101 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:04:06,101 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:04:06,137 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107c61fd0>
2025-03-19 05:04:06,137 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107bf2c30> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:04:06,154 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107b8e350>
2025-03-19 05:04:06,154 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:04:06,154 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:04:06,155 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:04:06,155 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:04:06,155 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:04:07,472 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:04:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:04:06Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:04:06Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:04:07Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:04:06Z'), (b'request-id', b'req_01RLgRuPjR6rB2RLW5rkXNjU'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227ae36af08e580-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:04:07,473 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:04:07,473 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:04:07,473 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:04:07,473 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:04:07,474 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:04:07,474 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:04:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:04:06Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:04:06Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:04:07Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:04:06Z', 'request-id': 'req_01RLgRuPjR6rB2RLW5rkXNjU', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227ae36af08e580-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:04:07,474 - anthropic._base_client - DEBUG - request_id: req_01RLgRuPjR6rB2RLW5rkXNjU
2025-03-19 05:04:07,478 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_lookup",
    "parameters": {
        "location": "Paris",
        "date": "today"
    }
}
```
2025-03-19 05:04:07,478 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_lookup', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 05:04:07,478 - __main__ - ERROR - Error processing request: 'Registry' object has no attribute 'find_servers_by_capability'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/real_world_test.py", line 68, in run_real_test
    response = await adapter.process_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 250, in process_request
    server = await self.connector.find_server_for_capability(capability)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/connector.py", line 350, in find_server_for_capability
    servers = self.registry.find_servers_by_capability(capability)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Registry' object has no attribute 'find_servers_by_capability'
2025-03-19 05:04:07,480 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:04:09,482 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:04:09,501 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:04:09,501 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:04:09,503 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': 'Can you tell me the current weather in London?'}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:04:09,503 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:04:09,503 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:04:09,512 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107d1d810>
2025-03-19 05:04:09,512 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107d180e0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:04:09,524 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107c05ba0>
2025-03-19 05:04:09,524 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:04:09,524 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:04:09,525 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:04:09,525 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:04:09,525 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:04:10,677 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:04:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:04:09Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:04:10Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:04:10Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:04:10Z'), (b'request-id', b'req_01MTEJYdzioNTN8CcmjDoTMb'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227ae4bb8149c13-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:04:10,678 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:04:10,678 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:04:10,678 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:04:10,678 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:04:10,678 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:04:10,678 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:04:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:04:09Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:04:10Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:04:10Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:04:10Z', 'request-id': 'req_01MTEJYdzioNTN8CcmjDoTMb', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227ae4bb8149c13-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:04:10,678 - anthropic._base_client - DEBUG - request_id: req_01MTEJYdzioNTN8CcmjDoTMb
2025-03-19 05:04:10,678 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_lookup",
    "parameters": {
        "location": "London"
    }
}
```
2025-03-19 05:04:10,678 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_lookup', 'parameters': {'location': 'London'}}
2025-03-19 05:04:10,678 - __main__ - ERROR - Error processing request: 'Registry' object has no attribute 'find_servers_by_capability'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/real_world_test.py", line 68, in run_real_test
    response = await adapter.process_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 250, in process_request
    server = await self.connector.find_server_for_capability(capability)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/connector.py", line 350, in find_server_for_capability
    servers = self.registry.find_servers_by_capability(capability)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Registry' object has no attribute 'find_servers_by_capability'
2025-03-19 05:04:10,679 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:04:12,681 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:04:12,699 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:04:12,699 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:04:12,700 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "I'd like to know the weather conditions in Tokyo."}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:04:12,701 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:04:12,701 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:04:12,713 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107c062c0>
2025-03-19 05:04:12,713 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107bf3530> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:04:12,727 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107c71130>
2025-03-19 05:04:12,727 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:04:12,727 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:04:12,727 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:04:12,728 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:04:12,728 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:04:13,852 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:04:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:04:12Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:04:13Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:04:13Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:04:13Z'), (b'request-id', b'req_01B5Z3ussxyg1BMJEz1MMu2K'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227ae5fb8e6e54f-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:04:13,852 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:04:13,852 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:04:13,853 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:04:13,853 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:04:13,853 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:04:13,853 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:04:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:04:12Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:04:13Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:04:13Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:04:13Z', 'request-id': 'req_01B5Z3ussxyg1BMJEz1MMu2K', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227ae5fb8e6e54f-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:04:13,853 - anthropic._base_client - DEBUG - request_id: req_01B5Z3ussxyg1BMJEz1MMu2K
2025-03-19 05:04:13,853 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_forecast",
    "parameters": {
        "location": "Tokyo"
    }
}
```
2025-03-19 05:04:13,853 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_forecast', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:04:13,853 - __main__ - ERROR - Error processing request: 'Registry' object has no attribute 'find_servers_by_capability'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/real_world_test.py", line 68, in run_real_test
    response = await adapter.process_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 250, in process_request
    server = await self.connector.find_server_for_capability(capability)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/connector.py", line 350, in find_server_for_capability
    servers = self.registry.find_servers_by_capability(capability)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
AttributeError: 'Registry' object has no attribute 'find_servers_by_capability'
2025-03-19 05:04:13,854 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:04:13,875 - httpcore.connection - DEBUG - close.started
2025-03-19 05:04:13,875 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:04:13,876 - httpcore.connection - DEBUG - close.started
2025-03-19 05:04:13,876 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:04:13,876 - httpcore.connection - DEBUG - close.started
2025-03-19 05:04:13,876 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:04:58,411 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:04:58,413 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:04:58,452 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:04:58,452 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:04:58,454 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "What's the weather like in Paris today?"}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:04:58,475 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:04:58,475 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:04:58,487 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10478dfd0>
2025-03-19 05:04:58,487 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104722ba0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:04:58,502 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1046be350>
2025-03-19 05:04:58,502 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:04:58,502 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:04:58,503 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:04:58,503 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:04:58,503 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:04:59,829 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:04:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:04:58Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:04:58Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:04:59Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:04:58Z'), (b'request-id', b'req_01EqEPvVNxTdNDv57H4wFrQV'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227af7ddf16d42e-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:04:59,829 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:04:59,829 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:04:59,830 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:04:59,830 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:04:59,830 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:04:59,830 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:04:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:04:58Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:04:58Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:04:59Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:04:58Z', 'request-id': 'req_01EqEPvVNxTdNDv57H4wFrQV', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227af7ddf16d42e-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:04:59,830 - anthropic._base_client - DEBUG - request_id: req_01EqEPvVNxTdNDv57H4wFrQV
2025-03-19 05:04:59,835 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_lookup",
    "parameters": {
        "location": "Paris",
        "date": "today"
    }
}
```
2025-03-19 05:04:59,835 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_lookup', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 05:04:59,835 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:04:59,835 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:04:59,835 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:04:59,835 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:04:59,835 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:04:59,835 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:04:59,835 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:05:01,837 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:05:01,856 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:05:01,856 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:05:01,857 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': 'Can you tell me the current weather in London?'}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:05:01,857 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:05:01,857 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:05:01,866 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1047fd810>
2025-03-19 05:05:01,866 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1047231d0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:05:01,879 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104735ba0>
2025-03-19 05:05:01,879 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:05:01,879 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:05:01,879 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:05:01,879 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:05:01,879 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:05:03,080 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:05:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:05:02Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:05:02Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:05:02Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:05:02Z'), (b'request-id', b'req_01PDYvteY5p2uChNuo41oFE6'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227af92e9e4fa4d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:05:03,081 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:05:03,081 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:05:03,082 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:05:03,082 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:05:03,082 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:05:03,082 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:05:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:05:02Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:05:02Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:05:02Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:05:02Z', 'request-id': 'req_01PDYvteY5p2uChNuo41oFE6', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227af92e9e4fa4d-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:05:03,082 - anthropic._base_client - DEBUG - request_id: req_01PDYvteY5p2uChNuo41oFE6
2025-03-19 05:05:03,083 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "OpenWeatherMap API",
    "parameters": {
        "city": "London",
        "country": "GB"
    }
}
```
2025-03-19 05:05:03,083 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'OpenWeatherMap API', 'parameters': {'city': 'London', 'country': 'GB'}}
2025-03-19 05:05:03,083 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:05:03,083 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:05:03,083 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:05:03,083 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:05:03,083 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:05:03,083 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:05:03,083 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:05:05,084 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:05:05,103 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:05:05,103 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:05:05,105 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "I'd like to know the weather conditions in Tokyo."}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:05:05,105 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:05:05,105 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:05:05,117 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1047362c0>
2025-03-19 05:05:05,117 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1047234a0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:05:05,132 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1047a16d0>
2025-03-19 05:05:05,132 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:05:05,132 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:05:05,132 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:05:05,132 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:05:05,132 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:05:06,472 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:05:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:05:05Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:05:05Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:05:06Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:05:05Z'), (b'request-id', b'req_01KhEPk66KdCveH6TkV9ALwo'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227afa74b21d89d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:05:06,472 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:05:06,472 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:05:06,472 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:05:06,472 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:05:06,472 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:05:06,472 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:05:06 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:05:05Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:05:05Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:05:06Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:05:05Z', 'request-id': 'req_01KhEPk66KdCveH6TkV9ALwo', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227afa74b21d89d-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:05:06,473 - anthropic._base_client - DEBUG - request_id: req_01KhEPk66KdCveH6TkV9ALwo
2025-03-19 05:05:06,473 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather lookup",
    "parameters": {
        "location": "Tokyo"
    }
}
```
2025-03-19 05:05:06,473 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather lookup', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:05:06,473 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:05:06,473 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:05:06,473 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:05:06,473 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:05:06,473 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:05:06,473 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:05:06,473 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:05:06,491 - httpcore.connection - DEBUG - close.started
2025-03-19 05:05:06,492 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:05:06,492 - httpcore.connection - DEBUG - close.started
2025-03-19 05:05:06,492 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:05:06,492 - httpcore.connection - DEBUG - close.started
2025-03-19 05:05:06,492 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:07:18,383 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:07:18,385 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:07:18,430 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:07:18,430 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:07:18,431 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "What's the weather like in Paris today?"}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:07:18,454 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:07:18,455 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:07:18,466 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104e8dfd0>
2025-03-19 05:07:18,466 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104e22c30> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:07:18,477 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104dbe490>
2025-03-19 05:07:18,477 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:07:18,477 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:07:18,477 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:07:18,477 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:07:18,477 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:07:19,814 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:07:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:07:18Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:07:19Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:07:19Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:07:19Z'), (b'request-id', b'req_01WPJfjAYxv1CWVj2E7mR6ek'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227b2e8aedee584-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:07:19,815 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:07:19,815 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:07:19,815 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:07:19,815 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:07:19,815 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:07:19,815 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:07:19 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:07:18Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:07:19Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:07:19Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:07:19Z', 'request-id': 'req_01WPJfjAYxv1CWVj2E7mR6ek', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227b2e8aedee584-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:07:19,816 - anthropic._base_client - DEBUG - request_id: req_01WPJfjAYxv1CWVj2E7mR6ek
2025-03-19 05:07:19,820 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_forecast",
    "parameters": {
        "location": "Paris",
        "forecast_type": "current"
    }
}
```
2025-03-19 05:07:19,821 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_forecast', 'parameters': {'location': 'Paris', 'forecast_type': 'current'}}
2025-03-19 05:07:19,821 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:07:19,821 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:07:19,821 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:07:19,821 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:07:19,821 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:07:19,821 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:07:19,821 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:07:21,844 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:07:21,931 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:07:21,933 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:07:21,943 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': 'Can you tell me the current weather in London?'}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:07:21,947 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:07:21,948 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:07:21,965 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105201950>
2025-03-19 05:07:21,965 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104e23260> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:07:21,986 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104e5da70>
2025-03-19 05:07:21,986 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:07:21,987 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:07:21,987 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:07:21,987 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:07:21,987 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:07:23,094 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:07:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:07:22Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:07:22Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:07:23Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:07:22Z'), (b'request-id', b'req_0151cnYMJE4NteMpWFSMcbdi'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227b2fe9dec7a9e-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:07:23,095 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:07:23,095 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:07:23,095 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:07:23,095 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:07:23,095 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:07:23,095 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:07:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:07:22Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:07:22Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:07:23Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:07:22Z', 'request-id': 'req_0151cnYMJE4NteMpWFSMcbdi', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227b2fe9dec7a9e-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:07:23,095 - anthropic._base_client - DEBUG - request_id: req_0151cnYMJE4NteMpWFSMcbdi
2025-03-19 05:07:23,096 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "get_weather",
    "parameters": {
        "location": "London"
    }
}
```
2025-03-19 05:07:23,096 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:07:23,096 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:07:23,096 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:07:23,096 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:07:23,096 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:07:23,096 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:07:23,096 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:07:23,096 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:07:25,098 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:07:25,116 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:07:25,116 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:07:25,117 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "I'd like to know the weather conditions in Tokyo."}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:07:25,118 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:07:25,118 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:07:25,130 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104e5e190>
2025-03-19 05:07:25,130 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104e23530> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:07:25,143 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104ea5490>
2025-03-19 05:07:25,143 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:07:25,144 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:07:25,144 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:07:25,144 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:07:25,144 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:07:26,366 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:07:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:07:25Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:07:25Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:07:26Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:07:25Z'), (b'request-id', b'req_01SS9SK2u9u3BnYWw1phzi7v'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227b3125cd48a1d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:07:26,366 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:07:26,366 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:07:26,366 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:07:26,366 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:07:26,367 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:07:26,367 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:07:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:07:25Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:07:25Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:07:26Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:07:25Z', 'request-id': 'req_01SS9SK2u9u3BnYWw1phzi7v', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227b3125cd48a1d-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:07:26,367 - anthropic._base_client - DEBUG - request_id: req_01SS9SK2u9u3BnYWw1phzi7v
2025-03-19 05:07:26,367 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_forecast",
    "parameters": {
        "location": "Tokyo, Japan"
    }
}
```
2025-03-19 05:07:26,367 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_forecast', 'parameters': {'location': 'Tokyo, Japan'}}
2025-03-19 05:07:26,367 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:07:26,367 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:07:26,367 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:07:26,367 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:07:26,367 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:07:26,367 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:07:26,367 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:07:26,390 - httpcore.connection - DEBUG - close.started
2025-03-19 05:07:26,391 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:07:26,391 - httpcore.connection - DEBUG - close.started
2025-03-19 05:07:26,391 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:07:26,391 - httpcore.connection - DEBUG - close.started
2025-03-19 05:07:26,391 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:08:55,238 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:08:55,240 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:08:55,279 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:08:55,279 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:08:55,281 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "What's the weather like in Paris today?"}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:08:55,300 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:08:55,301 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:08:55,315 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1078c9fd0>
2025-03-19 05:08:55,315 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10785ec30> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:08:55,331 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1077fe490>
2025-03-19 05:08:55,331 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:08:55,331 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:08:55,331 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:08:55,331 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:08:55,331 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:08:56,647 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:08:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:08:55Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:08:55Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:08:56Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:08:55Z'), (b'request-id', b'req_019WxMWfffY8BSb53dKifXqZ'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227b545fc25d433-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:08:56,647 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:08:56,647 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:08:56,648 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:08:56,648 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:08:56,648 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:08:56,648 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:08:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:08:55Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:08:55Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:08:56Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:08:55Z', 'request-id': 'req_019WxMWfffY8BSb53dKifXqZ', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227b545fc25d433-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:08:56,648 - anthropic._base_client - DEBUG - request_id: req_019WxMWfffY8BSb53dKifXqZ
2025-03-19 05:08:56,652 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_lookup",
    "parameters": {
        "location": "Paris",
        "date": "today"
    }
}
```
2025-03-19 05:08:56,652 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_lookup', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 05:08:56,652 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:08:56,653 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:08:56,653 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:08:56,653 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:08:56,653 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:08:56,653 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:08:56,653 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:08:58,654 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:08:58,672 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:08:58,672 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:08:58,673 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': 'Can you tell me the current weather in London?'}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:08:58,673 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:08:58,673 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:08:58,688 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1079fd950>
2025-03-19 05:08:58,688 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10785f260> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:08:58,704 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107881ba0>
2025-03-19 05:08:58,704 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:08:58,704 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:08:58,705 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:08:58,705 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:08:58,705 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:08:59,857 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:08:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:08:58Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:08:59Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:08:59Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:08:59Z'), (b'request-id', b'req_01CH5tm1yozALpFHfggA97qP'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227b55b1e3e730a-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:08:59,858 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:08:59,858 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:08:59,858 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:08:59,858 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:08:59,858 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:08:59,858 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:08:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:08:58Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:08:59Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:08:59Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:08:59Z', 'request-id': 'req_01CH5tm1yozALpFHfggA97qP', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227b55b1e3e730a-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:08:59,858 - anthropic._base_client - DEBUG - request_id: req_01CH5tm1yozALpFHfggA97qP
2025-03-19 05:08:59,858 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_lookup",
    "parameters": {
        "location": "London"
    }
}
```
2025-03-19 05:08:59,858 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_lookup', 'parameters': {'location': 'London'}}
2025-03-19 05:08:59,858 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:08:59,858 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:08:59,858 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:08:59,859 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:08:59,859 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:08:59,859 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:08:59,859 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:09:01,861 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:09:01,879 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:09:01,879 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:09:01,880 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "I'd like to know the weather conditions in Tokyo."}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:09:01,880 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:09:01,881 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:09:01,894 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1078822c0>
2025-03-19 05:09:01,894 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10785f530> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:09:01,910 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1078e1490>
2025-03-19 05:09:01,910 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:09:01,910 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:09:01,910 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:09:01,910 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:09:01,910 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:09:03,711 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:09:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:09:02Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:09:02Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:09:03Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:09:02Z'), (b'request-id', b'req_01DJpZTejAup45h38no1Mt32'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227b56f1fc4d42f-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:09:03,711 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:09:03,711 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:09:03,712 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:09:03,712 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:09:03,712 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:09:03,712 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:09:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:09:02Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:09:02Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:09:03Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:09:02Z', 'request-id': 'req_01DJpZTejAup45h38no1Mt32', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227b56f1fc4d42f-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:09:03,712 - anthropic._base_client - DEBUG - request_id: req_01DJpZTejAup45h38no1Mt32
2025-03-19 05:09:03,712 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_forecast",
    "parameters": {
        "location": "Tokyo"
    }
}
```
2025-03-19 05:09:03,712 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_forecast', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:09:03,712 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:09:03,712 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:09:03,712 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:09:03,712 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:09:03,712 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:09:03,712 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:09:03,712 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:09:03,731 - httpcore.connection - DEBUG - close.started
2025-03-19 05:09:03,732 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:09:03,732 - httpcore.connection - DEBUG - close.started
2025-03-19 05:09:03,732 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:09:03,732 - httpcore.connection - DEBUG - close.started
2025-03-19 05:09:03,732 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:09:44,012 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:09:44,014 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:09:44,051 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:09:44,051 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:09:44,053 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "What's the weather like in Paris today?"}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:09:44,073 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:09:44,073 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:09:44,086 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105469fd0>
2025-03-19 05:09:44,086 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1053faba0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:09:44,100 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10538a5d0>
2025-03-19 05:09:44,100 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:09:44,100 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:09:44,100 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:09:44,100 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:09:44,100 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:09:45,529 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:09:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:09:44Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:09:44Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:09:45Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:09:44Z'), (b'request-id', b'req_01Jo7w5xY4MwpQJfE9sQ7P16'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227b676caaae588-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:09:45,529 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:09:45,529 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:09:45,530 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:09:45,530 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:09:45,530 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:09:45,530 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:09:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:09:44Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:09:44Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:09:45Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:09:44Z', 'request-id': 'req_01Jo7w5xY4MwpQJfE9sQ7P16', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227b676caaae588-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:09:45,530 - anthropic._base_client - DEBUG - request_id: req_01Jo7w5xY4MwpQJfE9sQ7P16
2025-03-19 05:09:45,534 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_forecast",
    "parameters": {
        "location": "Paris",
        "date": "today"
    }
}
```
2025-03-19 05:09:45,534 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_forecast', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 05:09:45,534 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:09:45,534 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:09:45,534 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:09:45,534 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:09:45,534 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:09:45,534 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:09:45,534 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:09:47,536 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:09:47,554 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:09:47,554 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:09:47,555 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': 'Can you tell me the current weather in London?'}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:09:47,555 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:09:47,555 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:09:47,566 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105599a90>
2025-03-19 05:09:47,566 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1053fb1d0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:09:47,578 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105421cd0>
2025-03-19 05:09:47,578 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:09:47,578 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:09:47,578 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:09:47,578 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:09:47,578 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:09:48,718 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:09:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:09:47Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:09:47Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:09:48Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:09:47Z'), (b'request-id', b'req_019MPD1V7vbwJGSeQ6GQmAiY'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227b68c8983d432-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:09:48,719 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:09:48,719 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:09:48,719 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:09:48,719 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:09:48,719 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:09:48,719 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:09:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:09:47Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:09:47Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:09:48Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:09:47Z', 'request-id': 'req_019MPD1V7vbwJGSeQ6GQmAiY', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227b68c8983d432-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:09:48,719 - anthropic._base_client - DEBUG - request_id: req_019MPD1V7vbwJGSeQ6GQmAiY
2025-03-19 05:09:48,720 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_lookup",
    "parameters": {
        "location": "London"
    }
}
```
2025-03-19 05:09:48,720 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_lookup', 'parameters': {'location': 'London'}}
2025-03-19 05:09:48,720 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:09:48,720 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:09:48,720 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:09:48,720 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:09:48,720 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:09:48,720 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:09:48,720 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:09:50,722 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:09:50,739 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:09:50,739 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:09:50,740 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "I'd like to know the weather conditions in Tokyo."}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:09:50,740 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:09:50,740 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:09:50,750 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1054223f0>
2025-03-19 05:09:50,750 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1053fb4a0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:09:50,764 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1054815b0>
2025-03-19 05:09:50,764 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:09:50,764 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:09:50,764 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:09:50,764 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:09:50,764 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:09:51,979 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:09:51 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:09:50Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:09:51Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:09:51Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:09:51Z'), (b'request-id', b'req_01MHyKizeCYweXpZQFftcfJF'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227b6a07ab8d433-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:09:51,980 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:09:51,980 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:09:51,980 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:09:51,980 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:09:51,980 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:09:51,980 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:09:51 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:09:50Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:09:51Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:09:51Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:09:51Z', 'request-id': 'req_01MHyKizeCYweXpZQFftcfJF', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227b6a07ab8d433-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:09:51,980 - anthropic._base_client - DEBUG - request_id: req_01MHyKizeCYweXpZQFftcfJF
2025-03-19 05:09:51,981 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_lookup",
    "parameters": {
        "location": "Tokyo"
    }
}
```
2025-03-19 05:09:51,981 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_lookup', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:09:51,981 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:09:51,981 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:09:51,981 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:09:51,981 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:09:51,981 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:09:51,981 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:09:51,981 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:09:51,999 - httpcore.connection - DEBUG - close.started
2025-03-19 05:09:52,000 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:09:52,000 - httpcore.connection - DEBUG - close.started
2025-03-19 05:09:52,000 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:09:52,000 - httpcore.connection - DEBUG - close.started
2025-03-19 05:09:52,000 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:10:41,763 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:10:41,765 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:10:41,803 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:10:41,803 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:10:41,804 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "What's the weather like in Paris today?"}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:10:41,821 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:10:41,822 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:10:41,866 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104392120>
2025-03-19 05:10:41,866 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104322c30> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:10:41,881 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1041c2490>
2025-03-19 05:10:41,881 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:10:41,882 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:10:41,882 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:10:41,882 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:10:41,882 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:10:43,268 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:10:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:10:42Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:10:42Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:10:43Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:10:42Z'), (b'request-id', b'req_01XqJ5RqCANzp3M2RNyqQqgm'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227b7dfe922fa4b-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:10:43,269 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:10:43,269 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:10:43,269 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:10:43,269 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:10:43,269 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:10:43,269 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:10:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:10:42Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:10:42Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:10:43Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:10:42Z', 'request-id': 'req_01XqJ5RqCANzp3M2RNyqQqgm', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227b7dfe922fa4b-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:10:43,270 - anthropic._base_client - DEBUG - request_id: req_01XqJ5RqCANzp3M2RNyqQqgm
2025-03-19 05:10:43,272 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_forecast",
    "parameters": {
        "location": "Paris",
        "time": "today"
    }
}
```
2025-03-19 05:10:43,272 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_forecast', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:10:43,273 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:10:43,273 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:10:43,273 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:10:43,273 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:10:43,273 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:10:43,273 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:10:43,273 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:10:45,274 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:10:45,292 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:10:45,293 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:10:45,294 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': 'Can you tell me the current weather in London?'}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:10:45,294 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:10:45,294 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:10:45,304 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104601950>
2025-03-19 05:10:45,304 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104323260> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:10:45,317 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104345cd0>
2025-03-19 05:10:45,317 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:10:45,317 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:10:45,317 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:10:45,318 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:10:45,318 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:10:46,443 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:10:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:10:45Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:10:45Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:10:46Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:10:45Z'), (b'request-id', b'req_01PFT2SaWKwKz5iA8S6WsWTD'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227b7f56afad42d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:10:46,443 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:10:46,443 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:10:46,443 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:10:46,443 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:10:46,443 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:10:46,444 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:10:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:10:45Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:10:45Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:10:46Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:10:45Z', 'request-id': 'req_01PFT2SaWKwKz5iA8S6WsWTD', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227b7f56afad42d-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:10:46,444 - anthropic._base_client - DEBUG - request_id: req_01PFT2SaWKwKz5iA8S6WsWTD
2025-03-19 05:10:46,444 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_lookup",
    "parameters": {
        "location": "London"
    }
}
```
2025-03-19 05:10:46,444 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_lookup', 'parameters': {'location': 'London'}}
2025-03-19 05:10:46,444 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:10:46,444 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:10:46,444 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:10:46,444 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:10:46,444 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:10:46,444 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:10:46,444 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:10:48,446 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:10:48,464 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:10:48,464 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:10:48,465 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': [{'type': 'text', 'text': "I'd like to know the weather conditions in Tokyo."}]}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an assistant that helps interpret natural language requests into structured commands.\n        \n        First, determine the capability needed for the request (weather, search, etc.).\n        Then, identify the specific tool needed and required parameters.\n        \n        Format your response as JSON with these fields:\n        {\n            "capability": "the capability name",\n            "tool_name": "the tool name",\n            "parameters": {\n                "param1": "value1",\n                "param2": "value2"\n            }\n        }\n        \n        Think carefully about what the user is actually asking for and format your response\n        precisely as JSON inside ```json code blocks.\n        '}}
2025-03-19 05:10:48,465 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:10:48,465 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:10:48,479 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1043463f0>
2025-03-19 05:10:48,479 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104323530> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:10:48,491 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1043a9490>
2025-03-19 05:10:48,491 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:10:48,491 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:10:48,491 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:10:48,491 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:10:48,491 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:10:49,606 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:10:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:10:48Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:10:48Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:10:49Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:10:48Z'), (b'request-id', b'req_01ViHspWAqHjev6a5WHjpGSo'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227b8093c19d433-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:10:49,607 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:10:49,607 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:10:49,608 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:10:49,608 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:10:49,608 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:10:49,608 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:10:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:10:48Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:10:48Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:10:49Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:10:48Z', 'request-id': 'req_01ViHspWAqHjev6a5WHjpGSo', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227b8093c19d433-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:10:49,608 - anthropic._base_client - DEBUG - request_id: req_01ViHspWAqHjev6a5WHjpGSo
2025-03-19 05:10:49,608 - state_of_mika.adapters.claude - DEBUG - Claude response: ```json
{
    "capability": "weather",
    "tool_name": "weather_api",
    "parameters": {
        "location": "Tokyo"
    }
}
```
2025-03-19 05:10:49,608 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'weather_api', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:10:49,608 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:10:49,608 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:10:49,608 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:10:49,608 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:10:49,608 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:10:49,608 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:10:49,608 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:10:49,627 - httpcore.connection - DEBUG - close.started
2025-03-19 05:10:49,628 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:10:49,628 - httpcore.connection - DEBUG - close.started
2025-03-19 05:10:49,628 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:10:49,628 - httpcore.connection - DEBUG - close.started
2025-03-19 05:10:49,628 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:11:29,075 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:11:29,077 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:11:29,117 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:11:29,118 - __main__ - ERROR - Error processing request: 'ClaudeAdapter' object has no attribute 'logger'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/real_world_test.py", line 124, in run_real_test
    response = await adapter.process_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 138, in process_request
    self.logger.info("Using mock data for request: %s", request)
    ^^^^^^^^^^^
AttributeError: 'ClaudeAdapter' object has no attribute 'logger'
2025-03-19 05:11:29,118 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:11:31,120 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:11:31,137 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:11:31,138 - __main__ - ERROR - Error processing request: 'ClaudeAdapter' object has no attribute 'logger'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/real_world_test.py", line 124, in run_real_test
    response = await adapter.process_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 138, in process_request
    self.logger.info("Using mock data for request: %s", request)
    ^^^^^^^^^^^
AttributeError: 'ClaudeAdapter' object has no attribute 'logger'
2025-03-19 05:11:31,138 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:11:33,140 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:11:33,156 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:11:33,156 - __main__ - ERROR - Error processing request: 'ClaudeAdapter' object has no attribute 'logger'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/real_world_test.py", line 124, in run_real_test
    response = await adapter.process_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 138, in process_request
    self.logger.info("Using mock data for request: %s", request)
    ^^^^^^^^^^^
AttributeError: 'ClaudeAdapter' object has no attribute 'logger'
2025-03-19 05:11:33,157 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:12:16,182 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:12:16,184 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:12:16,226 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:12:16,226 - state_of_mika.adapters.claude - INFO - Using mock data for request: What's the weather like in Paris today?
2025-03-19 05:12:16,226 - __main__ - ERROR - Error processing request: ClaudeAdapter.process_request() takes 2 positional arguments but 3 were given
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/real_world_test.py", line 133, in run_real_test
    chat_response = await adapter.chat(request)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 245, in chat
    result = await self.process_request(message, image_path)
                   ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
TypeError: ClaudeAdapter.process_request() takes 2 positional arguments but 3 were given
2025-03-19 05:12:16,227 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:12:18,229 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:12:18,246 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:12:18,246 - state_of_mika.adapters.claude - INFO - Using mock data for request: Can you tell me the current weather in London?
2025-03-19 05:12:18,246 - __main__ - ERROR - Error processing request: ClaudeAdapter.process_request() takes 2 positional arguments but 3 were given
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/real_world_test.py", line 133, in run_real_test
    chat_response = await adapter.chat(request)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 245, in chat
    result = await self.process_request(message, image_path)
                   ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
TypeError: ClaudeAdapter.process_request() takes 2 positional arguments but 3 were given
2025-03-19 05:12:18,246 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:12:20,248 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:12:20,265 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:12:20,265 - state_of_mika.adapters.claude - INFO - Using mock data for request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:12:20,265 - __main__ - ERROR - Error processing request: ClaudeAdapter.process_request() takes 2 positional arguments but 3 were given
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/real_world_test.py", line 133, in run_real_test
    chat_response = await adapter.chat(request)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 245, in chat
    result = await self.process_request(message, image_path)
                   ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^
TypeError: ClaudeAdapter.process_request() takes 2 positional arguments but 3 were given
2025-03-19 05:12:20,265 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:13:04,154 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:13:04,156 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:13:04,195 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:13:04,195 - state_of_mika.adapters.claude - INFO - Using mock data for request: What's the weather like in Paris today?
2025-03-19 05:13:04,195 - state_of_mika.adapters.claude - INFO - Using mock data for request: What's the weather like in Paris today?
2025-03-19 05:13:04,195 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:13:06,197 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:13:06,224 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:13:06,224 - state_of_mika.adapters.claude - INFO - Using mock data for request: Can you tell me the current weather in London?
2025-03-19 05:13:06,224 - state_of_mika.adapters.claude - INFO - Using mock data for request: Can you tell me the current weather in London?
2025-03-19 05:13:06,224 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:13:08,253 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:13:08,280 - state_of_mika.adapters.claude - DEBUG - ClaudeAdapter initialized with model: claude-3-sonnet-20240229
2025-03-19 05:13:08,280 - state_of_mika.adapters.claude - INFO - Using mock data for request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:13:08,280 - state_of_mika.adapters.claude - INFO - Using mock data for request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:13:08,280 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:13:18,462 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:13:18,462 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:13:18,465 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:13:18,465 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:13:18,466 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:13:18,466 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:13:49,235 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:13:49,235 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:13:49,236 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:13:49,236 - state_of_mika.adapters.claude - INFO - Using mock data for request: I need to search for information about quantum computing.
2025-03-19 05:13:49,236 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:13:49,238 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:13:49,238 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:13:49,238 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:13:49,238 - state_of_mika.adapters.claude - INFO - Using mock data for request: Can you tell me the current time in Tokyo?
2025-03-19 05:13:49,238 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:13:49,239 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:13:49,240 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:13:49,240 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:13:49,240 - state_of_mika.adapters.claude - INFO - Using mock data for request: What's the weather like in Paris today?
2025-03-19 05:13:49,240 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:15:06,898 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:15:06,898 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:15:06,898 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:15:06,898 - state_of_mika.adapters.claude - INFO - Using mock data for request: I need to search for information about quantum computing.
2025-03-19 05:15:06,899 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:15:06,899 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:15:06,899 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:15:06,899 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:15:06,899 - state_of_mika.adapters.claude - INFO - Using mock data for request: Can you tell me the current time in Tokyo?
2025-03-19 05:15:06,899 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:15:06,899 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:15:06,899 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:15:06,900 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:15:06,900 - state_of_mika.adapters.claude - INFO - Using mock data for request: What's the weather like in Paris today?
2025-03-19 05:15:06,900 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:15:15,868 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:15:15,869 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:15:15,870 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:15:15,870 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:15:15,873 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:15:15,873 - process - INFO - Start time: 2025-03-19 05:15:15
2025-03-19 05:15:15,873 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:15:15,873 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:15:15,873 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 05:15:15,873 - state_of_mika.adapters.claude - INFO - Using mock data for request: What's the weather like in Paris today?
2025-03-19 05:15:15,873 - result - INFO - Request processing completed successfully
2025-03-19 05:15:15,873 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "Paris"
  },
  "result": {
    "temperature": 22,
    "condition": "Sunny",
    "humidity": 65,
    "location": "Paris"
  }
}
2025-03-19 05:15:15,873 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:15:15,873 - process - INFO - End time: 2025-03-19 05:15:15
2025-03-19 05:15:15,873 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:15:15,873 - process - INFO - Start time: 2025-03-19 05:15:15
2025-03-19 05:15:15,873 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:15:15,873 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:15:15,873 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 05:15:15,873 - state_of_mika.adapters.claude - INFO - Using mock data for request: Can you tell me the current weather in London?
2025-03-19 05:15:15,874 - result - INFO - Request processing completed successfully
2025-03-19 05:15:15,874 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "London"
  },
  "result": {
    "temperature": 18,
    "condition": "Cloudy",
    "humidity": 75,
    "location": "London"
  }
}
2025-03-19 05:15:15,874 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:15:15,874 - process - INFO - End time: 2025-03-19 05:15:15
2025-03-19 05:15:15,874 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:15:15,874 - process - INFO - Start time: 2025-03-19 05:15:15
2025-03-19 05:15:15,874 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:15:15,874 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:15:15,874 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 05:15:15,874 - state_of_mika.adapters.claude - INFO - Using mock data for request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:15:15,874 - result - INFO - Request processing completed successfully
2025-03-19 05:15:15,874 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "Tokyo"
  },
  "result": {
    "temperature": 28,
    "condition": "Partly Cloudy",
    "humidity": 60,
    "location": "Tokyo"
  }
}
2025-03-19 05:15:15,874 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:15:15,874 - process - INFO - End time: 2025-03-19 05:15:15
2025-03-19 05:15:47,976 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:15:47,978 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:15:47,978 - process - INFO - Start time: 2025-03-19 05:15:47
2025-03-19 05:15:47,979 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:15:47,979 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:15:47,979 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 05:15:47,979 - state_of_mika.adapters.claude - INFO - Using mock data for request: What's the weather like in Paris today?
2025-03-19 05:15:47,979 - result - INFO - Request processing completed successfully
2025-03-19 05:15:47,979 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "Paris"
  },
  "result": {
    "temperature": 22,
    "condition": "Sunny",
    "humidity": 65,
    "location": "Paris"
  }
}
2025-03-19 05:15:47,979 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:15:47,979 - process - INFO - End time: 2025-03-19 05:15:47
2025-03-19 05:15:47,979 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:15:47,979 - process - INFO - Start time: 2025-03-19 05:15:47
2025-03-19 05:15:47,981 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:15:47,981 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:15:47,981 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 05:15:47,981 - state_of_mika.adapters.claude - INFO - Using mock data for request: Can you tell me the current weather in London?
2025-03-19 05:15:47,981 - result - INFO - Request processing completed successfully
2025-03-19 05:15:47,981 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "London"
  },
  "result": {
    "temperature": 18,
    "condition": "Cloudy",
    "humidity": 75,
    "location": "London"
  }
}
2025-03-19 05:15:47,982 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:15:47,982 - process - INFO - End time: 2025-03-19 05:15:47
2025-03-19 05:15:47,982 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:15:47,982 - process - INFO - Start time: 2025-03-19 05:15:47
2025-03-19 05:15:47,984 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:15:47,985 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:15:47,985 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 05:15:47,985 - state_of_mika.adapters.claude - INFO - Using mock data for request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:15:47,985 - result - INFO - Request processing completed successfully
2025-03-19 05:15:47,985 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "Tokyo"
  },
  "result": {
    "temperature": 28,
    "condition": "Partly Cloudy",
    "humidity": 60,
    "location": "Tokyo"
  }
}
2025-03-19 05:15:47,985 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:15:47,985 - process - INFO - End time: 2025-03-19 05:15:47
2025-03-19 05:16:37,846 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:16:37,847 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:16:37,847 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:16:37,849 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:16:37,849 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:16:37,851 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:16:37,851 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:16:37,852 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:16:37,852 - process - INFO - Start time: 2025-03-19 05:16:37
2025-03-19 05:16:37,852 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:16:37,852 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:16:37,852 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 05:16:37,852 - state_of_mika.adapters.claude - INFO - Using mock data for request: What's the weather like in Paris today?
2025-03-19 05:16:37,852 - result - INFO - Request processing completed successfully
2025-03-19 05:16:37,852 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "Paris"
  },
  "result": {
    "temperature": 22,
    "condition": "Sunny",
    "humidity": 65,
    "location": "Paris"
  }
}
2025-03-19 05:16:37,852 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:16:37,852 - process - INFO - End time: 2025-03-19 05:16:37
2025-03-19 05:16:37,852 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:16:37,852 - process - INFO - Start time: 2025-03-19 05:16:37
2025-03-19 05:16:37,853 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:16:37,853 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:16:37,853 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 05:16:37,853 - state_of_mika.adapters.claude - INFO - Using mock data for request: Can you tell me the current weather in London?
2025-03-19 05:16:37,853 - result - INFO - Request processing completed successfully
2025-03-19 05:16:37,853 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "London"
  },
  "result": {
    "temperature": 18,
    "condition": "Cloudy",
    "humidity": 75,
    "location": "London"
  }
}
2025-03-19 05:16:37,853 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:16:37,853 - process - INFO - End time: 2025-03-19 05:16:37
2025-03-19 05:16:37,853 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:16:37,853 - process - INFO - Start time: 2025-03-19 05:16:37
2025-03-19 05:16:37,854 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:16:37,854 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:16:37,854 - process - INFO - Sending request to Claude adapter for processing
2025-03-19 05:16:37,854 - state_of_mika.adapters.claude - INFO - Using mock data for request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:16:37,854 - result - INFO - Request processing completed successfully
2025-03-19 05:16:37,854 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "Tokyo"
  },
  "result": {
    "temperature": 28,
    "condition": "Partly Cloudy",
    "humidity": 60,
    "location": "Tokyo"
  }
}
2025-03-19 05:16:37,854 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:16:37,854 - process - INFO - End time: 2025-03-19 05:16:37
2025-03-19 05:17:17,135 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:17:17,136 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:17,136 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:17,136 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:17,136 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:17:17,136 - process - INFO - Start time: 2025-03-19 05:17:17
2025-03-19 05:17:17,137 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:17,137 - process - ERROR - Error processing request: 'ClaudeAdapter' object has no attribute 'api_key'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 103, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 75, in setup
    if not self.api_key and not self.testing_mode:
           ^^^^^^^^^^^^
AttributeError: 'ClaudeAdapter' object has no attribute 'api_key'
2025-03-19 05:17:17,137 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:17:17,137 - process - INFO - End time: 2025-03-19 05:17:17
2025-03-19 05:17:17,137 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:17:17,137 - process - INFO - Start time: 2025-03-19 05:17:17
2025-03-19 05:17:17,137 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:17,138 - process - ERROR - Error processing request: 'ClaudeAdapter' object has no attribute 'api_key'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 103, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 75, in setup
    if not self.api_key and not self.testing_mode:
           ^^^^^^^^^^^^
AttributeError: 'ClaudeAdapter' object has no attribute 'api_key'
2025-03-19 05:17:17,138 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:17:17,138 - process - INFO - End time: 2025-03-19 05:17:17
2025-03-19 05:17:17,138 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:17:17,138 - process - INFO - Start time: 2025-03-19 05:17:17
2025-03-19 05:17:17,138 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:17,138 - process - ERROR - Error processing request: 'ClaudeAdapter' object has no attribute 'api_key'
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 103, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 75, in setup
    if not self.api_key and not self.testing_mode:
           ^^^^^^^^^^^^
AttributeError: 'ClaudeAdapter' object has no attribute 'api_key'
2025-03-19 05:17:17,138 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:17:17,138 - process - INFO - End time: 2025-03-19 05:17:17
2025-03-19 05:17:44,556 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:17:44,557 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:44,557 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:44,558 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:44,558 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:17:44,558 - process - INFO - Start time: 2025-03-19 05:17:44
2025-03-19 05:17:44,558 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:44,558 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:44,558 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 103, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 94, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:17:44,559 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:17:44,559 - process - INFO - End time: 2025-03-19 05:17:44
2025-03-19 05:17:44,559 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:17:44,559 - process - INFO - Start time: 2025-03-19 05:17:44
2025-03-19 05:17:44,559 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:44,559 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:44,559 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 103, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 94, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:17:44,559 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:17:44,559 - process - INFO - End time: 2025-03-19 05:17:44
2025-03-19 05:17:44,560 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:17:44,560 - process - INFO - Start time: 2025-03-19 05:17:44
2025-03-19 05:17:44,560 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:44,560 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:17:44,560 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 103, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 94, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:17:44,560 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:17:44,560 - process - INFO - End time: 2025-03-19 05:17:44
2025-03-19 05:20:04,630 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:20:04,631 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:20:04,632 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:20:04,632 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:20:04,632 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:20:04,632 - process - INFO - Start time: 2025-03-19 05:20:04
2025-03-19 05:20:04,632 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:20:04,632 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 108, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 94, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:20:04,633 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:20:04,633 - process - INFO - End time: 2025-03-19 05:20:04
2025-03-19 05:20:04,634 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:20:04,634 - process - INFO - Start time: 2025-03-19 05:20:04
2025-03-19 05:20:04,634 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:20:04,634 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 108, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 94, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:20:04,634 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:20:04,634 - process - INFO - End time: 2025-03-19 05:20:04
2025-03-19 05:20:04,634 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:20:04,634 - process - INFO - Start time: 2025-03-19 05:20:04
2025-03-19 05:20:04,634 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:20:04,634 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 108, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 94, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:20:04,635 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:20:04,635 - process - INFO - End time: 2025-03-19 05:20:04
2025-03-19 05:20:44,870 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:20:44,871 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:20:44,871 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:20:44,871 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:20:44,872 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:20:44,872 - process - INFO - Start time: 2025-03-19 05:20:44
2025-03-19 05:20:44,872 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:20:44,872 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 108, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 93, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:20:44,873 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:20:44,873 - process - INFO - End time: 2025-03-19 05:20:44
2025-03-19 05:20:44,873 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:20:44,873 - process - INFO - Start time: 2025-03-19 05:20:44
2025-03-19 05:20:44,873 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:20:44,873 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 108, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 93, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:20:44,873 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:20:44,873 - process - INFO - End time: 2025-03-19 05:20:44
2025-03-19 05:20:44,873 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:20:44,873 - process - INFO - Start time: 2025-03-19 05:20:44
2025-03-19 05:20:44,873 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:20:44,873 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 108, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 93, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:20:44,874 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:20:44,874 - process - INFO - End time: 2025-03-19 05:20:44
2025-03-19 05:21:34,141 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:21:34,143 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:21:34,143 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:21:34,143 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:21:34,144 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:21:34,144 - process - INFO - Start time: 2025-03-19 05:21:34
2025-03-19 05:21:34,144 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:21:34,144 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 110, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 93, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:21:34,145 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:21:34,145 - process - INFO - End time: 2025-03-19 05:21:34
2025-03-19 05:21:34,145 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:21:34,145 - process - INFO - Start time: 2025-03-19 05:21:34
2025-03-19 05:21:34,145 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:21:34,145 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 110, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 93, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:21:34,145 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:21:34,145 - process - INFO - End time: 2025-03-19 05:21:34
2025-03-19 05:21:34,145 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:21:34,145 - process - INFO - Start time: 2025-03-19 05:21:34
2025-03-19 05:21:34,146 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:21:34,146 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 110, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 93, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:21:34,146 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:21:34,146 - process - INFO - End time: 2025-03-19 05:21:34
2025-03-19 05:22:12,468 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:22:12,470 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:22:12,470 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:22:12,470 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:22:12,470 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:22:12,470 - process - INFO - Start time: 2025-03-19 05:22:12
2025-03-19 05:22:12,470 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:22:12,470 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 189, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 93, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:22:12,471 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:22:12,471 - process - INFO - End time: 2025-03-19 05:22:12
2025-03-19 05:22:12,471 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:22:12,471 - process - INFO - Start time: 2025-03-19 05:22:12
2025-03-19 05:22:12,471 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:22:12,471 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 189, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 93, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:22:12,471 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:22:12,471 - process - INFO - End time: 2025-03-19 05:22:12
2025-03-19 05:22:12,471 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:22:12,471 - process - INFO - Start time: 2025-03-19 05:22:12
2025-03-19 05:22:12,471 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:22:12,471 - process - ERROR - Error processing request: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 189, in process_llm_request
    await adapter.setup()
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/state_of_mika/adapters/claude.py", line 93, in setup
    raise ValueError(
        "ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter"
    )
ValueError: ANTHROPIC_API_KEY environment variable is required for ClaudeAdapter
2025-03-19 05:22:12,472 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:22:12,472 - process - INFO - End time: 2025-03-19 05:22:12
2025-03-19 05:22:23,132 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:22:23,133 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:22:23,133 - process - INFO - Start time: 2025-03-19 05:22:23
2025-03-19 05:22:23,133 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:22:23,133 - mock - INFO - MockClaudeAdapter initialized in testing mode
2025-03-19 05:22:23,133 - process - INFO - Sending request to adapter for processing
2025-03-19 05:22:23,133 - mock - INFO - Processing request with mock data: What's the weather like in Paris today?
2025-03-19 05:22:23,134 - result - INFO - Request processing completed successfully
2025-03-19 05:22:23,134 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "Paris"
  },
  "result": {
    "temperature": 22,
    "condition": "Sunny",
    "humidity": 65,
    "location": "Paris"
  }
}
2025-03-19 05:22:23,134 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:22:23,134 - process - INFO - End time: 2025-03-19 05:22:23
2025-03-19 05:22:23,134 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:22:23,134 - process - INFO - Start time: 2025-03-19 05:22:23
2025-03-19 05:22:23,134 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:22:23,134 - mock - INFO - MockClaudeAdapter initialized in testing mode
2025-03-19 05:22:23,134 - process - INFO - Sending request to adapter for processing
2025-03-19 05:22:23,134 - mock - INFO - Processing request with mock data: Can you tell me the current weather in London?
2025-03-19 05:22:23,134 - result - INFO - Request processing completed successfully
2025-03-19 05:22:23,134 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "London"
  },
  "result": {
    "temperature": 18,
    "condition": "Cloudy",
    "humidity": 75,
    "location": "London"
  }
}
2025-03-19 05:22:23,134 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:22:23,134 - process - INFO - End time: 2025-03-19 05:22:23
2025-03-19 05:22:23,134 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:22:23,134 - process - INFO - Start time: 2025-03-19 05:22:23
2025-03-19 05:22:23,134 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:22:23,134 - mock - INFO - MockClaudeAdapter initialized in testing mode
2025-03-19 05:22:23,134 - process - INFO - Sending request to adapter for processing
2025-03-19 05:22:23,134 - mock - INFO - Processing request with mock data: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:22:23,134 - result - INFO - Request processing completed successfully
2025-03-19 05:22:23,134 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "Tokyo"
  },
  "result": {
    "temperature": 28,
    "condition": "Partly Cloudy",
    "humidity": 60,
    "location": "Tokyo"
  }
}
2025-03-19 05:22:23,134 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:22:23,134 - process - INFO - End time: 2025-03-19 05:22:23
2025-03-19 05:23:39,806 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:23:39,809 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:23:39,809 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:23:39,809 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:23:40,346 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:23:40,346 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:23:40,346 - process - INFO - Start time: 2025-03-19 05:23:40
2025-03-19 05:23:40,347 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:23:40,347 - mock - INFO - MockClaudeAdapter initialized in testing mode
2025-03-19 05:23:40,347 - process - INFO - Sending request to adapter for processing
2025-03-19 05:23:40,347 - mock - INFO - Processing request with mock data: What's the weather like in Paris today?
2025-03-19 05:23:40,347 - result - INFO - Request processing completed successfully
2025-03-19 05:23:40,347 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "Paris"
  },
  "result": {
    "temperature": 22,
    "condition": "Sunny",
    "humidity": 65,
    "location": "Paris"
  }
}
2025-03-19 05:23:40,347 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:23:40,347 - process - INFO - End time: 2025-03-19 05:23:40
2025-03-19 05:23:40,347 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:23:40,347 - process - INFO - Start time: 2025-03-19 05:23:40
2025-03-19 05:23:40,347 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:23:40,347 - mock - INFO - MockClaudeAdapter initialized in testing mode
2025-03-19 05:23:40,347 - process - INFO - Sending request to adapter for processing
2025-03-19 05:23:40,347 - mock - INFO - Processing request with mock data: Can you tell me the current weather in London?
2025-03-19 05:23:40,347 - result - INFO - Request processing completed successfully
2025-03-19 05:23:40,347 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "London"
  },
  "result": {
    "temperature": 18,
    "condition": "Cloudy",
    "humidity": 75,
    "location": "London"
  }
}
2025-03-19 05:23:40,347 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:23:40,347 - process - INFO - End time: 2025-03-19 05:23:40
2025-03-19 05:23:40,347 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:23:40,347 - process - INFO - Start time: 2025-03-19 05:23:40
2025-03-19 05:23:40,347 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:23:40,347 - mock - INFO - MockClaudeAdapter initialized in testing mode
2025-03-19 05:23:40,347 - process - INFO - Sending request to adapter for processing
2025-03-19 05:23:40,347 - mock - INFO - Processing request with mock data: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:23:40,347 - result - INFO - Request processing completed successfully
2025-03-19 05:23:40,347 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "Tokyo"
  },
  "result": {
    "temperature": 28,
    "condition": "Partly Cloudy",
    "humidity": 60,
    "location": "Tokyo"
  }
}
2025-03-19 05:23:40,347 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:23:40,347 - process - INFO - End time: 2025-03-19 05:23:40
2025-03-19 05:26:03,140 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:26:03,142 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:26:03,142 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:26:03,142 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: <state_of_mika.connector.Connector object at 0x103eac830>
2025-03-19 05:26:03,182 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:26:03,182 - state_of_mika.adapters.claude - ERROR - Error processing request: 'ClaudeAdapter' object has no attribute '_structure_request'
2025-03-19 05:26:03,182 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:26:05,184 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:26:05,184 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:26:05,184 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: <state_of_mika.connector.Connector object at 0x103e88690>
2025-03-19 05:26:05,201 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:26:05,201 - state_of_mika.adapters.claude - ERROR - Error processing request: 'ClaudeAdapter' object has no attribute '_structure_request'
2025-03-19 05:26:05,201 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:26:07,203 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:26:07,203 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:26:07,203 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: <state_of_mika.connector.Connector object at 0x103f490f0>
2025-03-19 05:26:07,220 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:26:07,220 - state_of_mika.adapters.claude - ERROR - Error processing request: 'ClaudeAdapter' object has no attribute '_structure_request'
2025-03-19 05:26:07,221 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:28:11,480 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:28:11,483 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:28:11,483 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:28:11,483 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:28:11,483 - state_of_mika.adapters.claude - INFO - Using mock data for request: What's the weather like in Paris today?
2025-03-19 05:28:11,483 - state_of_mika.adapters.claude - INFO - Using mock data for request: What's the weather like in Paris today?
2025-03-19 05:28:11,483 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:28:13,485 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:28:13,485 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:28:13,485 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:28:13,485 - state_of_mika.adapters.claude - INFO - Using mock data for request: Can you tell me the current weather in London?
2025-03-19 05:28:13,485 - state_of_mika.adapters.claude - INFO - Using mock data for request: Can you tell me the current weather in London?
2025-03-19 05:28:13,485 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:28:15,486 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:28:15,486 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:28:15,486 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:28:15,486 - state_of_mika.adapters.claude - INFO - Using mock data for request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:28:15,487 - state_of_mika.adapters.claude - INFO - Using mock data for request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:28:15,487 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:28:48,731 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:28:48,732 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:28:48,732 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:28:48,732 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: <state_of_mika.connector.Connector object at 0x1045c8980>
2025-03-19 05:28:48,767 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:28:48,767 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:28:48,768 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': <state_of_mika.connector.Connector object at 0x1045c8980>, 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:28:48,785 - state_of_mika.adapters.claude - ERROR - Error communicating with Claude API: Object of type Connector is not JSON serializable
2025-03-19 05:28:48,785 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:28:50,787 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:28:50,787 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:28:50,787 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: <state_of_mika.connector.Connector object at 0x1045b0690>
2025-03-19 05:28:50,804 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:28:50,805 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:28:50,805 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': <state_of_mika.connector.Connector object at 0x1045b0690>, 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:28:50,806 - state_of_mika.adapters.claude - ERROR - Error communicating with Claude API: Object of type Connector is not JSON serializable
2025-03-19 05:28:50,806 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:28:52,807 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:28:52,808 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:28:52,808 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: <state_of_mika.connector.Connector object at 0x10476cfc0>
2025-03-19 05:28:52,824 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:28:52,825 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:28:52,825 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': <state_of_mika.connector.Connector object at 0x10476cfc0>, 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:28:52,825 - state_of_mika.adapters.claude - ERROR - Error communicating with Claude API: Object of type Connector is not JSON serializable
2025-03-19 05:28:52,826 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:30:10,305 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:30:10,306 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:30:10,306 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:30:10,306 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: <state_of_mika.connector.Connector object at 0x107bdc980>
2025-03-19 05:30:10,343 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:30:10,343 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:30:10,344 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': <state_of_mika.connector.Connector object at 0x107bdc980>, 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:30:10,366 - state_of_mika.adapters.claude - ERROR - Error communicating with Claude API: Object of type Connector is not JSON serializable
2025-03-19 05:30:10,366 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:30:12,368 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:30:12,368 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:30:12,368 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: <state_of_mika.connector.Connector object at 0x107bc8550>
2025-03-19 05:30:12,386 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:30:12,386 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:30:12,387 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': <state_of_mika.connector.Connector object at 0x107bc8550>, 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:30:12,387 - state_of_mika.adapters.claude - ERROR - Error communicating with Claude API: Object of type Connector is not JSON serializable
2025-03-19 05:30:12,387 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:30:14,389 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:30:14,390 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:30:14,391 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: <state_of_mika.connector.Connector object at 0x107e310f0>
2025-03-19 05:30:14,408 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:30:14,408 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:30:14,408 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': <state_of_mika.connector.Connector object at 0x107e310f0>, 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:30:14,409 - state_of_mika.adapters.claude - ERROR - Error communicating with Claude API: Object of type Connector is not JSON serializable
2025-03-19 05:30:14,409 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:31:13,167 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:31:13,168 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:31:13,168 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:31:13,206 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:31:13,206 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:31:13,207 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:31:13,227 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:31:13,228 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:31:13,268 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10540a270>
2025-03-19 05:31:13,268 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10539ac30> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:31:13,283 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10532a710>
2025-03-19 05:31:13,283 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:31:13,283 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:31:13,283 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:31:13,283 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:31:13,283 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:31:13,631 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 18 Mar 2025 21:31:13 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'86'), (b'Connection', b'keep-alive'), (b'x-should-retry', b'false'), (b'request-id', b'req_011nopYh7jxRfN731qwGYXNF'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227d5f02ce5e547-KUL')])
2025-03-19 05:31:13,632 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 401 Unauthorized"
2025-03-19 05:31:13,632 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:31:13,632 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:31:13,632 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:31:13,632 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:31:13,632 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "401 Unauthorized" Headers({'date': 'Tue, 18 Mar 2025 21:31:13 GMT', 'content-type': 'application/json', 'content-length': '86', 'connection': 'keep-alive', 'x-should-retry': 'false', 'request-id': 'req_011nopYh7jxRfN731qwGYXNF', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227d5f02ce5e547-KUL'})
2025-03-19 05:31:13,632 - anthropic._base_client - DEBUG - request_id: req_011nopYh7jxRfN731qwGYXNF
2025-03-19 05:31:13,632 - anthropic._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1096, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/.venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '401 Unauthorized' for url 'https://api.anthropic.com/v1/messages'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401
2025-03-19 05:31:13,635 - anthropic._base_client - DEBUG - Not retrying as header `x-should-retry` is set to `false`
2025-03-19 05:31:13,635 - anthropic._base_client - DEBUG - Re-raising status error
2025-03-19 05:31:13,635 - state_of_mika.adapters.claude - ERROR - Error communicating with Claude API: Error code: 401 - {'type': 'error', 'error': {'type': 'authentication_error', 'message': 'invalid x-api-key'}}
2025-03-19 05:31:13,635 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:31:15,637 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:31:15,637 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:31:15,654 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:31:15,654 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:31:15,655 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:31:15,655 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:31:15,655 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:31:15,668 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1054d9a90>
2025-03-19 05:31:15,668 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105461250> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:31:15,684 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1053b0e90>
2025-03-19 05:31:15,684 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:31:15,684 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:31:15,684 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:31:15,684 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:31:15,684 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:31:15,988 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 18 Mar 2025 21:31:15 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'86'), (b'Connection', b'keep-alive'), (b'x-should-retry', b'false'), (b'request-id', b'req_01F1mLPVhDxCS7Y7suUM8Hd7'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227d5ff2d05435a-KUL')])
2025-03-19 05:31:15,989 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 401 Unauthorized"
2025-03-19 05:31:15,989 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:31:15,989 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:31:15,989 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:31:15,989 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:31:15,989 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "401 Unauthorized" Headers({'date': 'Tue, 18 Mar 2025 21:31:15 GMT', 'content-type': 'application/json', 'content-length': '86', 'connection': 'keep-alive', 'x-should-retry': 'false', 'request-id': 'req_01F1mLPVhDxCS7Y7suUM8Hd7', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227d5ff2d05435a-KUL'})
2025-03-19 05:31:15,989 - anthropic._base_client - DEBUG - request_id: req_01F1mLPVhDxCS7Y7suUM8Hd7
2025-03-19 05:31:15,989 - anthropic._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1096, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/.venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '401 Unauthorized' for url 'https://api.anthropic.com/v1/messages'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401
2025-03-19 05:31:15,989 - anthropic._base_client - DEBUG - Not retrying as header `x-should-retry` is set to `false`
2025-03-19 05:31:15,990 - anthropic._base_client - DEBUG - Re-raising status error
2025-03-19 05:31:15,990 - state_of_mika.adapters.claude - ERROR - Error communicating with Claude API: Error code: 401 - {'type': 'error', 'error': {'type': 'authentication_error', 'message': 'invalid x-api-key'}}
2025-03-19 05:31:15,990 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:31:17,991 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:31:17,991 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:31:18,010 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:31:18,010 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:31:18,010 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:31:18,011 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:31:18,011 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:31:18,021 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1053b2060>
2025-03-19 05:31:18,022 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10539b380> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:31:18,035 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10540d5b0>
2025-03-19 05:31:18,036 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:31:18,036 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:31:18,036 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:31:18,036 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:31:18,036 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:31:18,286 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 401, b'Unauthorized', [(b'Date', b'Tue, 18 Mar 2025 21:31:18 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'86'), (b'Connection', b'keep-alive'), (b'x-should-retry', b'false'), (b'request-id', b'req_013xezCWQpDadLS9dyZqEA9T'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227d60ddb7ddc17-KUL')])
2025-03-19 05:31:18,286 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 401 Unauthorized"
2025-03-19 05:31:18,286 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:31:18,286 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:31:18,286 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:31:18,286 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:31:18,286 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "401 Unauthorized" Headers({'date': 'Tue, 18 Mar 2025 21:31:18 GMT', 'content-type': 'application/json', 'content-length': '86', 'connection': 'keep-alive', 'x-should-retry': 'false', 'request-id': 'req_013xezCWQpDadLS9dyZqEA9T', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227d60ddb7ddc17-KUL'})
2025-03-19 05:31:18,286 - anthropic._base_client - DEBUG - request_id: req_013xezCWQpDadLS9dyZqEA9T
2025-03-19 05:31:18,286 - anthropic._base_client - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/.venv/lib/python3.13/site-packages/anthropic/_base_client.py", line 1096, in _request
    response.raise_for_status()
    ~~~~~~~~~~~~~~~~~~~~~~~~~^^
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/.venv/lib/python3.13/site-packages/httpx/_models.py", line 829, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '401 Unauthorized' for url 'https://api.anthropic.com/v1/messages'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/401
2025-03-19 05:31:18,287 - anthropic._base_client - DEBUG - Not retrying as header `x-should-retry` is set to `false`
2025-03-19 05:31:18,287 - anthropic._base_client - DEBUG - Re-raising status error
2025-03-19 05:31:18,287 - state_of_mika.adapters.claude - ERROR - Error communicating with Claude API: Error code: 401 - {'type': 'error', 'error': {'type': 'authentication_error', 'message': 'invalid x-api-key'}}
2025-03-19 05:31:18,287 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:31:18,307 - httpcore.connection - DEBUG - close.started
2025-03-19 05:31:18,308 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:31:18,308 - httpcore.connection - DEBUG - close.started
2025-03-19 05:31:18,308 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:31:18,308 - httpcore.connection - DEBUG - close.started
2025-03-19 05:31:18,308 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:31:30,671 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:31:30,673 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:31:30,673 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:31:30,673 - state_of_mika.adapters.claude - INFO - Using mock data for request: What's the weather like in Paris today?
2025-03-19 05:31:30,673 - state_of_mika.adapters.claude - INFO - Using mock data for request: What's the weather like in Paris today?
2025-03-19 05:31:30,673 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:31:32,674 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:31:32,675 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:31:32,675 - state_of_mika.adapters.claude - INFO - Using mock data for request: Can you tell me the current weather in London?
2025-03-19 05:31:32,675 - state_of_mika.adapters.claude - INFO - Using mock data for request: Can you tell me the current weather in London?
2025-03-19 05:31:32,675 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:31:34,676 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:31:34,676 - state_of_mika.adapters.claude - INFO - ClaudeAdapter initialized in testing mode with mock data
2025-03-19 05:31:34,676 - state_of_mika.adapters.claude - INFO - Using mock data for request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:31:34,677 - state_of_mika.adapters.claude - INFO - Using mock data for request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:31:34,677 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:34:14,177 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:34:14,179 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:34:14,179 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:34:14,225 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:34:14,225 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:34:14,226 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:34:14,247 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:34:14,248 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:34:14,260 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106692270>
2025-03-19 05:34:14,260 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106626cc0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:34:14,276 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1064b2850>
2025-03-19 05:34:14,276 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:34:14,276 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:34:14,276 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:34:14,276 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:34:14,277 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:34:15,857 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:34:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:34:14Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:34:15Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:34:15Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:34:15Z'), (b'request-id', b'req_011EZGd8pTMthv6bNUQCRr5G'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227da5b5cae38a5-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:34:15,859 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:34:15,859 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:34:15,859 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:34:15,859 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:34:15,860 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:34:15,860 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:34:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:34:14Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:34:15Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:34:15Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:34:15Z', 'request-id': 'req_011EZGd8pTMthv6bNUQCRr5G', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227da5b5cae38a5-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:34:15,860 - anthropic._base_client - DEBUG - request_id: req_011EZGd8pTMthv6bNUQCRr5G
2025-03-19 05:34:15,866 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 05:34:15,866 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 05:34:15,866 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:34:15,866 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:34:15,866 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:34:15,866 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:34:15,866 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:34:15,866 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:34:15,866 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:34:17,868 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:34:17,868 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:34:17,889 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:34:17,889 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:34:17,890 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:34:17,890 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:34:17,891 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:34:17,900 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1066fdd10>
2025-03-19 05:34:17,900 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066272f0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:34:17,913 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106669a70>
2025-03-19 05:34:17,914 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:34:17,914 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:34:17,914 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:34:17,914 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:34:17,914 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:34:18,977 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:34:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:34:18Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:34:18Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:34:18Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:34:18Z'), (b'request-id', b'req_01Sy5VXwy1thJztuPrjrcWX2'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227da721a438a1d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:34:18,978 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:34:18,979 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:34:18,979 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:34:18,979 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:34:18,979 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:34:18,979 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:34:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:34:18Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:34:18Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:34:18Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:34:18Z', 'request-id': 'req_01Sy5VXwy1thJztuPrjrcWX2', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227da721a438a1d-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:34:18,979 - anthropic._base_client - DEBUG - request_id: req_01Sy5VXwy1thJztuPrjrcWX2
2025-03-19 05:34:18,980 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:34:18,980 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:34:18,980 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:34:18,980 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:34:18,980 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:34:18,980 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:34:18,980 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:34:18,980 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:34:18,980 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:34:20,982 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:34:20,983 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:34:21,003 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:34:21,003 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:34:21,004 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:34:21,004 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:34:21,004 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:34:21,017 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10666a190>
2025-03-19 05:34:21,017 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066275c0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:34:21,032 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1066956d0>
2025-03-19 05:34:21,032 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:34:21,032 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:34:21,032 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:34:21,032 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:34:21,032 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:34:22,051 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:34:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:34:21Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:34:21Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:34:21Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:34:21Z'), (b'request-id', b'req_0151mUJgzDnjuSQc3wGdDhko'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227da859d3de58c-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:34:22,052 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:34:22,052 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:34:22,053 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:34:22,053 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:34:22,053 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:34:22,053 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:34:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:34:21Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:34:21Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:34:21Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:34:21Z', 'request-id': 'req_0151mUJgzDnjuSQc3wGdDhko', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227da859d3de58c-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:34:22,053 - anthropic._base_client - DEBUG - request_id: req_0151mUJgzDnjuSQc3wGdDhko
2025-03-19 05:34:22,054 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:34:22,054 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:34:22,054 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:34:22,054 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:34:22,054 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:34:22,054 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:34:22,054 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:34:22,054 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:34:22,054 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:34:22,083 - httpcore.connection - DEBUG - close.started
2025-03-19 05:34:22,084 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:34:22,084 - httpcore.connection - DEBUG - close.started
2025-03-19 05:34:22,084 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:34:22,084 - httpcore.connection - DEBUG - close.started
2025-03-19 05:34:22,084 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:34:50,872 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:34:50,873 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:34:50,874 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:34:50,911 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:34:50,911 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:34:50,912 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:34:50,935 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:34:50,936 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:34:50,954 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105292270>
2025-03-19 05:34:50,954 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105226cc0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:34:50,970 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1051b2850>
2025-03-19 05:34:50,970 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:34:50,971 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:34:50,971 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:34:50,971 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:34:50,971 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:34:52,122 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:34:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:34:51Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:34:51Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:34:52Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:34:51Z'), (b'request-id', b'req_01Tx7tJCRNsDkozSSNCU3bRN'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227db40a8ae4956-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:34:52,127 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:34:52,130 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:34:52,136 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:34:52,138 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:34:52,141 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:34:52,143 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:34:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:34:51Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:34:51Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:34:52Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:34:51Z', 'request-id': 'req_01Tx7tJCRNsDkozSSNCU3bRN', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227db40a8ae4956-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:34:52,147 - anthropic._base_client - DEBUG - request_id: req_01Tx7tJCRNsDkozSSNCU3bRN
2025-03-19 05:34:52,160 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 05:34:52,160 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 05:34:52,160 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:34:52,160 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:34:52,160 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:34:52,160 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:34:52,160 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:34:52,160 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:34:52,160 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:34:54,163 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:34:54,163 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:34:54,188 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:34:54,188 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:34:54,189 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:34:54,189 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:34:54,189 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:34:54,203 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1052f1d10>
2025-03-19 05:34:54,203 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1052272f0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:34:54,217 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105269a70>
2025-03-19 05:34:54,217 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:34:54,217 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:34:54,217 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:34:54,217 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:34:54,218 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:34:55,431 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:34:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:34:54Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:34:54Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:34:55Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:34:54Z'), (b'request-id', b'req_01Lp6SMtDYQfarbe2hskXBcQ'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227db54fb03e53f-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:34:55,432 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:34:55,432 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:34:55,433 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:34:55,433 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:34:55,433 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:34:55,433 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:34:55 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:34:54Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:34:54Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:34:55Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:34:54Z', 'request-id': 'req_01Lp6SMtDYQfarbe2hskXBcQ', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227db54fb03e53f-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:34:55,433 - anthropic._base_client - DEBUG - request_id: req_01Lp6SMtDYQfarbe2hskXBcQ
2025-03-19 05:34:55,434 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:34:55,434 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:34:55,434 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:34:55,434 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:34:55,434 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:34:55,434 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:34:55,434 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:34:55,434 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:34:55,434 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:34:57,436 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:34:57,437 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:34:57,460 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:34:57,460 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:34:57,461 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:34:57,461 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:34:57,461 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:34:57,476 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10526a190>
2025-03-19 05:34:57,476 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1052275c0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:34:57,493 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1052957f0>
2025-03-19 05:34:57,493 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:34:57,493 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:34:57,493 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:34:57,493 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:34:57,493 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:34:58,505 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:34:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:34:57Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:34:57Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:34:58Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:34:57Z'), (b'request-id', b'req_01JGkVjgFyzf3Y8SamuEBK2W'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227db6979bbe582-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:34:58,506 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:34:58,506 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:34:58,506 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:34:58,506 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:34:58,506 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:34:58,506 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:34:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:34:57Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:34:57Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:34:58Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:34:57Z', 'request-id': 'req_01JGkVjgFyzf3Y8SamuEBK2W', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227db6979bbe582-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:34:58,506 - anthropic._base_client - DEBUG - request_id: req_01JGkVjgFyzf3Y8SamuEBK2W
2025-03-19 05:34:58,507 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:34:58,507 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:34:58,507 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:34:58,507 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:34:58,507 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:34:58,507 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:34:58,507 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:34:58,507 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:34:58,507 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:34:58,539 - httpcore.connection - DEBUG - close.started
2025-03-19 05:34:58,540 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:34:58,540 - httpcore.connection - DEBUG - close.started
2025-03-19 05:34:58,540 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:34:58,540 - httpcore.connection - DEBUG - close.started
2025-03-19 05:34:58,540 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:35:36,580 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:35:36,581 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:35:36,581 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:35:36,619 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:35:36,619 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:35:36,620 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:35:36,639 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:35:36,640 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:35:36,664 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106e8e270>
2025-03-19 05:35:36,664 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106e22cc0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:35:36,681 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106db2710>
2025-03-19 05:35:36,681 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:35:36,682 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:35:36,682 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:35:36,682 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:35:36,682 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:35:37,845 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:35:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:35:36Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:35:37Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:35:37Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:35:37Z'), (b'request-id', b'req_01WrKS3vVLkFo2CpHtRe5e2Y'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227dc5e5f977a8a-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:35:37,846 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:35:37,847 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:35:37,847 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:35:37,847 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:35:37,847 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:35:37,847 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:35:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:35:36Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:35:37Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:35:37Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:35:37Z', 'request-id': 'req_01WrKS3vVLkFo2CpHtRe5e2Y', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227dc5e5f977a8a-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:35:37,847 - anthropic._base_client - DEBUG - request_id: req_01WrKS3vVLkFo2CpHtRe5e2Y
2025-03-19 05:35:37,853 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:35:37,853 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:35:37,853 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:35:37,853 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:35:37,853 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:35:37,853 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:35:37,853 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:35:37,853 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:35:37,853 - state_of_mika.adapters.claude - INFO - Trying fallback with execute_capability for weather
2025-03-19 05:35:37,853 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:35:37,853 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:35:37,854 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}, {'role': 'assistant', 'content': "The result for your request about weather is: {'temperature': 22, 'condition': 'Sunny', 'humidity': 65, 'location': 'Paris'}"}, {'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:35:37,854 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:35:37,855 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:35:37,855 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:35:37,855 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:35:37,855 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:35:37,855 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:35:39,090 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:35:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:35:38Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:35:38Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:35:38Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:35:38Z'), (b'request-id', b'req_016PrgMwq39qwuwzSD6YA78z'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227dc65ba377a8a-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:35:39,090 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:35:39,091 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:35:39,092 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:35:39,092 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:35:39,092 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:35:39,092 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:35:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:35:38Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:35:38Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:35:38Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:35:38Z', 'request-id': 'req_016PrgMwq39qwuwzSD6YA78z', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227dc65ba377a8a-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:35:39,092 - anthropic._base_client - DEBUG - request_id: req_016PrgMwq39qwuwzSD6YA78z
2025-03-19 05:35:39,092 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris'}}
2025-03-19 05:35:39,093 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris'}}
2025-03-19 05:35:39,093 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:35:39,093 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:35:39,093 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:35:39,093 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:35:39,093 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:35:39,093 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:35:39,093 - state_of_mika.adapters.claude - INFO - Trying fallback with execute_capability for weather
2025-03-19 05:35:39,093 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:35:41,095 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:35:41,095 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:35:41,115 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:35:41,115 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:35:41,116 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:35:41,116 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:35:41,116 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:35:41,129 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107106ad0>
2025-03-19 05:35:41,130 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106e23650> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:35:41,143 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106e61ba0>
2025-03-19 05:35:41,143 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:35:41,143 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:35:41,143 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:35:41,143 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:35:41,143 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:35:42,146 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:35:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:35:41Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:35:41Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:35:42Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:35:41Z'), (b'request-id', b'req_01WuqCFbxfzH8d3rDe2FuXgF'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227dc7a4ddfe58b-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:35:42,148 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:35:42,148 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:35:42,149 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:35:42,149 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:35:42,149 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:35:42,149 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:35:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:35:41Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:35:41Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:35:42Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:35:41Z', 'request-id': 'req_01WuqCFbxfzH8d3rDe2FuXgF', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227dc7a4ddfe58b-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:35:42,149 - anthropic._base_client - DEBUG - request_id: req_01WuqCFbxfzH8d3rDe2FuXgF
2025-03-19 05:35:42,149 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:35:42,149 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:35:42,149 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:35:42,149 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:35:42,149 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:35:42,149 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:35:42,149 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:35:42,149 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:35:42,149 - state_of_mika.adapters.claude - INFO - Trying fallback with execute_capability for weather
2025-03-19 05:35:42,150 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:35:42,150 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:35:42,150 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}, {'role': 'assistant', 'content': "The result for your request about weather is: {'temperature': 18, 'condition': 'Cloudy', 'humidity': 75, 'location': 'London'}"}, {'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:35:42,150 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:35:42,151 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:35:42,151 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:35:42,151 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:35:42,151 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:35:42,151 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:35:43,388 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:35:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:35:42Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:35:42Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:35:43Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:35:42Z'), (b'request-id', b'req_016qSbe8ayhbZxjRkbRnvfac'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227dc808ce1e58b-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:35:43,389 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:35:43,389 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:35:43,389 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:35:43,389 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:35:43,389 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:35:43,390 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:35:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:35:42Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:35:42Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:35:43Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:35:42Z', 'request-id': 'req_016qSbe8ayhbZxjRkbRnvfac', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227dc808ce1e58b-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:35:43,390 - anthropic._base_client - DEBUG - request_id: req_016qSbe8ayhbZxjRkbRnvfac
2025-03-19 05:35:43,390 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:35:43,391 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:35:43,391 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:35:43,391 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:35:43,391 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:35:43,391 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:35:43,391 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:35:43,391 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:35:43,391 - state_of_mika.adapters.claude - INFO - Trying fallback with execute_capability for weather
2025-03-19 05:35:43,391 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:35:45,393 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:35:45,393 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:35:45,417 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:35:45,417 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:35:45,417 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:35:45,418 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:35:45,418 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:35:45,432 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106e63950>
2025-03-19 05:35:45,432 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106e231d0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:35:45,444 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106e997f0>
2025-03-19 05:35:45,444 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:35:45,444 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:35:45,444 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:35:45,444 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:35:45,444 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:35:46,464 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:35:46 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:35:45Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:35:45Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:35:46Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:35:45Z'), (b'request-id', b'req_01A29MqzdLdALwRyuo4DjNfH'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227dc952cf4e588-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:35:46,465 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:35:46,465 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:35:46,465 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:35:46,465 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:35:46,465 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:35:46,466 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:35:46 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:35:45Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:35:45Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:35:46Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:35:45Z', 'request-id': 'req_01A29MqzdLdALwRyuo4DjNfH', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227dc952cf4e588-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:35:46,466 - anthropic._base_client - DEBUG - request_id: req_01A29MqzdLdALwRyuo4DjNfH
2025-03-19 05:35:46,466 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:35:46,466 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:35:46,467 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:35:46,467 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:35:46,467 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:35:46,467 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:35:46,467 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:35:46,467 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:35:46,467 - state_of_mika.adapters.claude - INFO - Trying fallback with execute_capability for weather
2025-03-19 05:35:46,467 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:35:46,467 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:35:46,468 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}, {'role': 'assistant', 'content': "The result for your request about weather is: {'temperature': 28, 'condition': 'Partly Cloudy', 'humidity': 60, 'location': 'Tokyo'}"}, {'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:35:46,468 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:35:46,469 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:35:46,469 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:35:46,469 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:35:46,469 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:35:46,469 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:35:47,693 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:35:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:35:46Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:35:46Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:35:47Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:35:46Z'), (b'request-id', b'req_011KcvfQNTxroAwoDhZ2s5DD'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227dc9b8cd1e588-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:35:47,693 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:35:47,693 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:35:47,694 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:35:47,694 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:35:47,694 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:35:47,694 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:35:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:35:46Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:35:46Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:35:47Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:35:46Z', 'request-id': 'req_011KcvfQNTxroAwoDhZ2s5DD', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227dc9b8cd1e588-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:35:47,694 - anthropic._base_client - DEBUG - request_id: req_011KcvfQNTxroAwoDhZ2s5DD
2025-03-19 05:35:47,695 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:35:47,695 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:35:47,695 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:35:47,695 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:35:47,696 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:35:47,696 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:35:47,696 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:35:47,696 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:35:47,696 - state_of_mika.adapters.claude - INFO - Trying fallback with execute_capability for weather
2025-03-19 05:35:47,696 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:35:47,725 - httpcore.connection - DEBUG - close.started
2025-03-19 05:35:47,726 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:35:47,726 - httpcore.connection - DEBUG - close.started
2025-03-19 05:35:47,726 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:35:47,726 - httpcore.connection - DEBUG - close.started
2025-03-19 05:35:47,726 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:36:20,871 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:36:20,872 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:36:20,872 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:36:20,872 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:36:21,248 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:36:21,248 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:36:21,248 - process - INFO - Start time: 2025-03-19 05:36:21
2025-03-19 05:36:21,248 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:36:21,248 - mock - INFO - MockClaudeAdapter initialized in testing mode
2025-03-19 05:36:21,248 - process - INFO - Sending request to adapter for processing
2025-03-19 05:36:21,248 - mock - INFO - Processing request with mock data: What's the weather like in Paris today?
2025-03-19 05:36:21,248 - result - INFO - Request processing completed successfully
2025-03-19 05:36:21,248 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "Paris"
  },
  "result": {
    "temperature": 22,
    "condition": "Sunny",
    "humidity": 65,
    "location": "Paris"
  }
}
2025-03-19 05:36:21,248 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:36:21,248 - process - INFO - End time: 2025-03-19 05:36:21
2025-03-19 05:36:21,248 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:36:21,248 - process - INFO - Start time: 2025-03-19 05:36:21
2025-03-19 05:36:21,249 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:36:21,249 - mock - INFO - MockClaudeAdapter initialized in testing mode
2025-03-19 05:36:21,249 - process - INFO - Sending request to adapter for processing
2025-03-19 05:36:21,249 - mock - INFO - Processing request with mock data: Can you tell me the current weather in London?
2025-03-19 05:36:21,249 - result - INFO - Request processing completed successfully
2025-03-19 05:36:21,249 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "London"
  },
  "result": {
    "temperature": 18,
    "condition": "Cloudy",
    "humidity": 75,
    "location": "London"
  }
}
2025-03-19 05:36:21,249 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:36:21,249 - process - INFO - End time: 2025-03-19 05:36:21
2025-03-19 05:36:21,249 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:36:21,249 - process - INFO - Start time: 2025-03-19 05:36:21
2025-03-19 05:36:21,249 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:36:21,249 - mock - INFO - MockClaudeAdapter initialized in testing mode
2025-03-19 05:36:21,249 - process - INFO - Sending request to adapter for processing
2025-03-19 05:36:21,249 - mock - INFO - Processing request with mock data: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:36:21,249 - result - INFO - Request processing completed successfully
2025-03-19 05:36:21,249 - result - DEBUG - Final result: {
  "success": true,
  "capability": "weather",
  "tool": "weather_lookup",
  "parameters": {
    "location": "Tokyo"
  },
  "result": {
    "temperature": 28,
    "condition": "Partly Cloudy",
    "humidity": 60,
    "location": "Tokyo"
  }
}
2025-03-19 05:36:21,249 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:36:21,249 - process - INFO - End time: 2025-03-19 05:36:21
2025-03-19 05:39:48,096 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:39:48,098 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:39:48,098 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:39:48,098 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:39:48,444 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:39:48,444 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:39:48,444 - process - INFO - Start time: 2025-03-19 05:39:48
2025-03-19 05:39:48,444 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:39:48,444 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:39:48,483 - process - INFO - Sending request to adapter for processing
2025-03-19 05:39:48,483 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:39:48,483 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:39:48,484 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:39:48,502 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:39:48,503 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:39:48,534 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111296120>
2025-03-19 05:39:48,534 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x11123ab10> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:39:48,549 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1111c25d0>
2025-03-19 05:39:48,549 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:39:48,549 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:39:48,549 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:39:48,550 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:39:48,550 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:39:49,741 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:39:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:39:48Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:39:48Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:39:49Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:39:48Z'), (b'request-id', b'req_01Treef5j5biEox6iYtBNQPe'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227e2848a75a476-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:39:49,742 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:39:49,742 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:39:49,742 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:39:49,742 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:39:49,742 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:39:49,742 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:39:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:39:48Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:39:48Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:39:49Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:39:48Z', 'request-id': 'req_01Treef5j5biEox6iYtBNQPe', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227e2848a75a476-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:39:49,742 - anthropic._base_client - DEBUG - request_id: req_01Treef5j5biEox6iYtBNQPe
2025-03-19 05:39:49,747 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:39:49,747 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:39:49,747 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:39:49,747 - state_of_mika.connector - WARNING - Server 'mcp_weather' is not installed and auto-install is disabled
2025-03-19 05:39:49,747 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:39:49,747 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:39:49,747 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:39:49,747 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:39:49,747 - process - INFO - End time: 2025-03-19 05:39:49
2025-03-19 05:39:49,747 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:39:49,747 - process - INFO - Start time: 2025-03-19 05:39:49
2025-03-19 05:39:49,748 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:39:49,748 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:39:49,773 - process - INFO - Sending request to adapter for processing
2025-03-19 05:39:49,773 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:39:49,773 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:39:49,774 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:39:49,774 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:39:49,774 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:39:49,783 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1112fd810>
2025-03-19 05:39:49,783 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x11123b140> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:39:49,794 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11123e2c0>
2025-03-19 05:39:49,794 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:39:49,795 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:39:49,795 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:39:49,795 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:39:49,795 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:39:50,962 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:39:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:39:50Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:39:50Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:39:50Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:39:50Z'), (b'request-id', b'req_01A7EthyqTWXeqc5FevXtFqv'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227e28c48d8e54f-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:39:50,963 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:39:50,963 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:39:50,963 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:39:50,963 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:39:50,963 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:39:50,964 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:39:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:39:50Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:39:50Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:39:50Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:39:50Z', 'request-id': 'req_01A7EthyqTWXeqc5FevXtFqv', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227e28c48d8e54f-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:39:50,964 - anthropic._base_client - DEBUG - request_id: req_01A7EthyqTWXeqc5FevXtFqv
2025-03-19 05:39:50,964 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:39:50,964 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:39:50,964 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:39:50,964 - state_of_mika.connector - WARNING - Server 'mcp_weather' is not installed and auto-install is disabled
2025-03-19 05:39:50,964 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:39:50,964 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:39:50,964 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:39:50,964 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:39:50,964 - process - INFO - End time: 2025-03-19 05:39:50
2025-03-19 05:39:50,965 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:39:50,965 - process - INFO - Start time: 2025-03-19 05:39:50
2025-03-19 05:39:50,965 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:39:50,965 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:39:50,982 - httpcore.connection - DEBUG - close.started
2025-03-19 05:39:50,983 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:39:50,984 - process - INFO - Sending request to adapter for processing
2025-03-19 05:39:50,984 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:39:50,984 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:39:50,985 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:39:50,985 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:39:50,985 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:39:50,996 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11123d350>
2025-03-19 05:39:50,996 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x11123b530> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:39:51,006 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11129c050>
2025-03-19 05:39:51,006 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:39:51,006 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:39:51,006 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:39:51,006 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:39:51,006 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:39:52,088 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:39:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:39:51Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:39:51Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:39:51Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:39:51Z'), (b'request-id', b'req_017YzxiWqrfi9fPbHFDhmwtQ'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227e293eef6fa4b-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:39:52,090 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:39:52,090 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:39:52,090 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:39:52,090 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:39:52,090 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:39:52,090 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:39:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:39:51Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:39:51Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:39:51Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:39:51Z', 'request-id': 'req_017YzxiWqrfi9fPbHFDhmwtQ', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227e293eef6fa4b-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:39:52,090 - anthropic._base_client - DEBUG - request_id: req_017YzxiWqrfi9fPbHFDhmwtQ
2025-03-19 05:39:52,091 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:39:52,091 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:39:52,091 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:39:52,091 - state_of_mika.connector - WARNING - Server 'mcp_weather' is not installed and auto-install is disabled
2025-03-19 05:39:52,091 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:39:52,091 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:39:52,091 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:39:52,091 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:39:52,091 - process - INFO - End time: 2025-03-19 05:39:52
2025-03-19 05:39:52,119 - httpcore.connection - DEBUG - close.started
2025-03-19 05:39:52,120 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:39:52,120 - httpcore.connection - DEBUG - close.started
2025-03-19 05:39:52,120 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:40:06,106 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:40:06,107 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:40:06,107 - process - INFO - Start time: 2025-03-19 05:40:06
2025-03-19 05:40:06,107 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:40:06,107 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:40:06,141 - process - INFO - Sending request to adapter for processing
2025-03-19 05:40:06,141 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:40:06,141 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:40:06,143 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:40:06,159 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:40:06,160 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:40:06,174 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105c52120>
2025-03-19 05:40:06,174 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105bf6b10> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:40:06,186 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105b7a5d0>
2025-03-19 05:40:06,186 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:40:06,186 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:40:06,186 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:40:06,186 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:40:06,186 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:40:07,326 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:40:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:40:06Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:40:07Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:40:07Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:40:07Z'), (b'request-id', b'req_01QEq5etPeAe3kD8Ua7FhaCn'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227e2f2cd1ce541-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:40:07,326 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:40:07,327 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:40:07,331 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:40:07,331 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:40:07,331 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:40:07,331 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:40:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:40:06Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:40:07Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:40:07Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:40:07Z', 'request-id': 'req_01QEq5etPeAe3kD8Ua7FhaCn', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227e2f2cd1ce541-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:40:07,331 - anthropic._base_client - DEBUG - request_id: req_01QEq5etPeAe3kD8Ua7FhaCn
2025-03-19 05:40:07,335 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:40:07,335 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:40:07,335 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:40:07,335 - state_of_mika.connector - WARNING - Server 'mcp_weather' is not installed and auto-install is disabled
2025-03-19 05:40:07,335 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:40:07,335 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:40:07,335 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:40:07,335 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:40:07,335 - process - INFO - End time: 2025-03-19 05:40:07
2025-03-19 05:40:07,335 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:40:07,335 - process - INFO - Start time: 2025-03-19 05:40:07
2025-03-19 05:40:07,336 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:40:07,336 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:40:07,357 - process - INFO - Sending request to adapter for processing
2025-03-19 05:40:07,357 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:40:07,357 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:40:07,358 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:40:07,358 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:40:07,358 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:40:07,369 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105cb9810>
2025-03-19 05:40:07,369 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105bf7140> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:40:07,384 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105bfa2c0>
2025-03-19 05:40:07,384 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:40:07,384 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:40:07,384 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:40:07,384 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:40:07,384 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:40:08,473 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:40:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:40:07Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:40:07Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:40:08Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:40:07Z'), (b'request-id', b'req_01VHet3RSCQNqJxkz4JVcqSE'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227e2fa4f847a9e-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:40:08,474 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:40:08,474 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:40:08,475 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:40:08,475 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:40:08,475 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:40:08,475 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:40:08 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:40:07Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:40:07Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:40:08Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:40:07Z', 'request-id': 'req_01VHet3RSCQNqJxkz4JVcqSE', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227e2fa4f847a9e-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:40:08,475 - anthropic._base_client - DEBUG - request_id: req_01VHet3RSCQNqJxkz4JVcqSE
2025-03-19 05:40:08,476 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:40:08,476 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:40:08,476 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:40:08,476 - state_of_mika.connector - WARNING - Server 'mcp_weather' is not installed and auto-install is disabled
2025-03-19 05:40:08,476 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:40:08,476 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:40:08,476 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:40:08,476 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:40:08,476 - process - INFO - End time: 2025-03-19 05:40:08
2025-03-19 05:40:08,476 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:40:08,476 - process - INFO - Start time: 2025-03-19 05:40:08
2025-03-19 05:40:08,477 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:40:08,477 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:40:08,497 - httpcore.connection - DEBUG - close.started
2025-03-19 05:40:08,497 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:40:08,498 - process - INFO - Sending request to adapter for processing
2025-03-19 05:40:08,498 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:40:08,498 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:40:08,499 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:40:08,499 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:40:08,499 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:40:08,509 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105bf9350>
2025-03-19 05:40:08,509 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105bf7530> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:40:08,523 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105c58050>
2025-03-19 05:40:08,523 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:40:08,523 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:40:08,523 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:40:08,523 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:40:08,523 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:40:09,521 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:40:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:40:08Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:40:08Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:40:09Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:40:08Z'), (b'request-id', b'req_01YQsNYxH3GFegF6bCB7vmDk'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227e3015e0ae586-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:40:09,522 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:40:09,522 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:40:09,522 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:40:09,522 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:40:09,522 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:40:09,522 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:40:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:40:08Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:40:08Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:40:09Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:40:08Z', 'request-id': 'req_01YQsNYxH3GFegF6bCB7vmDk', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227e3015e0ae586-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:40:09,523 - anthropic._base_client - DEBUG - request_id: req_01YQsNYxH3GFegF6bCB7vmDk
2025-03-19 05:40:09,523 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:40:09,523 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:40:09,523 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:40:09,523 - state_of_mika.connector - WARNING - Server 'mcp_weather' is not installed and auto-install is disabled
2025-03-19 05:40:09,523 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:40:09,523 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:40:09,523 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:40:09,523 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:40:09,523 - process - INFO - End time: 2025-03-19 05:40:09
2025-03-19 05:40:09,553 - httpcore.connection - DEBUG - close.started
2025-03-19 05:40:09,553 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:40:09,553 - httpcore.connection - DEBUG - close.started
2025-03-19 05:40:09,553 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:43:37,849 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:43:37,850 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:43:37,850 - process - INFO - Start time: 2025-03-19 05:43:37
2025-03-19 05:43:37,851 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:43:37,851 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:43:37,888 - process - INFO - Sending request to adapter for processing
2025-03-19 05:43:37,888 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:43:37,888 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:43:37,889 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:43:37,906 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:43:37,907 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:43:37,922 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107a9a120>
2025-03-19 05:43:37,922 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107a3ab10> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:43:37,934 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1079c25d0>
2025-03-19 05:43:37,934 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:43:37,935 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:43:37,935 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:43:37,935 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:43:37,935 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:43:39,121 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:43:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:43:38Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:43:38Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:43:39Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:43:38Z'), (b'request-id', b'req_01RXat8fdnoBDA6BJUoqYxoX'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227e81e2b1fe557-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:43:39,122 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:43:39,123 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:43:39,123 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:43:39,123 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:43:39,123 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:43:39,123 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:43:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:43:38Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:43:38Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:43:39Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:43:38Z', 'request-id': 'req_01RXat8fdnoBDA6BJUoqYxoX', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227e81e2b1fe557-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:43:39,123 - anthropic._base_client - DEBUG - request_id: req_01RXat8fdnoBDA6BJUoqYxoX
2025-03-19 05:43:39,129 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:43:39,130 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:43:39,130 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:43:39,130 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:43:39,130 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:43:39,130 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:43:39,130 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:43:39,130 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:43:39,130 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:43:39,130 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:43:39,130 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:43:39,130 - process - INFO - End time: 2025-03-19 05:43:39
2025-03-19 05:43:39,130 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:43:39,130 - process - INFO - Start time: 2025-03-19 05:43:39
2025-03-19 05:43:39,131 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:43:39,131 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:43:39,152 - process - INFO - Sending request to adapter for processing
2025-03-19 05:43:39,154 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:43:39,154 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:43:39,155 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:43:39,155 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:43:39,155 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:43:39,165 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107af9810>
2025-03-19 05:43:39,165 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107a3b140> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:43:39,184 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107a3e2c0>
2025-03-19 05:43:39,184 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:43:39,184 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:43:39,184 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:43:39,184 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:43:39,184 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:43:40,889 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:43:40 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:43:40Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:43:40Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:43:40Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:43:40Z'), (b'request-id', b'req_01NzyDrhDQ3ZgUfyE1iwBJRP'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227e825fd29a844-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:43:40,890 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:43:40,890 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:43:40,891 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:43:40,891 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:43:40,891 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:43:40,891 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:43:40 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:43:40Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:43:40Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:43:40Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:43:40Z', 'request-id': 'req_01NzyDrhDQ3ZgUfyE1iwBJRP', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227e825fd29a844-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:43:40,891 - anthropic._base_client - DEBUG - request_id: req_01NzyDrhDQ3ZgUfyE1iwBJRP
2025-03-19 05:43:40,892 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:43:40,892 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:43:40,892 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:43:40,892 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:43:40,892 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:43:40,892 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:43:40,892 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:43:40,892 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:43:40,892 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:43:40,892 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:43:40,892 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:43:40,892 - process - INFO - End time: 2025-03-19 05:43:40
2025-03-19 05:43:40,892 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:43:40,892 - process - INFO - Start time: 2025-03-19 05:43:40
2025-03-19 05:43:40,893 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:43:40,893 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:43:40,914 - httpcore.connection - DEBUG - close.started
2025-03-19 05:43:40,914 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:43:40,915 - process - INFO - Sending request to adapter for processing
2025-03-19 05:43:40,915 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:43:40,915 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:43:40,916 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:43:40,916 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:43:40,916 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:43:40,926 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107a3d350>
2025-03-19 05:43:40,926 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107a3b530> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:43:40,938 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107a8c170>
2025-03-19 05:43:40,938 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:43:40,938 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:43:40,938 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:43:40,938 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:43:40,938 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:43:41,964 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:43:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:43:41Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:43:41Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:43:41Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:43:41Z'), (b'request-id', b'req_01S2q9Lc5KeRhTnxptQAgWxB'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227e830fdfae541-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:43:41,965 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:43:41,965 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:43:41,965 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:43:41,965 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:43:41,965 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:43:41,965 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:43:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:43:41Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:43:41Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:43:41Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:43:41Z', 'request-id': 'req_01S2q9Lc5KeRhTnxptQAgWxB', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227e830fdfae541-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:43:41,965 - anthropic._base_client - DEBUG - request_id: req_01S2q9Lc5KeRhTnxptQAgWxB
2025-03-19 05:43:41,966 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:43:41,966 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:43:41,966 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:43:41,966 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:43:41,966 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:43:41,966 - state_of_mika.installer - ERROR - Unsupported installation type: npm
2025-03-19 05:43:41,966 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:43:41,966 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:43:41,966 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:43:41,966 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:43:41,966 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:43:41,967 - process - INFO - End time: 2025-03-19 05:43:41
2025-03-19 05:43:41,987 - httpcore.connection - DEBUG - close.started
2025-03-19 05:43:41,988 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:43:41,988 - httpcore.connection - DEBUG - close.started
2025-03-19 05:43:41,988 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:48:02,971 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:48:02,971 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:48:02,971 - process - INFO - Start time: 2025-03-19 05:48:02
2025-03-19 05:48:02,972 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:48:02,972 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:48:03,008 - process - INFO - Sending request to adapter for processing
2025-03-19 05:48:03,008 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:48:03,008 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:48:03,009 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:48:03,027 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:48:03,027 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:48:03,061 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10749a120>
2025-03-19 05:48:03,061 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1074329f0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:48:03,078 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1073c25d0>
2025-03-19 05:48:03,078 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:48:03,078 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:48:03,078 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:48:03,078 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:48:03,079 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:48:04,332 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:48:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:48:03Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:48:03Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:48:04Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:48:03Z'), (b'request-id', b'req_01QSR3jPzk6T2wydbVr2gKs7'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227ee975c127137-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:48:04,332 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:48:04,332 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:48:04,332 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:48:04,332 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:48:04,332 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:48:04,332 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:48:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:48:03Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:48:03Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:48:04Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:48:03Z', 'request-id': 'req_01QSR3jPzk6T2wydbVr2gKs7', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227ee975c127137-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:48:04,333 - anthropic._base_client - DEBUG - request_id: req_01QSR3jPzk6T2wydbVr2gKs7
2025-03-19 05:48:04,336 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:48:04,336 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:48:04,336 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:48:04,336 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:48:04,336 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:48:04,610 - state_of_mika.installer - INFO - Installing npm package: mcp-weather (globally)
2025-03-19 05:48:05,776 - state_of_mika.installer - ERROR - Error installing npm package mcp-weather: npm error code E404
npm error 404 Not Found - GET https://registry.npmjs.org/mcp-weather - Not found
npm error 404
npm error 404  'mcp-weather@*' is not in this registry.
npm error 404
npm error 404 Note that you can also install from a
npm error 404 tarball, folder, http url, or git url.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_48_04_676Z-debug-0.log

2025-03-19 05:48:05,777 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:48:05,777 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:48:05,777 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:48:05,777 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:48:05,777 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:48:05,777 - process - INFO - End time: 2025-03-19 05:48:05
2025-03-19 05:48:05,777 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:48:05,777 - process - INFO - Start time: 2025-03-19 05:48:05
2025-03-19 05:48:05,777 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:48:05,777 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:48:05,797 - process - INFO - Sending request to adapter for processing
2025-03-19 05:48:05,797 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:48:05,797 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:48:05,798 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:48:05,798 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:48:05,798 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:48:05,808 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107741590>
2025-03-19 05:48:05,808 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107433410> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:48:05,821 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10744a3f0>
2025-03-19 05:48:05,821 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:48:05,821 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:48:05,821 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:48:05,822 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:48:05,822 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:48:07,541 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:48:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:48:06Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:48:06Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:48:07Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:48:06Z'), (b'request-id', b'req_01N6f2uKtd6PQ4qfjivkvkTp'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227eea87b82e553-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:48:07,542 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:48:07,542 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:48:07,542 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:48:07,543 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:48:07,543 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:48:07,543 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:48:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:48:06Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:48:06Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:48:07Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:48:06Z', 'request-id': 'req_01N6f2uKtd6PQ4qfjivkvkTp', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227eea87b82e553-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:48:07,543 - anthropic._base_client - DEBUG - request_id: req_01N6f2uKtd6PQ4qfjivkvkTp
2025-03-19 05:48:07,543 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:48:07,543 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:48:07,543 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:48:07,543 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:48:07,543 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:48:07,639 - state_of_mika.installer - INFO - Installing npm package: mcp-weather (globally)
2025-03-19 05:48:07,911 - state_of_mika.installer - ERROR - Error installing npm package mcp-weather: npm error code E404
npm error 404 Not Found - GET https://registry.npmjs.org/mcp-weather - Not found
npm error 404
npm error 404  'mcp-weather@*' is not in this registry.
npm error 404
npm error 404 Note that you can also install from a
npm error 404 tarball, folder, http url, or git url.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_48_07_703Z-debug-0.log

2025-03-19 05:48:07,911 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:48:07,911 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:48:07,911 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:48:07,911 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:48:07,911 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:48:07,911 - process - INFO - End time: 2025-03-19 05:48:07
2025-03-19 05:48:07,911 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:48:07,911 - process - INFO - Start time: 2025-03-19 05:48:07
2025-03-19 05:48:07,911 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:48:07,911 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:48:07,928 - process - INFO - Sending request to adapter for processing
2025-03-19 05:48:07,929 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:48:07,929 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:48:07,929 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:48:07,930 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:48:07,930 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:48:07,941 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10744a8b0>
2025-03-19 05:48:07,941 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1074335c0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:48:07,956 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10748db50>
2025-03-19 05:48:07,956 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:48:07,956 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:48:07,956 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:48:07,956 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:48:07,956 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:48:09,042 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:48:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:48:08Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:48:08Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:48:08Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:48:08Z'), (b'request-id', b'req_0184gUYwCeKycLrYep7fUPHx'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227eeb5c91bd431-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:48:09,043 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:48:09,043 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:48:09,044 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:48:09,044 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:48:09,044 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:48:09,044 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:48:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:48:08Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:48:08Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:48:08Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:48:08Z', 'request-id': 'req_0184gUYwCeKycLrYep7fUPHx', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227eeb5c91bd431-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:48:09,044 - anthropic._base_client - DEBUG - request_id: req_0184gUYwCeKycLrYep7fUPHx
2025-03-19 05:48:09,045 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:48:09,045 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:48:09,045 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:48:09,045 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:48:09,045 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:48:09,140 - state_of_mika.installer - INFO - Installing npm package: mcp-weather (globally)
2025-03-19 05:48:09,418 - state_of_mika.installer - ERROR - Error installing npm package mcp-weather: npm error code E404
npm error 404 Not Found - GET https://registry.npmjs.org/mcp-weather - Not found
npm error 404
npm error 404  'mcp-weather@*' is not in this registry.
npm error 404
npm error 404 Note that you can also install from a
npm error 404 tarball, folder, http url, or git url.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_48_09_202Z-debug-0.log

2025-03-19 05:48:09,418 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:48:09,418 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:48:09,418 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:48:09,418 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:48:09,418 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:48:09,418 - process - INFO - End time: 2025-03-19 05:48:09
2025-03-19 05:48:09,436 - httpcore.connection - DEBUG - close.started
2025-03-19 05:48:09,437 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:48:09,437 - httpcore.connection - DEBUG - close.started
2025-03-19 05:48:09,437 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:48:09,438 - httpcore.connection - DEBUG - close.started
2025-03-19 05:48:09,438 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:48:39,434 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:48:39,436 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:48:39,436 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:48:39,436 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:48:39,773 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:48:39,774 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:48:39,774 - process - INFO - Start time: 2025-03-19 05:48:39
2025-03-19 05:48:39,774 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:48:39,774 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:48:39,811 - process - INFO - Sending request to adapter for processing
2025-03-19 05:48:39,811 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:48:39,811 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:48:39,812 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:48:39,830 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:48:39,830 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:48:39,845 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10519a120>
2025-03-19 05:48:39,846 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1051329f0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:48:39,863 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1050c25d0>
2025-03-19 05:48:39,866 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:48:39,866 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:48:39,866 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:48:39,867 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:48:39,867 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:48:41,065 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:48:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:48:40Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:48:40Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:48:40Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:48:40Z'), (b'request-id', b'req_01Wzd4oPGhEPnoCgCXqsS7G9'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227ef7d4c008a1d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:48:41,066 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:48:41,066 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:48:41,066 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:48:41,067 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:48:41,067 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:48:41,067 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:48:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:48:40Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:48:40Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:48:40Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:48:40Z', 'request-id': 'req_01Wzd4oPGhEPnoCgCXqsS7G9', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227ef7d4c008a1d-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:48:41,067 - anthropic._base_client - DEBUG - request_id: req_01Wzd4oPGhEPnoCgCXqsS7G9
2025-03-19 05:48:41,074 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:48:41,074 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:48:41,074 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:48:41,075 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:48:41,075 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:48:41,295 - state_of_mika.installer - INFO - Installing npm package: mcp-weather (globally)
2025-03-19 05:48:41,710 - state_of_mika.installer - ERROR - Error installing npm package mcp-weather: npm error code E404
npm error 404 Not Found - GET https://registry.npmjs.org/mcp-weather - Not found
npm error 404
npm error 404  'mcp-weather@*' is not in this registry.
npm error 404
npm error 404 Note that you can also install from a
npm error 404 tarball, folder, http url, or git url.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_48_41_358Z-debug-0.log

2025-03-19 05:48:41,710 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:48:41,710 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:48:41,710 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:48:41,710 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:48:41,710 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:48:41,710 - process - INFO - End time: 2025-03-19 05:48:41
2025-03-19 05:48:41,710 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:48:41,710 - process - INFO - Start time: 2025-03-19 05:48:41
2025-03-19 05:48:41,711 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:48:41,711 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:48:41,729 - process - INFO - Sending request to adapter for processing
2025-03-19 05:48:41,729 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:48:41,729 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:48:41,730 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:48:41,730 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:48:41,730 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:48:41,741 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1051fd590>
2025-03-19 05:48:41,741 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105133410> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:48:41,753 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10514a3f0>
2025-03-19 05:48:41,753 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:48:41,753 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:48:41,753 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:48:41,754 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:48:41,754 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:48:42,756 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:48:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:48:41Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:48:42Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:48:42Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:48:42Z'), (b'request-id', b'req_01TmARptziu93mPL4bXL7qT7'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227ef890d0ce53d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:48:42,757 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:48:42,757 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:48:42,758 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:48:42,758 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:48:42,758 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:48:42,758 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:48:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:48:41Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:48:42Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:48:42Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:48:42Z', 'request-id': 'req_01TmARptziu93mPL4bXL7qT7', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227ef890d0ce53d-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:48:42,758 - anthropic._base_client - DEBUG - request_id: req_01TmARptziu93mPL4bXL7qT7
2025-03-19 05:48:42,759 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:48:42,759 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:48:42,759 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:48:42,759 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:48:42,759 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:48:42,864 - state_of_mika.installer - INFO - Installing npm package: mcp-weather (globally)
2025-03-19 05:48:43,169 - state_of_mika.installer - ERROR - Error installing npm package mcp-weather: npm error code E404
npm error 404 Not Found - GET https://registry.npmjs.org/mcp-weather - Not found
npm error 404
npm error 404  'mcp-weather@*' is not in this registry.
npm error 404
npm error 404 Note that you can also install from a
npm error 404 tarball, folder, http url, or git url.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_48_42_935Z-debug-0.log

2025-03-19 05:48:43,169 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:48:43,169 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:48:43,169 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:48:43,169 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:48:43,169 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:48:43,169 - process - INFO - End time: 2025-03-19 05:48:43
2025-03-19 05:48:43,169 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:48:43,169 - process - INFO - Start time: 2025-03-19 05:48:43
2025-03-19 05:48:43,170 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:48:43,170 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:48:43,188 - process - INFO - Sending request to adapter for processing
2025-03-19 05:48:43,188 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:48:43,188 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:48:43,189 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:48:43,189 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:48:43,190 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:48:43,202 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10514a8b0>
2025-03-19 05:48:43,202 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1051335c0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:48:43,214 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10518db50>
2025-03-19 05:48:43,214 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:48:43,214 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:48:43,214 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:48:43,214 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:48:43,214 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:48:44,222 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:48:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:48:43Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:48:43Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:48:44Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:48:43Z'), (b'request-id', b'req_01MwUQe9JYckJdJgE2cUZTL4'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227ef922f6ad433-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:48:44,222 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:48:44,222 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:48:44,223 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:48:44,223 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:48:44,223 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:48:44,223 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:48:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:48:43Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:48:43Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:48:44Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:48:43Z', 'request-id': 'req_01MwUQe9JYckJdJgE2cUZTL4', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227ef922f6ad433-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:48:44,223 - anthropic._base_client - DEBUG - request_id: req_01MwUQe9JYckJdJgE2cUZTL4
2025-03-19 05:48:44,223 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:48:44,223 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:48:44,223 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:48:44,223 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:48:44,223 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:48:44,316 - state_of_mika.installer - INFO - Installing npm package: mcp-weather (globally)
2025-03-19 05:48:44,599 - state_of_mika.installer - ERROR - Error installing npm package mcp-weather: npm error code E404
npm error 404 Not Found - GET https://registry.npmjs.org/mcp-weather - Not found
npm error 404
npm error 404  'mcp-weather@*' is not in this registry.
npm error 404
npm error 404 Note that you can also install from a
npm error 404 tarball, folder, http url, or git url.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_48_44_378Z-debug-0.log

2025-03-19 05:48:44,599 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:48:44,599 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:48:44,599 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:48:44,599 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:48:44,599 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:48:44,599 - process - INFO - End time: 2025-03-19 05:48:44
2025-03-19 05:48:44,619 - httpcore.connection - DEBUG - close.started
2025-03-19 05:48:44,620 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:48:44,620 - httpcore.connection - DEBUG - close.started
2025-03-19 05:48:44,620 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:48:44,620 - httpcore.connection - DEBUG - close.started
2025-03-19 05:48:44,620 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:51:53,021 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:51:53,022 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:51:53,022 - process - INFO - Start time: 2025-03-19 05:51:53
2025-03-19 05:51:53,022 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:51:53,022 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:51:53,058 - process - INFO - Sending request to adapter for processing
2025-03-19 05:51:53,059 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:51:53,059 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:51:53,060 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:51:53,076 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:51:53,076 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:51:53,090 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103bf6120>
2025-03-19 05:51:53,090 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103b8e9f0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:51:53,107 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103b1e5d0>
2025-03-19 05:51:53,107 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:51:53,107 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:51:53,107 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:51:53,107 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:51:53,107 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:51:54,307 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:51:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:51:53Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:51:53Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:51:54Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:51:53Z'), (b'request-id', b'req_01P7KW5fWz5uD9DSxjzVFGLY'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227f434fbc0e586-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:51:54,309 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:51:54,309 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:51:54,309 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:51:54,310 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:51:54,310 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:51:54,310 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:51:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:51:53Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:51:53Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:51:54Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:51:53Z', 'request-id': 'req_01P7KW5fWz5uD9DSxjzVFGLY', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227f434fbc0e586-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:51:54,310 - anthropic._base_client - DEBUG - request_id: req_01P7KW5fWz5uD9DSxjzVFGLY
2025-03-19 05:51:54,315 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:51:54,316 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:51:54,316 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:51:54,316 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:51:54,316 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:51:54,501 - state_of_mika.installer - INFO - Installing npm package from repository: https://github.com/ZeparHyfar/mcp-weather.git (globally)
2025-03-19 05:51:57,189 - state_of_mika.installer - ERROR - Error installing npm package: npm error code 128
npm error An unknown git error occurred
npm error command git --no-replace-objects ls-remote ssh://git@github.com/ZeparHyfar/mcp-weather.git
npm error Warning: Permanently added 'github.com' (ED25519) to the list of known hosts.
npm error git@github.com: Permission denied (publickey).
npm error fatal: Could not read from remote repository.
npm error
npm error Please make sure you have the correct access rights
npm error and the repository exists.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_51_54_564Z-debug-0.log

2025-03-19 05:51:57,190 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:51:57,190 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:51:57,190 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:51:57,190 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:51:57,190 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:51:57,190 - process - INFO - End time: 2025-03-19 05:51:57
2025-03-19 05:51:57,191 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:51:57,191 - process - INFO - Start time: 2025-03-19 05:51:57
2025-03-19 05:51:57,191 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:51:57,191 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:51:57,215 - process - INFO - Sending request to adapter for processing
2025-03-19 05:51:57,215 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:51:57,215 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:51:57,216 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:51:57,216 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:51:57,217 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:51:57,227 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103d1d590>
2025-03-19 05:51:57,227 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103b8f410> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:51:57,242 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103ba63f0>
2025-03-19 05:51:57,242 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:51:57,242 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:51:57,242 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:51:57,242 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:51:57,242 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:51:58,907 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:51:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:51:58Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:51:58Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:51:58Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:51:58Z'), (b'request-id', b'req_01TKtdRanJcfEwKVDT6c6PqW'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227f44edfe9a476-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:51:58,908 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:51:58,909 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:51:58,909 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:51:58,909 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:51:58,909 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:51:58,909 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:51:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:51:58Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:51:58Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:51:58Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:51:58Z', 'request-id': 'req_01TKtdRanJcfEwKVDT6c6PqW', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227f44edfe9a476-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:51:58,910 - anthropic._base_client - DEBUG - request_id: req_01TKtdRanJcfEwKVDT6c6PqW
2025-03-19 05:51:58,910 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:51:58,910 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:51:58,910 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:51:58,910 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:51:58,910 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:51:59,006 - state_of_mika.installer - INFO - Installing npm package from repository: https://github.com/ZeparHyfar/mcp-weather.git (globally)
2025-03-19 05:52:01,378 - state_of_mika.installer - ERROR - Error installing npm package: npm error code 128
npm error An unknown git error occurred
npm error command git --no-replace-objects ls-remote ssh://git@github.com/ZeparHyfar/mcp-weather.git
npm error git@github.com: Permission denied (publickey).
npm error fatal: Could not read from remote repository.
npm error
npm error Please make sure you have the correct access rights
npm error and the repository exists.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_51_59_071Z-debug-0.log

2025-03-19 05:52:01,378 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:52:01,378 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:52:01,378 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:52:01,378 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:52:01,378 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:52:01,378 - process - INFO - End time: 2025-03-19 05:52:01
2025-03-19 05:52:01,378 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:52:01,378 - process - INFO - Start time: 2025-03-19 05:52:01
2025-03-19 05:52:01,379 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:52:01,379 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:52:01,398 - process - INFO - Sending request to adapter for processing
2025-03-19 05:52:01,399 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:52:01,399 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:52:01,399 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:52:01,400 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:52:01,400 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:52:01,413 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103ba68b0>
2025-03-19 05:52:01,413 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103b8f5c0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:52:01,427 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103be9b50>
2025-03-19 05:52:01,427 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:52:01,428 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:52:01,428 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:52:01,428 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:52:01,428 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:52:02,432 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:52:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:52:01Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:52:01Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:52:02Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:52:01Z'), (b'request-id', b'req_0149sDFe4BFJCHNArDxNKeZY'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227f468fd7dc237-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:52:02,433 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:52:02,433 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:52:02,433 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:52:02,433 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:52:02,433 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:52:02,434 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:52:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:52:01Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:52:01Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:52:02Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:52:01Z', 'request-id': 'req_0149sDFe4BFJCHNArDxNKeZY', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227f468fd7dc237-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:52:02,434 - anthropic._base_client - DEBUG - request_id: req_0149sDFe4BFJCHNArDxNKeZY
2025-03-19 05:52:02,435 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:52:02,435 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:52:02,435 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:52:02,435 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:52:02,435 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:52:02,534 - state_of_mika.installer - INFO - Installing npm package from repository: https://github.com/ZeparHyfar/mcp-weather.git (globally)
2025-03-19 05:52:05,185 - state_of_mika.installer - ERROR - Error installing npm package: npm error code 128
npm error An unknown git error occurred
npm error command git --no-replace-objects ls-remote ssh://git@github.com/ZeparHyfar/mcp-weather.git
npm error git@github.com: Permission denied (publickey).
npm error fatal: Could not read from remote repository.
npm error
npm error Please make sure you have the correct access rights
npm error and the repository exists.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_52_02_597Z-debug-0.log

2025-03-19 05:52:05,186 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:52:05,186 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:52:05,186 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:52:05,186 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:52:05,186 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:52:05,186 - process - INFO - End time: 2025-03-19 05:52:05
2025-03-19 05:52:05,207 - httpcore.connection - DEBUG - close.started
2025-03-19 05:52:05,207 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:52:05,207 - httpcore.connection - DEBUG - close.started
2025-03-19 05:52:05,207 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:52:05,207 - httpcore.connection - DEBUG - close.started
2025-03-19 05:52:05,207 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:54:12,263 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:54:12,264 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:54:12,264 - process - INFO - Start time: 2025-03-19 05:54:12
2025-03-19 05:54:12,264 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:54:12,264 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:54:12,303 - process - INFO - Sending request to adapter for processing
2025-03-19 05:54:12,303 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:54:12,303 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:54:12,304 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:54:12,321 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:54:12,321 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:54:12,336 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10659a120>
2025-03-19 05:54:12,337 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10653e9f0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:54:12,353 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1064c25d0>
2025-03-19 05:54:12,353 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:54:12,353 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:54:12,353 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:54:12,353 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:54:12,353 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:54:13,498 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:54:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:54:12Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:54:12Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:54:13Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:54:12Z'), (b'request-id', b'req_016drJqNLGg5UG9SK781egKY'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227f79bab53e53f-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:54:13,500 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:54:13,500 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:54:13,500 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:54:13,500 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:54:13,500 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:54:13,500 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:54:13 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:54:12Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:54:12Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:54:13Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:54:12Z', 'request-id': 'req_016drJqNLGg5UG9SK781egKY', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227f79bab53e53f-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:54:13,501 - anthropic._base_client - DEBUG - request_id: req_016drJqNLGg5UG9SK781egKY
2025-03-19 05:54:13,507 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:54:13,507 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 05:54:13,507 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:54:13,507 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:54:13,507 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:54:13,710 - state_of_mika.installer - INFO - Installing npm package from repository: https://github.com/ZeparHyfar/mcp-weather.git (globally)
2025-03-19 05:54:16,517 - state_of_mika.installer - ERROR - Error installing npm package: npm error code 128
npm error An unknown git error occurred
npm error command git --no-replace-objects ls-remote ssh://git@github.com/ZeparHyfar/mcp-weather.git
npm error git@github.com: Permission denied (publickey).
npm error fatal: Could not read from remote repository.
npm error
npm error Please make sure you have the correct access rights
npm error and the repository exists.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_54_13_772Z-debug-0.log

2025-03-19 05:54:16,517 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:54:16,517 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:54:16,517 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:54:16,517 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:54:16,518 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:54:16,518 - process - INFO - End time: 2025-03-19 05:54:16
2025-03-19 05:54:16,518 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:54:16,518 - process - INFO - Start time: 2025-03-19 05:54:16
2025-03-19 05:54:16,519 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:54:16,519 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:54:16,544 - process - INFO - Sending request to adapter for processing
2025-03-19 05:54:16,544 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:54:16,544 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:54:16,545 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:54:16,545 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:54:16,545 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:54:16,556 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106901590>
2025-03-19 05:54:16,556 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10653f410> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:54:16,576 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10654a3f0>
2025-03-19 05:54:16,576 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:54:16,576 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:54:16,576 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:54:16,576 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:54:16,576 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:54:17,663 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:54:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:54:16Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:54:17Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:54:17Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:54:17Z'), (b'request-id', b'req_01DkwHYobEFq6pL3MKcP5dhJ'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227f7b60ea49c13-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:54:17,664 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:54:17,664 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:54:17,664 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:54:17,665 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:54:17,665 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:54:17,665 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:54:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:54:16Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:54:17Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:54:17Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:54:17Z', 'request-id': 'req_01DkwHYobEFq6pL3MKcP5dhJ', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227f7b60ea49c13-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:54:17,665 - anthropic._base_client - DEBUG - request_id: req_01DkwHYobEFq6pL3MKcP5dhJ
2025-03-19 05:54:17,666 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:54:17,666 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:54:17,666 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:54:17,666 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:54:17,666 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:54:17,757 - state_of_mika.installer - INFO - Installing npm package from repository: https://github.com/ZeparHyfar/mcp-weather.git (globally)
2025-03-19 05:54:20,142 - state_of_mika.installer - ERROR - Error installing npm package: npm error code 128
npm error An unknown git error occurred
npm error command git --no-replace-objects ls-remote ssh://git@github.com/ZeparHyfar/mcp-weather.git
npm error git@github.com: Permission denied (publickey).
npm error fatal: Could not read from remote repository.
npm error
npm error Please make sure you have the correct access rights
npm error and the repository exists.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_54_17_822Z-debug-0.log

2025-03-19 05:54:20,142 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:54:20,142 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:54:20,142 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:54:20,142 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:54:20,142 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:54:20,143 - process - INFO - End time: 2025-03-19 05:54:20
2025-03-19 05:54:20,143 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:54:20,143 - process - INFO - Start time: 2025-03-19 05:54:20
2025-03-19 05:54:20,144 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:54:20,144 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:54:20,166 - process - INFO - Sending request to adapter for processing
2025-03-19 05:54:20,167 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:54:20,167 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:54:20,167 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:54:20,168 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:54:20,168 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:54:20,177 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10654a780>
2025-03-19 05:54:20,177 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10653f5c0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:54:20,188 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10658db50>
2025-03-19 05:54:20,188 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:54:20,189 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:54:20,189 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:54:20,189 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:54:20,189 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:54:21,257 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:54:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:54:20Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:54:20Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:54:21Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:54:20Z'), (b'request-id', b'req_01NCQa7Y9XgJtqaGxMy3EDR9'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227f7cc9cdbe54d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:54:21,258 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:54:21,258 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:54:21,259 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:54:21,259 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:54:21,259 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:54:21,259 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:54:21 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:54:20Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:54:20Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:54:21Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:54:20Z', 'request-id': 'req_01NCQa7Y9XgJtqaGxMy3EDR9', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227f7cc9cdbe54d-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:54:21,260 - anthropic._base_client - DEBUG - request_id: req_01NCQa7Y9XgJtqaGxMy3EDR9
2025-03-19 05:54:21,260 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:54:21,261 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:54:21,261 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:54:21,261 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:54:21,261 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:54:21,365 - state_of_mika.installer - INFO - Installing npm package from repository: https://github.com/ZeparHyfar/mcp-weather.git (globally)
2025-03-19 05:54:23,832 - state_of_mika.installer - ERROR - Error installing npm package: npm error code 128
npm error An unknown git error occurred
npm error command git --no-replace-objects ls-remote ssh://git@github.com/ZeparHyfar/mcp-weather.git
npm error git@github.com: Permission denied (publickey).
npm error fatal: Could not read from remote repository.
npm error
npm error Please make sure you have the correct access rights
npm error and the repository exists.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_54_21_430Z-debug-0.log

2025-03-19 05:54:23,832 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:54:23,832 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:54:23,832 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:54:23,833 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:54:23,833 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:54:23,833 - process - INFO - End time: 2025-03-19 05:54:23
2025-03-19 05:54:23,860 - httpcore.connection - DEBUG - close.started
2025-03-19 05:54:23,860 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:54:23,860 - httpcore.connection - DEBUG - close.started
2025-03-19 05:54:23,861 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:54:23,861 - httpcore.connection - DEBUG - close.started
2025-03-19 05:54:23,861 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:55:33,673 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 05:55:33,674 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 05:55:33,674 - process - INFO - Start time: 2025-03-19 05:55:33
2025-03-19 05:55:33,674 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:55:33,674 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:55:33,714 - process - INFO - Sending request to adapter for processing
2025-03-19 05:55:33,714 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 05:55:33,714 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 05:55:33,715 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:55:33,735 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:55:33,735 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:55:33,749 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11089a120>
2025-03-19 05:55:33,750 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1108329f0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:55:33,764 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1107c25d0>
2025-03-19 05:55:33,765 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:55:33,765 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:55:33,765 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:55:33,765 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:55:33,765 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:55:34,936 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:55:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:55:33Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:55:34Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:55:34Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:55:34Z'), (b'request-id', b'req_01Tei9GoCbwX58L1gbhia4ni'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227f99879ff7a8a-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:55:34,937 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:55:34,937 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:55:34,942 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:55:34,942 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:55:34,943 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:55:34,943 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:55:34 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:55:33Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:55:34Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:55:34Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:55:34Z', 'request-id': 'req_01Tei9GoCbwX58L1gbhia4ni', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227f99879ff7a8a-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:55:34,944 - anthropic._base_client - DEBUG - request_id: req_01Tei9GoCbwX58L1gbhia4ni
2025-03-19 05:55:34,949 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 05:55:34,949 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 05:55:34,949 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:55:34,949 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:55:34,949 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:55:35,186 - state_of_mika.installer - INFO - Using git+https protocol for repository: git+https://github.com/ZeparHyfar/mcp-weather.git
2025-03-19 05:55:35,187 - state_of_mika.installer - INFO - Installing npm package from repository: git+https://github.com/ZeparHyfar/mcp-weather.git (globally)
2025-03-19 05:55:37,916 - state_of_mika.installer - ERROR - Error installing npm package: npm error code 128
npm error An unknown git error occurred
npm error command git --no-replace-objects ls-remote ssh://git@github.com/ZeparHyfar/mcp-weather.git
npm error git@github.com: Permission denied (publickey).
npm error fatal: Could not read from remote repository.
npm error
npm error Please make sure you have the correct access rights
npm error and the repository exists.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_55_35_246Z-debug-0.log

2025-03-19 05:55:37,917 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:55:37,917 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:55:37,917 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:55:37,917 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:55:37,917 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:55:37,917 - process - INFO - End time: 2025-03-19 05:55:37
2025-03-19 05:55:37,917 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 05:55:37,917 - process - INFO - Start time: 2025-03-19 05:55:37
2025-03-19 05:55:37,917 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:55:37,917 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:55:37,935 - process - INFO - Sending request to adapter for processing
2025-03-19 05:55:37,935 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 05:55:37,935 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 05:55:37,936 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:55:37,936 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:55:37,937 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:55:37,944 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x110d01590>
2025-03-19 05:55:37,944 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110833410> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:55:37,960 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11084a3f0>
2025-03-19 05:55:37,960 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:55:37,960 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:55:37,960 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:55:37,960 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:55:37,960 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:55:38,971 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:55:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:55:38Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:55:38Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:55:38Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:55:38Z'), (b'request-id', b'req_01M25R7Ac18rkzm2ujKd3QzW'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227f9b2a9cae545-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:55:38,972 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:55:38,972 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:55:38,973 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:55:38,973 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:55:38,973 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:55:38,973 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:55:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:55:38Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:55:38Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:55:38Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:55:38Z', 'request-id': 'req_01M25R7Ac18rkzm2ujKd3QzW', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227f9b2a9cae545-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:55:38,973 - anthropic._base_client - DEBUG - request_id: req_01M25R7Ac18rkzm2ujKd3QzW
2025-03-19 05:55:38,974 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:55:38,974 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 05:55:38,974 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:55:38,974 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:55:38,974 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:55:39,090 - state_of_mika.installer - INFO - Using git+https protocol for repository: git+https://github.com/ZeparHyfar/mcp-weather.git
2025-03-19 05:55:39,090 - state_of_mika.installer - INFO - Installing npm package from repository: git+https://github.com/ZeparHyfar/mcp-weather.git (globally)
2025-03-19 05:55:41,597 - state_of_mika.installer - ERROR - Error installing npm package: npm error code 128
npm error An unknown git error occurred
npm error command git --no-replace-objects ls-remote ssh://git@github.com/ZeparHyfar/mcp-weather.git
npm error git@github.com: Permission denied (publickey).
npm error fatal: Could not read from remote repository.
npm error
npm error Please make sure you have the correct access rights
npm error and the repository exists.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_55_39_173Z-debug-0.log

2025-03-19 05:55:41,598 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:55:41,598 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:55:41,598 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:55:41,598 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:55:41,599 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:55:41,599 - process - INFO - End time: 2025-03-19 05:55:41
2025-03-19 05:55:41,599 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:55:41,599 - process - INFO - Start time: 2025-03-19 05:55:41
2025-03-19 05:55:41,600 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 05:55:41,600 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 05:55:41,622 - process - INFO - Sending request to adapter for processing
2025-03-19 05:55:41,622 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:55:41,622 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 05:55:41,623 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 05:55:41,623 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 05:55:41,623 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 05:55:41,634 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11084a8b0>
2025-03-19 05:55:41,634 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1108335c0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 05:55:41,648 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11088db50>
2025-03-19 05:55:41,648 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 05:55:41,649 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 05:55:41,649 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 05:55:41,649 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 05:55:41,649 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 05:55:42,697 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 21:55:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T21:55:41Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T21:55:42Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T21:55:42Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T21:55:42Z'), (b'request-id', b'req_01YTsrzZL7hoW7S4JSyLBLS6'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9227f9c9bf9b6d6b-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 05:55:42,698 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 05:55:42,699 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 05:55:42,699 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 05:55:42,699 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 05:55:42,699 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 05:55:42,699 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 21:55:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T21:55:41Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T21:55:42Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T21:55:42Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T21:55:42Z', 'request-id': 'req_01YTsrzZL7hoW7S4JSyLBLS6', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9227f9c9bf9b6d6b-KUL', 'content-encoding': 'gzip'})
2025-03-19 05:55:42,700 - anthropic._base_client - DEBUG - request_id: req_01YTsrzZL7hoW7S4JSyLBLS6
2025-03-19 05:55:42,700 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:55:42,701 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 05:55:42,701 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 05:55:42,701 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 05:55:42,701 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 05:55:42,804 - state_of_mika.installer - INFO - Using git+https protocol for repository: git+https://github.com/ZeparHyfar/mcp-weather.git
2025-03-19 05:55:42,804 - state_of_mika.installer - INFO - Installing npm package from repository: git+https://github.com/ZeparHyfar/mcp-weather.git (globally)
2025-03-19 05:55:45,235 - state_of_mika.installer - ERROR - Error installing npm package: npm error code 128
npm error An unknown git error occurred
npm error command git --no-replace-objects ls-remote ssh://git@github.com/ZeparHyfar/mcp-weather.git
npm error git@github.com: Permission denied (publickey).
npm error fatal: Could not read from remote repository.
npm error
npm error Please make sure you have the correct access rights
npm error and the repository exists.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T21_55_42_865Z-debug-0.log

2025-03-19 05:55:45,235 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 05:55:45,235 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 05:55:45,235 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 05:55:45,235 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 05:55:45,235 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 05:55:45,235 - process - INFO - End time: 2025-03-19 05:55:45
2025-03-19 05:55:45,258 - httpcore.connection - DEBUG - close.started
2025-03-19 05:55:45,259 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:55:45,259 - httpcore.connection - DEBUG - close.started
2025-03-19 05:55:45,259 - httpcore.connection - DEBUG - close.complete
2025-03-19 05:55:45,259 - httpcore.connection - DEBUG - close.started
2025-03-19 05:55:45,259 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:00:44,611 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 06:00:44,612 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 06:00:44,612 - process - INFO - Start time: 2025-03-19 06:00:44
2025-03-19 06:00:44,612 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:00:44,612 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:00:44,649 - process - INFO - Sending request to adapter for processing
2025-03-19 06:00:44,650 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 06:00:44,650 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 06:00:44,651 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:00:44,669 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:00:44,669 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:00:44,701 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105ac6120>
2025-03-19 06:00:44,702 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105a5e9f0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:00:44,718 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1059ea5d0>
2025-03-19 06:00:44,719 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:00:44,719 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:00:44,719 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:00:44,719 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:00:44,719 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:00:45,862 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:00:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:00:44Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:00:45Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:00:45Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:00:45Z'), (b'request-id', b'req_01NLVDkXTEjiZhGFB4gXC71b'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9228012fec4ad89d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:00:45,864 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:00:45,864 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:00:45,865 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:00:45,865 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:00:45,865 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:00:45,865 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:00:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:00:44Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:00:45Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:00:45Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:00:45Z', 'request-id': 'req_01NLVDkXTEjiZhGFB4gXC71b', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9228012fec4ad89d-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:00:45,865 - anthropic._base_client - DEBUG - request_id: req_01NLVDkXTEjiZhGFB4gXC71b
2025-03-19 06:00:45,872 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'timeframe': 'today'}}
2025-03-19 06:00:45,872 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'timeframe': 'today'}}
2025-03-19 06:00:45,872 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:00:45,872 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:00:45,872 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:00:46,082 - state_of_mika.installer - INFO - Installing npm package from GitHub tarball: https://github.com/ZeparHyfar/mcp-weather/tarball/main
2025-03-19 06:00:46,771 - state_of_mika.installer - ERROR - Error installing npm package from tarball: npm error code E404
npm error 404 Not Found - GET https://github.com/ZeparHyfar/mcp-weather/tarball/main
npm error 404
npm error 404  'https://github.com/ZeparHyfar/mcp-weather/tarball/main' is not in this registry.
npm error 404 This package name is not valid, because 
npm error 404  1. name can only contain URL-friendly characters
npm error 404  2. name can no longer contain capital letters
npm error 404
npm error 404 Note that you can also install from a
npm error 404 tarball, folder, http url, or git url.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T22_00_46_149Z-debug-0.log

2025-03-19 06:00:46,772 - state_of_mika.installer - INFO - Falling back to standard npm install for mcp-weather
2025-03-19 06:00:46,772 - state_of_mika.installer - INFO - Installing npm package from repository: https://github.com/ZeparHyfar/mcp-weather.git (globally)
2025-03-19 06:00:49,157 - state_of_mika.installer - ERROR - Error installing npm package: npm error code 128
npm error An unknown git error occurred
npm error command git --no-replace-objects ls-remote ssh://git@github.com/ZeparHyfar/mcp-weather.git
npm error git@github.com: Permission denied (publickey).
npm error fatal: Could not read from remote repository.
npm error
npm error Please make sure you have the correct access rights
npm error and the repository exists.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T22_00_46_844Z-debug-0.log

2025-03-19 06:00:49,157 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 06:00:49,157 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 06:00:49,157 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 06:00:49,157 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 06:00:49,157 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:00:49,157 - process - INFO - End time: 2025-03-19 06:00:49
2025-03-19 06:00:49,158 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 06:00:49,158 - process - INFO - Start time: 2025-03-19 06:00:49
2025-03-19 06:00:49,158 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:00:49,158 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:00:49,176 - process - INFO - Sending request to adapter for processing
2025-03-19 06:00:49,177 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 06:00:49,177 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 06:00:49,177 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:00:49,178 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:00:49,178 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:00:49,190 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105bed590>
2025-03-19 06:00:49,190 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105a5ef00> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:00:49,207 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105a7a3f0>
2025-03-19 06:00:49,207 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:00:49,207 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:00:49,207 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:00:49,207 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:00:49,207 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:00:50,233 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:00:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:00:49Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:00:49Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:00:50Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:00:49Z'), (b'request-id', b'req_01D3oHbLZkVX4muNVUsBLd1j'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9228014bffed38a5-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:00:50,234 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:00:50,234 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:00:50,235 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:00:50,235 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:00:50,235 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:00:50,235 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:00:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:00:49Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:00:49Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:00:50Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:00:49Z', 'request-id': 'req_01D3oHbLZkVX4muNVUsBLd1j', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9228014bffed38a5-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:00:50,235 - anthropic._base_client - DEBUG - request_id: req_01D3oHbLZkVX4muNVUsBLd1j
2025-03-19 06:00:50,235 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 06:00:50,235 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 06:00:50,235 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:00:50,235 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:00:50,235 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:00:50,336 - state_of_mika.installer - INFO - Installing npm package from GitHub tarball: https://github.com/ZeparHyfar/mcp-weather/tarball/main
2025-03-19 06:00:50,615 - state_of_mika.installer - ERROR - Error installing npm package from tarball: npm error code E404
npm error 404 Not Found - GET https://github.com/ZeparHyfar/mcp-weather/tarball/main
npm error 404
npm error 404  'https://github.com/ZeparHyfar/mcp-weather/tarball/main' is not in this registry.
npm error 404 This package name is not valid, because 
npm error 404  1. name can only contain URL-friendly characters
npm error 404  2. name can no longer contain capital letters
npm error 404
npm error 404 Note that you can also install from a
npm error 404 tarball, folder, http url, or git url.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T22_00_50_399Z-debug-0.log

2025-03-19 06:00:50,616 - state_of_mika.installer - INFO - Falling back to standard npm install for mcp-weather
2025-03-19 06:00:50,616 - state_of_mika.installer - INFO - Installing npm package from repository: https://github.com/ZeparHyfar/mcp-weather.git (globally)
2025-03-19 06:00:53,213 - state_of_mika.installer - ERROR - Error installing npm package: npm error code 128
npm error An unknown git error occurred
npm error command git --no-replace-objects ls-remote ssh://git@github.com/ZeparHyfar/mcp-weather.git
npm error git@github.com: Permission denied (publickey).
npm error fatal: Could not read from remote repository.
npm error
npm error Please make sure you have the correct access rights
npm error and the repository exists.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T22_00_50_680Z-debug-0.log

2025-03-19 06:00:53,213 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 06:00:53,213 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 06:00:53,213 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 06:00:53,213 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 06:00:53,213 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:00:53,214 - process - INFO - End time: 2025-03-19 06:00:53
2025-03-19 06:00:53,214 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:00:53,214 - process - INFO - Start time: 2025-03-19 06:00:53
2025-03-19 06:00:53,214 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:00:53,214 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:00:53,238 - process - INFO - Sending request to adapter for processing
2025-03-19 06:00:53,238 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:00:53,238 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:00:53,239 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:00:53,239 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:00:53,239 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:00:53,250 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105a79f30>
2025-03-19 06:00:53,250 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105a5f410> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:00:53,262 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105ab9910>
2025-03-19 06:00:53,262 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:00:53,263 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:00:53,263 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:00:53,263 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:00:53,263 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:00:54,338 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:00:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:00:53Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:00:53Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:00:54Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:00:53Z'), (b'request-id', b'req_017LVp6U3BmNDayH3XVe7dWZ'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'92280165592f8697-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:00:54,339 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:00:54,339 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:00:54,340 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:00:54,340 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:00:54,340 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:00:54,340 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:00:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:00:53Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:00:53Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:00:54Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:00:53Z', 'request-id': 'req_017LVp6U3BmNDayH3XVe7dWZ', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '92280165592f8697-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:00:54,340 - anthropic._base_client - DEBUG - request_id: req_017LVp6U3BmNDayH3XVe7dWZ
2025-03-19 06:00:54,341 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 06:00:54,341 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 06:00:54,341 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:00:54,341 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:00:54,341 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:00:54,446 - state_of_mika.installer - INFO - Installing npm package from GitHub tarball: https://github.com/ZeparHyfar/mcp-weather/tarball/main
2025-03-19 06:00:54,735 - state_of_mika.installer - ERROR - Error installing npm package from tarball: npm error code E404
npm error 404 Not Found - GET https://github.com/ZeparHyfar/mcp-weather/tarball/main
npm error 404
npm error 404  'https://github.com/ZeparHyfar/mcp-weather/tarball/main' is not in this registry.
npm error 404 This package name is not valid, because 
npm error 404  1. name can only contain URL-friendly characters
npm error 404  2. name can no longer contain capital letters
npm error 404
npm error 404 Note that you can also install from a
npm error 404 tarball, folder, http url, or git url.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T22_00_54_507Z-debug-0.log

2025-03-19 06:00:54,735 - state_of_mika.installer - INFO - Falling back to standard npm install for mcp-weather
2025-03-19 06:00:54,735 - state_of_mika.installer - INFO - Installing npm package from repository: https://github.com/ZeparHyfar/mcp-weather.git (globally)
2025-03-19 06:00:57,103 - state_of_mika.installer - ERROR - Error installing npm package: npm error code 128
npm error An unknown git error occurred
npm error command git --no-replace-objects ls-remote ssh://git@github.com/ZeparHyfar/mcp-weather.git
npm error git@github.com: Permission denied (publickey).
npm error fatal: Could not read from remote repository.
npm error
npm error Please make sure you have the correct access rights
npm error and the repository exists.
npm error A complete log of this run can be found in: /Users/yongjoekit/.npm/_logs/2025-03-18T22_00_54_798Z-debug-0.log

2025-03-19 06:00:57,104 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 06:00:57,104 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 06:00:57,104 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 06:00:57,104 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 06:00:57,104 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:00:57,104 - process - INFO - End time: 2025-03-19 06:00:57
2025-03-19 06:00:57,138 - httpcore.connection - DEBUG - close.started
2025-03-19 06:00:57,139 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:00:57,139 - httpcore.connection - DEBUG - close.started
2025-03-19 06:00:57,139 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:00:57,139 - httpcore.connection - DEBUG - close.started
2025-03-19 06:00:57,139 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:01:56,260 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 06:01:56,261 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 06:01:56,261 - process - INFO - Start time: 2025-03-19 06:01:56
2025-03-19 06:01:56,261 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:01:56,261 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:01:56,296 - process - INFO - Sending request to adapter for processing
2025-03-19 06:01:56,297 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 06:01:56,297 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 06:01:56,298 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:01:56,317 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:01:56,317 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:01:56,330 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105a9a120>
2025-03-19 06:01:56,330 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105a329f0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:01:56,357 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1058c25d0>
2025-03-19 06:01:56,357 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:01:56,358 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:01:56,358 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:01:56,358 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:01:56,358 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:01:57,538 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:01:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:01:56Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:01:56Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:01:57Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:01:56Z'), (b'request-id', b'req_01A1RyG3pX8C3LksgCb25Eqj'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922802efbe9ae58b-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:01:57,539 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:01:57,540 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:01:57,540 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:01:57,540 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:01:57,540 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:01:57,540 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:01:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:01:56Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:01:56Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:01:57Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:01:56Z', 'request-id': 'req_01A1RyG3pX8C3LksgCb25Eqj', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922802efbe9ae58b-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:01:57,541 - anthropic._base_client - DEBUG - request_id: req_01A1RyG3pX8C3LksgCb25Eqj
2025-03-19 06:01:57,546 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 06:01:57,546 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 06:01:57,546 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:01:57,546 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:01:57,546 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:01:57,547 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:01:57,547 - state_of_mika.installer - INFO - Installing from repository: https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:01:57,561 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:01:57,561 - state_of_mika.installer - WARNING - Falling back to pip for installing https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:01:58,876 - state_of_mika.installer - ERROR - Error installing https://github.com/adhikasp/mcp-weather.git with pip:   ERROR: Cannot unpack file /private/var/folders/3r/1b5c01q12_v2kcvc7_11swpc0000gn/T/pip-unpack-l_hk_lna/mcp-weather.git (downloaded from /private/var/folders/3r/1b5c01q12_v2kcvc7_11swpc0000gn/T/pip-req-build-yf9ym_v4, content-type: text/html; charset=utf-8); cannot detect archive format
ERROR: Cannot determine archive format of /private/var/folders/3r/1b5c01q12_v2kcvc7_11swpc0000gn/T/pip-req-build-yf9ym_v4

2025-03-19 06:01:58,876 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 06:01:58,877 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 06:01:58,877 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 06:01:58,877 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 06:01:58,877 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:01:58,877 - process - INFO - End time: 2025-03-19 06:01:58
2025-03-19 06:01:58,877 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 06:01:58,877 - process - INFO - Start time: 2025-03-19 06:01:58
2025-03-19 06:01:58,877 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:01:58,877 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:01:58,895 - process - INFO - Sending request to adapter for processing
2025-03-19 06:01:58,895 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 06:01:58,895 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 06:01:58,895 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:01:58,896 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:01:58,896 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:01:58,907 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105af9590>
2025-03-19 06:01:58,907 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105a332f0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:01:58,921 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105a4e3f0>
2025-03-19 06:01:58,921 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:01:58,921 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:01:58,921 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:01:58,921 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:01:58,921 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:01:59,952 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:02:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:01:59Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:01:59Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:01:59Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:01:59Z'), (b'request-id', b'req_0183aSFAYcKnmZHrPVxK5mvh'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922802ffbd38a844-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:01:59,953 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:01:59,954 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:01:59,954 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:01:59,954 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:01:59,954 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:01:59,954 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:02:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:01:59Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:01:59Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:01:59Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:01:59Z', 'request-id': 'req_0183aSFAYcKnmZHrPVxK5mvh', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922802ffbd38a844-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:01:59,954 - anthropic._base_client - DEBUG - request_id: req_0183aSFAYcKnmZHrPVxK5mvh
2025-03-19 06:01:59,955 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 06:01:59,955 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 06:01:59,955 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:01:59,955 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:01:59,955 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:01:59,955 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:01:59,955 - state_of_mika.installer - INFO - Installing from repository: https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:01:59,963 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:01:59,964 - state_of_mika.installer - WARNING - Falling back to pip for installing https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:00,335 - state_of_mika.installer - ERROR - Error installing https://github.com/adhikasp/mcp-weather.git with pip:   ERROR: Cannot unpack file /private/var/folders/3r/1b5c01q12_v2kcvc7_11swpc0000gn/T/pip-unpack-4fut5vhq/mcp-weather.git (downloaded from /private/var/folders/3r/1b5c01q12_v2kcvc7_11swpc0000gn/T/pip-req-build-ted_ra6c, content-type: text/html; charset=utf-8); cannot detect archive format
ERROR: Cannot determine archive format of /private/var/folders/3r/1b5c01q12_v2kcvc7_11swpc0000gn/T/pip-req-build-ted_ra6c

2025-03-19 06:02:00,336 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 06:02:00,336 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 06:02:00,336 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 06:02:00,336 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 06:02:00,336 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:02:00,336 - process - INFO - End time: 2025-03-19 06:02:00
2025-03-19 06:02:00,336 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:02:00,336 - process - INFO - Start time: 2025-03-19 06:02:00
2025-03-19 06:02:00,336 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:02:00,336 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:02:00,353 - process - INFO - Sending request to adapter for processing
2025-03-19 06:02:00,353 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:02:00,353 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:02:00,354 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:02:00,355 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:02:00,355 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:02:00,369 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105a4eea0>
2025-03-19 06:02:00,369 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105a33380> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:02:00,381 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105a8c170>
2025-03-19 06:02:00,381 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:02:00,381 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:02:00,381 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:02:00,381 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:02:00,381 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:02:01,600 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:02:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:02:00Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:02:01Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:02:01Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:02:01Z'), (b'request-id', b'req_01L7csQJRFZRFMDQhAUV8H4R'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'92280308daffe541-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:02:01,601 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:02:01,601 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:02:01,602 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:02:01,602 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:02:01,602 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:02:01,602 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:02:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:02:00Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:02:01Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:02:01Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:02:01Z', 'request-id': 'req_01L7csQJRFZRFMDQhAUV8H4R', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '92280308daffe541-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:02:01,602 - anthropic._base_client - DEBUG - request_id: req_01L7csQJRFZRFMDQhAUV8H4R
2025-03-19 06:02:01,603 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 06:02:01,603 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 06:02:01,603 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:02:01,603 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:02:01,603 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:02:01,603 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:01,603 - state_of_mika.installer - INFO - Installing from repository: https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:01,611 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:02:01,612 - state_of_mika.installer - WARNING - Falling back to pip for installing https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:01,984 - state_of_mika.installer - ERROR - Error installing https://github.com/adhikasp/mcp-weather.git with pip:   ERROR: Cannot unpack file /private/var/folders/3r/1b5c01q12_v2kcvc7_11swpc0000gn/T/pip-unpack-cvvkssv1/mcp-weather.git (downloaded from /private/var/folders/3r/1b5c01q12_v2kcvc7_11swpc0000gn/T/pip-req-build-vh1xrbpo, content-type: text/html; charset=utf-8); cannot detect archive format
ERROR: Cannot determine archive format of /private/var/folders/3r/1b5c01q12_v2kcvc7_11swpc0000gn/T/pip-req-build-vh1xrbpo

2025-03-19 06:02:01,984 - state_of_mika.connector - ERROR - Failed to install server for capability: weather
2025-03-19 06:02:01,984 - state_of_mika.adapters.claude - ERROR - No server found for capability: weather
2025-03-19 06:02:01,984 - result - WARNING - Request processing failed: No server available for capability: weather
2025-03-19 06:02:01,984 - result - DEBUG - Final result: {
  "success": false,
  "error": "No server available for capability: weather"
}
2025-03-19 06:02:01,984 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:02:01,984 - process - INFO - End time: 2025-03-19 06:02:01
2025-03-19 06:02:02,004 - httpcore.connection - DEBUG - close.started
2025-03-19 06:02:02,004 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:02:02,004 - httpcore.connection - DEBUG - close.started
2025-03-19 06:02:02,004 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:02:02,004 - httpcore.connection - DEBUG - close.started
2025-03-19 06:02:02,004 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:02:26,844 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 06:02:26,844 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 06:02:26,844 - process - INFO - Start time: 2025-03-19 06:02:26
2025-03-19 06:02:26,845 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:02:26,845 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:02:26,880 - process - INFO - Sending request to adapter for processing
2025-03-19 06:02:26,880 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 06:02:26,880 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 06:02:26,881 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:02:26,897 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:02:26,897 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:02:26,912 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10909a120>
2025-03-19 06:02:26,912 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1090329f0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:02:26,927 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x108fc25d0>
2025-03-19 06:02:26,927 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:02:26,927 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:02:26,927 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:02:26,927 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:02:26,927 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:02:28,092 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:02:28 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:02:27Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:02:27Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:02:28Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:02:27Z'), (b'request-id', b'req_01XpqRWpjDsCnQZwRfaSBudn'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922803aebf08e588-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:02:28,094 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:02:28,094 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:02:28,099 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:02:28,099 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:02:28,099 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:02:28,099 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:02:28 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:02:27Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:02:27Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:02:28Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:02:27Z', 'request-id': 'req_01XpqRWpjDsCnQZwRfaSBudn', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922803aebf08e588-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:02:28,100 - anthropic._base_client - DEBUG - request_id: req_01XpqRWpjDsCnQZwRfaSBudn
2025-03-19 06:02:28,105 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 06:02:28,106 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 06:02:28,106 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:02:28,106 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:02:28,106 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:02:28,106 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:28,106 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:28,106 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:28,114 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:02:28,114 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:32,027 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:02:32,028 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:02:32,028 - state_of_mika.adapters.claude - ERROR - Error executing tool: Installer.install_server() takes 2 positional arguments but 3 were given
2025-03-19 06:02:32,028 - result - WARNING - Request processing failed: Failed to execute get_weather for capability weather: Installer.install_server() takes 2 positional arguments but 3 were given
2025-03-19 06:02:32,028 - result - DEBUG - Final result: {
  "success": false,
  "error": "Failed to execute get_weather for capability weather: Installer.install_server() takes 2 positional arguments but 3 were given"
}
2025-03-19 06:02:32,028 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:02:32,028 - process - INFO - End time: 2025-03-19 06:02:32
2025-03-19 06:02:32,028 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 06:02:32,028 - process - INFO - Start time: 2025-03-19 06:02:32
2025-03-19 06:02:32,028 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:02:32,029 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:02:32,046 - process - INFO - Sending request to adapter for processing
2025-03-19 06:02:32,046 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 06:02:32,046 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 06:02:32,047 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:02:32,048 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:02:32,048 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:02:32,057 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1090f9590>
2025-03-19 06:02:32,057 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x109032ba0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:02:32,070 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10904e3f0>
2025-03-19 06:02:32,070 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:02:32,070 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:02:32,070 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:02:32,070 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:02:32,070 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:02:33,312 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:02:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:02:32Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:02:32Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:02:33Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:02:32Z'), (b'request-id', b'req_01LhNPAXwzwcnqyyP7K5RdAh'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922803ceecef435a-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:02:33,313 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:02:33,314 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:02:33,314 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:02:33,314 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:02:33,314 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:02:33,315 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:02:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:02:32Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:02:32Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:02:33Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:02:32Z', 'request-id': 'req_01LhNPAXwzwcnqyyP7K5RdAh', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922803ceecef435a-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:02:33,315 - anthropic._base_client - DEBUG - request_id: req_01LhNPAXwzwcnqyyP7K5RdAh
2025-03-19 06:02:33,315 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 06:02:33,315 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 06:02:33,315 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:02:33,315 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:02:33,316 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:02:33,316 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:33,316 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:33,316 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:33,321 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:02:33,321 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:37,003 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:02:37,004 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:02:37,004 - state_of_mika.adapters.claude - ERROR - Error executing tool: Installer.install_server() takes 2 positional arguments but 3 were given
2025-03-19 06:02:37,004 - result - WARNING - Request processing failed: Failed to execute get_weather for capability weather: Installer.install_server() takes 2 positional arguments but 3 were given
2025-03-19 06:02:37,004 - result - DEBUG - Final result: {
  "success": false,
  "error": "Failed to execute get_weather for capability weather: Installer.install_server() takes 2 positional arguments but 3 were given"
}
2025-03-19 06:02:37,004 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:02:37,004 - process - INFO - End time: 2025-03-19 06:02:37
2025-03-19 06:02:37,004 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:02:37,004 - process - INFO - Start time: 2025-03-19 06:02:37
2025-03-19 06:02:37,004 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:02:37,004 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:02:37,022 - process - INFO - Sending request to adapter for processing
2025-03-19 06:02:37,022 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:02:37,022 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:02:37,022 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:02:37,023 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:02:37,023 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:02:37,033 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10904eea0>
2025-03-19 06:02:37,034 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x109033410> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:02:37,046 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10908c170>
2025-03-19 06:02:37,046 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:02:37,046 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:02:37,046 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:02:37,046 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:02:37,046 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:02:38,258 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:02:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:02:37Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:02:37Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:02:38Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:02:37Z'), (b'request-id', b'req_01GzEiijF2HnvErAX8hnjQbK'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922803edfe90e580-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:02:38,258 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:02:38,258 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:02:38,258 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:02:38,258 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:02:38,259 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:02:38,259 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:02:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:02:37Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:02:37Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:02:38Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:02:37Z', 'request-id': 'req_01GzEiijF2HnvErAX8hnjQbK', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922803edfe90e580-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:02:38,259 - anthropic._base_client - DEBUG - request_id: req_01GzEiijF2HnvErAX8hnjQbK
2025-03-19 06:02:38,259 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 06:02:38,259 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 06:02:38,259 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:02:38,259 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:02:38,259 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:02:38,259 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:38,259 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:38,259 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:38,262 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:02:38,262 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:02:41,282 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:02:41,283 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:02:41,283 - state_of_mika.adapters.claude - ERROR - Error executing tool: Installer.install_server() takes 2 positional arguments but 3 were given
2025-03-19 06:02:41,283 - result - WARNING - Request processing failed: Failed to execute get_weather for capability weather: Installer.install_server() takes 2 positional arguments but 3 were given
2025-03-19 06:02:41,283 - result - DEBUG - Final result: {
  "success": false,
  "error": "Failed to execute get_weather for capability weather: Installer.install_server() takes 2 positional arguments but 3 were given"
}
2025-03-19 06:02:41,283 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:02:41,283 - process - INFO - End time: 2025-03-19 06:02:41
2025-03-19 06:02:41,305 - httpcore.connection - DEBUG - close.started
2025-03-19 06:02:41,305 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:02:41,305 - httpcore.connection - DEBUG - close.started
2025-03-19 06:02:41,305 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:02:41,305 - httpcore.connection - DEBUG - close.started
2025-03-19 06:02:41,305 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:03:52,363 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 06:03:52,364 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 06:03:52,364 - process - INFO - Start time: 2025-03-19 06:03:52
2025-03-19 06:03:52,365 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:03:52,365 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:03:52,401 - process - INFO - Sending request to adapter for processing
2025-03-19 06:03:52,402 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 06:03:52,402 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 06:03:52,403 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:03:52,420 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:03:52,420 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:03:52,433 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10499a120>
2025-03-19 06:03:52,433 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1049329f0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:03:52,448 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1048c25d0>
2025-03-19 06:03:52,448 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:03:52,449 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:03:52,449 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:03:52,449 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:03:52,449 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:03:54,961 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:03:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:03:52Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:03:54Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:03:54Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:03:54Z'), (b'request-id', b'req_014gUjwHzanDiNM7TMY5qV5U'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922805c54bf7d42f-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:03:54,967 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:03:54,967 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:03:54,967 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:03:54,967 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:03:54,967 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:03:54,968 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:03:54 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:03:52Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:03:54Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:03:54Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:03:54Z', 'request-id': 'req_014gUjwHzanDiNM7TMY5qV5U', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922805c54bf7d42f-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:03:54,970 - anthropic._base_client - DEBUG - request_id: req_014gUjwHzanDiNM7TMY5qV5U
2025-03-19 06:03:55,005 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 06:03:55,005 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 06:03:55,006 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:03:55,006 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:03:55,006 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:03:55,006 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:03:55,006 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:03:55,006 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:03:55,028 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:03:55,029 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:03:58,046 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:03:58,046 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:03:58,046 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:03:58,046 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:03:58,046 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:03:58,046 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:03:58,049 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:03:58,049 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:00,785 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:04:00,786 - state_of_mika.connector - ERROR - Failed to connect to server mcp_weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 06:04:00,786 - state_of_mika.adapters.claude - ERROR - Error executing tool: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 06:04:00,786 - result - WARNING - Request processing failed: Failed to execute get_weather for capability weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 06:04:00,786 - result - DEBUG - Final result: {
  "success": false,
  "error": "Failed to execute get_weather for capability weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value"
}
2025-03-19 06:04:00,786 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:04:00,786 - process - INFO - End time: 2025-03-19 06:04:00
2025-03-19 06:04:00,786 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 06:04:00,786 - process - INFO - Start time: 2025-03-19 06:04:00
2025-03-19 06:04:00,787 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:04:00,787 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:04:00,803 - process - INFO - Sending request to adapter for processing
2025-03-19 06:04:00,803 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 06:04:00,804 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 06:04:00,804 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:04:00,805 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:04:00,805 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:04:00,816 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1049fd590>
2025-03-19 06:04:00,816 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104933020> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:04:00,830 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104936520>
2025-03-19 06:04:00,830 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:04:00,830 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:04:00,830 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:04:00,831 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:04:00,831 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:04:02,596 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:04:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:04:01Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:04:01Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:04:02Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:04:01Z'), (b'request-id', b'req_013XaxXjmQXMKG54baLftqpM'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922805f9acdf4f1e-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:04:02,598 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:04:02,598 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:04:02,598 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:04:02,598 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:04:02,598 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:04:02,599 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:04:02 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:04:01Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:04:01Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:04:02Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:04:01Z', 'request-id': 'req_013XaxXjmQXMKG54baLftqpM', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922805f9acdf4f1e-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:04:02,599 - anthropic._base_client - DEBUG - request_id: req_013XaxXjmQXMKG54baLftqpM
2025-03-19 06:04:02,599 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 06:04:02,600 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 06:04:02,600 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:04:02,600 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:04:02,600 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:04:02,600 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:02,600 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:02,600 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:02,604 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:04:02,604 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:05,374 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:04:05,374 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:04:05,374 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:04:05,374 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:05,375 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:05,375 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:05,377 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:04:05,377 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:08,547 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:04:08,547 - state_of_mika.connector - ERROR - Failed to connect to server mcp_weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 06:04:08,547 - state_of_mika.adapters.claude - ERROR - Error executing tool: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 06:04:08,547 - result - WARNING - Request processing failed: Failed to execute get_weather for capability weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 06:04:08,547 - result - DEBUG - Final result: {
  "success": false,
  "error": "Failed to execute get_weather for capability weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value"
}
2025-03-19 06:04:08,547 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:04:08,547 - process - INFO - End time: 2025-03-19 06:04:08
2025-03-19 06:04:08,547 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:04:08,548 - process - INFO - Start time: 2025-03-19 06:04:08
2025-03-19 06:04:08,548 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:04:08,548 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:04:08,566 - process - INFO - Sending request to adapter for processing
2025-03-19 06:04:08,566 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:04:08,566 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:04:08,567 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:04:08,567 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:04:08,567 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:04:08,580 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1049369e0>
2025-03-19 06:04:08,580 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104933380> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:04:08,595 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10498deb0>
2025-03-19 06:04:08,595 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:04:08,596 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:04:08,596 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:04:08,596 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:04:08,596 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:04:09,808 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:04:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:04:08Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:04:09Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:04:09Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:04:09Z'), (b'request-id', b'req_01NaPSPMeS9EgRF6iHfbN4W9'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9228062a288bfa4d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:04:09,808 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:04:09,808 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:04:09,808 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:04:09,808 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:04:09,808 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:04:09,808 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:04:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:04:08Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:04:09Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:04:09Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:04:09Z', 'request-id': 'req_01NaPSPMeS9EgRF6iHfbN4W9', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9228062a288bfa4d-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:04:09,809 - anthropic._base_client - DEBUG - request_id: req_01NaPSPMeS9EgRF6iHfbN4W9
2025-03-19 06:04:09,809 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 06:04:09,809 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 06:04:09,809 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:04:09,809 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:04:09,809 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:04:09,809 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:09,809 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:09,809 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:09,812 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:04:09,812 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:12,844 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:04:12,845 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:04:12,845 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:04:12,845 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:12,845 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:12,845 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:12,848 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:04:12,848 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:04:15,611 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:04:15,612 - state_of_mika.connector - ERROR - Failed to connect to server mcp_weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 06:04:15,612 - state_of_mika.adapters.claude - ERROR - Error executing tool: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 06:04:15,612 - result - WARNING - Request processing failed: Failed to execute get_weather for capability weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value
2025-03-19 06:04:15,612 - result - DEBUG - Final result: {
  "success": false,
  "error": "Failed to execute get_weather for capability weather: cannot access local variable 'StdioServerParameters' where it is not associated with a value"
}
2025-03-19 06:04:15,612 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:04:15,612 - process - INFO - End time: 2025-03-19 06:04:15
2025-03-19 06:04:15,632 - httpcore.connection - DEBUG - close.started
2025-03-19 06:04:15,632 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:04:15,632 - httpcore.connection - DEBUG - close.started
2025-03-19 06:04:15,632 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:04:15,632 - httpcore.connection - DEBUG - close.started
2025-03-19 06:04:15,633 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:06:14,586 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 06:06:14,587 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 06:06:14,587 - process - INFO - Start time: 2025-03-19 06:06:14
2025-03-19 06:06:14,587 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:06:14,587 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:06:14,626 - process - INFO - Sending request to adapter for processing
2025-03-19 06:06:14,626 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 06:06:14,626 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 06:06:14,627 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:06:14,645 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:06:14,646 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:06:14,664 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1075e17f0>
2025-03-19 06:06:14,664 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107562d50> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:06:14,685 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107467d90>
2025-03-19 06:06:14,685 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:06:14,686 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:06:14,686 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:06:14,686 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:06:14,686 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:06:17,248 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:06:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:06:14Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:06:16Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:06:17Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:06:16Z'), (b'request-id', b'req_019YSpUotJPfsG4AfBmD2VnZ'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9228093e4e83392d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:06:17,249 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:06:17,249 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:06:17,250 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:06:17,250 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:06:17,250 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:06:17,250 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:06:17 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:06:14Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:06:16Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:06:17Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:06:16Z', 'request-id': 'req_019YSpUotJPfsG4AfBmD2VnZ', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9228093e4e83392d-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:06:17,250 - anthropic._base_client - DEBUG - request_id: req_019YSpUotJPfsG4AfBmD2VnZ
2025-03-19 06:06:17,255 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 06:06:17,255 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 06:06:17,255 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:06:17,255 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:06:17,255 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:06:17,255 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:06:17,255 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:06:17,255 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:06:17,259 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:06:17,259 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:06:20,178 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:06:20,279 - state_of_mika.adapters.claude - ERROR - Error executing tool: 'Registry' object has no attribute 'get_server'
2025-03-19 06:06:20,279 - result - WARNING - Request processing failed: Failed to execute get_weather for capability weather: 'Registry' object has no attribute 'get_server'
2025-03-19 06:06:20,279 - result - DEBUG - Final result: {
  "success": false,
  "error": "Failed to execute get_weather for capability weather: 'Registry' object has no attribute 'get_server'"
}
2025-03-19 06:06:20,279 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:06:20,279 - process - INFO - End time: 2025-03-19 06:06:20
2025-03-19 06:06:20,279 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 06:06:20,279 - process - INFO - Start time: 2025-03-19 06:06:20
2025-03-19 06:06:20,279 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:06:20,279 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:06:20,296 - process - INFO - Sending request to adapter for processing
2025-03-19 06:06:20,296 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 06:06:20,296 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 06:06:20,297 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:06:20,297 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:06:20,297 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:06:20,310 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107ee1310>
2025-03-19 06:06:20,310 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107e66cc0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:06:20,322 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107d9e520>
2025-03-19 06:06:20,322 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:06:20,322 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:06:20,322 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:06:20,323 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:06:20,323 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:06:22,147 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:06:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:06:21Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:06:21Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:06:22Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:06:21Z'), (b'request-id', b'req_0124buKvPwBsptPy8ApVow8x'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922809617ad0d432-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:06:22,148 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:06:22,148 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:06:22,148 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:06:22,148 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:06:22,148 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:06:22,148 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:06:22 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:06:21Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:06:21Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:06:22Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:06:21Z', 'request-id': 'req_0124buKvPwBsptPy8ApVow8x', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922809617ad0d432-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:06:22,149 - anthropic._base_client - DEBUG - request_id: req_0124buKvPwBsptPy8ApVow8x
2025-03-19 06:06:22,149 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 06:06:22,149 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 06:06:22,149 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:06:22,149 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:06:22,149 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:06:22,149 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:06:22,149 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:06:22,149 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:06:22,154 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:06:22,154 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:06:25,231 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:06:25,233 - state_of_mika.adapters.claude - ERROR - Error executing tool: 'Registry' object has no attribute 'get_server'
2025-03-19 06:06:25,233 - result - WARNING - Request processing failed: Failed to execute get_weather for capability weather: 'Registry' object has no attribute 'get_server'
2025-03-19 06:06:25,233 - result - DEBUG - Final result: {
  "success": false,
  "error": "Failed to execute get_weather for capability weather: 'Registry' object has no attribute 'get_server'"
}
2025-03-19 06:06:25,233 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:06:25,233 - process - INFO - End time: 2025-03-19 06:06:25
2025-03-19 06:06:25,233 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:06:25,233 - process - INFO - Start time: 2025-03-19 06:06:25
2025-03-19 06:06:25,234 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:06:25,234 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:06:25,251 - process - INFO - Sending request to adapter for processing
2025-03-19 06:06:25,251 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:06:25,251 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:06:25,252 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:06:25,252 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:06:25,252 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:06:25,264 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107d9efd0>
2025-03-19 06:06:25,264 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107563380> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:06:25,277 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x107eb9910>
2025-03-19 06:06:25,277 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:06:25,277 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:06:25,277 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:06:25,278 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:06:25,278 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:06:26,397 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:06:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:06:25Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:06:25Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:06:26Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:06:25Z'), (b'request-id', b'req_01Ppw2s7cECAkzKMfc3P8yLr'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'92280980782be54b-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:06:26,397 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:06:26,398 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:06:26,398 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:06:26,398 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:06:26,398 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:06:26,398 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:06:26 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:06:25Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:06:25Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:06:26Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:06:25Z', 'request-id': 'req_01Ppw2s7cECAkzKMfc3P8yLr', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '92280980782be54b-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:06:26,398 - anthropic._base_client - DEBUG - request_id: req_01Ppw2s7cECAkzKMfc3P8yLr
2025-03-19 06:06:26,399 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 06:06:26,399 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 06:06:26,399 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:06:26,399 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:06:26,399 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:06:26,399 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:06:26,399 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:06:26,399 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:06:26,402 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:06:26,402 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:06:29,169 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:06:29,169 - state_of_mika.adapters.claude - ERROR - Error executing tool: 'Registry' object has no attribute 'get_server'
2025-03-19 06:06:29,169 - result - WARNING - Request processing failed: Failed to execute get_weather for capability weather: 'Registry' object has no attribute 'get_server'
2025-03-19 06:06:29,169 - result - DEBUG - Final result: {
  "success": false,
  "error": "Failed to execute get_weather for capability weather: 'Registry' object has no attribute 'get_server'"
}
2025-03-19 06:06:29,169 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:06:29,169 - process - INFO - End time: 2025-03-19 06:06:29
2025-03-19 06:06:29,188 - httpcore.connection - DEBUG - close.started
2025-03-19 06:06:29,188 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:06:29,188 - httpcore.connection - DEBUG - close.started
2025-03-19 06:06:29,188 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:06:29,188 - httpcore.connection - DEBUG - close.started
2025-03-19 06:06:29,188 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:07:04,496 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 06:07:04,496 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 06:07:04,496 - process - INFO - Start time: 2025-03-19 06:07:04
2025-03-19 06:07:04,497 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:07:04,497 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:07:04,534 - process - INFO - Sending request to adapter for processing
2025-03-19 06:07:04,534 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 06:07:04,534 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 06:07:04,535 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:07:04,553 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:07:04,553 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:07:04,593 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x110ce17f0>
2025-03-19 06:07:04,593 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110c5ed50> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:07:04,609 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x110b67d90>
2025-03-19 06:07:04,610 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:07:04,610 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:07:04,610 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:07:04,610 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:07:04,610 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:07:07,672 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:07:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:07:04Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:07:06Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:07:07Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:07:06Z'), (b'request-id', b'req_01JCjd6AWppCgK9vG6eQNdAo'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'92280a764e6fe551-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:07:07,673 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:07:07,673 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:07:07,674 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:07:07,674 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:07:07,674 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:07:07,674 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:07:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:07:04Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:07:06Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:07:07Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:07:06Z', 'request-id': 'req_01JCjd6AWppCgK9vG6eQNdAo', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '92280a764e6fe551-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:07:07,674 - anthropic._base_client - DEBUG - request_id: req_01JCjd6AWppCgK9vG6eQNdAo
2025-03-19 06:07:07,679 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 06:07:07,679 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 06:07:07,679 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:07:07,679 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:07:07,679 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:07:07,679 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:07:07,679 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:07:07,679 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:07:07,682 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:07:07,683 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:07:10,817 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:07:10,927 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:07:10,927 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:07:10,927 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:07:10,927 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:07:10,927 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:07:10,930 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:07:10,931 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:07:13,676 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:07:13,676 - state_of_mika.connector - INFO - Starting server: mcp_weather
2025-03-19 06:09:40,537 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 06:09:40,538 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 06:09:40,538 - process - INFO - Start time: 2025-03-19 06:09:40
2025-03-19 06:09:40,538 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:09:40,538 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:09:40,578 - process - INFO - Sending request to adapter for processing
2025-03-19 06:09:40,578 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 06:09:40,578 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 06:09:40,579 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:09:40,596 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:09:40,597 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:09:40,615 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1053e17f0>
2025-03-19 06:09:40,615 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105362d50> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:09:40,629 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105267d90>
2025-03-19 06:09:40,629 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:09:40,629 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:09:40,629 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:09:40,629 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:09:40,629 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:09:41,875 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:09:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:09:40Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:09:41Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:09:41Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:09:41Z'), (b'request-id', b'req_01Qm3mqpyqD8Xh3egyGt5ffg'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'92280e456d1ce557-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:09:41,875 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:09:41,875 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:09:41,876 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:09:41,876 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:09:41,876 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:09:41,876 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:09:41 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:09:40Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:09:41Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:09:41Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:09:41Z', 'request-id': 'req_01Qm3mqpyqD8Xh3egyGt5ffg', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '92280e456d1ce557-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:09:41,876 - anthropic._base_client - DEBUG - request_id: req_01Qm3mqpyqD8Xh3egyGt5ffg
2025-03-19 06:09:41,879 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 06:09:41,880 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 06:09:41,880 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:09:41,880 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:09:41,880 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:09:41,880 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:09:41,880 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:09:41,880 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:09:41,883 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:09:41,883 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:09:44,898 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:09:45,002 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:09:45,002 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:09:45,002 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:09:45,002 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:09:45,002 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:09:45,006 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:09:45,006 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:09:47,731 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:09:47,731 - state_of_mika.connector - INFO - Starting server: mcp_weather
2025-03-19 06:10:26,665 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:10:26,667 - process - INFO - End time: 2025-03-19 06:10:26
2025-03-19 06:10:26,718 - httpcore.connection - DEBUG - close.started
2025-03-19 06:10:26,719 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:14:15,422 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 06:14:15,423 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 06:14:15,423 - process - INFO - Start time: 2025-03-19 06:14:15
2025-03-19 06:14:15,423 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:14:15,423 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:14:15,461 - process - INFO - Sending request to adapter for processing
2025-03-19 06:14:15,461 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 06:14:15,461 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 06:14:15,462 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:14:15,483 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:14:15,483 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:14:15,521 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1112e17f0>
2025-03-19 06:14:15,522 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x111262de0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:14:15,534 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111163d90>
2025-03-19 06:14:15,534 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:14:15,535 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:14:15,535 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:14:15,535 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:14:15,535 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:14:16,754 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:14:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:14:15Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:14:15Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:14:16Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:14:15Z'), (b'request-id', b'req_01UkLwcFZ5fraoW9LCcouCsg'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922814fb9d39d42e-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:14:16,755 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:14:16,756 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:14:16,756 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:14:16,756 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:14:16,756 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:14:16,756 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:14:16 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:14:15Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:14:15Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:14:16Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:14:15Z', 'request-id': 'req_01UkLwcFZ5fraoW9LCcouCsg', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922814fb9d39d42e-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:14:16,756 - anthropic._base_client - DEBUG - request_id: req_01UkLwcFZ5fraoW9LCcouCsg
2025-03-19 06:14:16,761 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 06:14:16,761 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 06:14:16,761 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:14:16,761 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:14:16,761 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:14:16,761 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:14:16,761 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:14:16,761 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:14:16,766 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:14:16,766 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:14:19,629 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:14:19,732 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:14:19,732 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:14:19,732 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:14:19,732 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:14:19,732 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:14:19,736 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:14:19,736 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:14:22,568 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:14:22,568 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -m mcp_weather
2025-03-19 06:15:31,630 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:15:31,632 - process - INFO - End time: 2025-03-19 06:15:31
2025-03-19 06:15:31,699 - httpcore.connection - DEBUG - close.started
2025-03-19 06:15:31,705 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:15:59,878 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 06:15:59,879 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 06:15:59,879 - process - INFO - Start time: 2025-03-19 06:15:59
2025-03-19 06:15:59,879 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:15:59,879 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:15:59,919 - process - INFO - Sending request to adapter for processing
2025-03-19 06:15:59,922 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 06:15:59,923 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 06:15:59,924 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:15:59,945 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:15:59,946 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:15:59,985 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1114e17f0>
2025-03-19 06:15:59,985 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x111462de0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:15:59,999 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x111367ed0>
2025-03-19 06:15:59,999 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:15:59,999 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:15:59,999 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:15:59,999 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:15:59,999 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:16:01,154 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:16:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:16:00Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:16:00Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:16:01Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:16:00Z'), (b'request-id', b'req_01TAHjMLQ3jxTekZUQrTqgVt'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9228178878d3e58b-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:16:01,154 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:16:01,155 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:16:01,156 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:16:01,156 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:16:01,156 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:16:01,156 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:16:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:16:00Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:16:00Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:16:01Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:16:00Z', 'request-id': 'req_01TAHjMLQ3jxTekZUQrTqgVt', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '9228178878d3e58b-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:16:01,156 - anthropic._base_client - DEBUG - request_id: req_01TAHjMLQ3jxTekZUQrTqgVt
2025-03-19 06:16:01,159 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'timeframe': 'today'}}
2025-03-19 06:16:01,159 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'timeframe': 'today'}}
2025-03-19 06:16:01,159 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:16:01,159 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:16:01,159 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:16:01,159 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:16:01,159 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:16:01,160 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:16:01,163 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:16:01,163 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:16:04,001 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:16:04,102 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:16:04,102 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:16:04,102 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:16:04,102 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:16:04,102 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:16:04,106 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:16:04,106 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:16:07,138 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:16:07,139 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c import mcp_weather; mcp_weather.run_server()
2025-03-19 06:16:15,585 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:16:15,585 - process - INFO - End time: 2025-03-19 06:16:15
2025-03-19 06:16:15,629 - httpcore.connection - DEBUG - close.started
2025-03-19 06:16:15,629 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:18:13,427 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 06:18:13,428 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 06:18:13,428 - process - INFO - Start time: 2025-03-19 06:18:13
2025-03-19 06:18:13,428 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:18:13,429 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:18:13,467 - process - INFO - Sending request to adapter for processing
2025-03-19 06:18:13,467 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 06:18:13,467 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 06:18:13,468 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:18:13,487 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:18:13,487 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:18:13,506 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10531d7f0>
2025-03-19 06:18:13,506 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1052a2de0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:18:13,520 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10519bed0>
2025-03-19 06:18:13,520 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:18:13,520 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:18:13,520 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:18:13,521 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:18:13,521 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:18:14,803 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:18:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:18:13Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:18:13Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:18:14Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:18:13Z'), (b'request-id', b'req_0171oiGkJZGtP9kYoXAi28b5'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'92281acb0fb0e58c-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:18:14,804 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:18:14,804 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:18:14,805 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:18:14,805 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:18:14,805 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:18:14,805 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:18:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:18:13Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:18:13Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:18:14Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:18:13Z', 'request-id': 'req_0171oiGkJZGtP9kYoXAi28b5', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '92281acb0fb0e58c-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:18:14,805 - anthropic._base_client - DEBUG - request_id: req_0171oiGkJZGtP9kYoXAi28b5
2025-03-19 06:18:14,809 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 06:18:14,809 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 06:18:14,809 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:18:14,809 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:18:14,809 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:18:14,809 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:18:14,809 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:18:14,809 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:18:14,813 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:18:14,813 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:18:17,935 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:18:18,037 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:18:18,037 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:18:18,037 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:18:18,037 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:18:18,037 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:18:18,041 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:18:18,041 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:18:20,827 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:18:20,829 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -m fastmcp -m mcp_weather.weather
2025-03-19 06:18:34,777 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:18:34,777 - process - INFO - End time: 2025-03-19 06:18:34
2025-03-19 06:18:34,820 - httpcore.connection - DEBUG - close.started
2025-03-19 06:18:34,820 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:19:41,987 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 06:19:41,987 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 06:19:41,987 - process - INFO - Start time: 2025-03-19 06:19:41
2025-03-19 06:19:41,987 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:19:41,987 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:19:42,023 - process - INFO - Sending request to adapter for processing
2025-03-19 06:19:42,023 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 06:19:42,023 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 06:19:42,024 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:19:42,039 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:19:42,040 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:19:42,057 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1202e17f0>
2025-03-19 06:19:42,057 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x120266de0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:19:42,070 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x120163ed0>
2025-03-19 06:19:42,070 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:19:42,070 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:19:42,070 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:19:42,070 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:19:42,070 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:19:43,890 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:19:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:19:42Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:19:43Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:19:43Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:19:43Z'), (b'request-id', b'req_01TYqepgTp1nE9BBYZWnSa8E'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'92281cf478b5a476-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:19:43,891 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:19:43,891 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:19:43,891 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:19:43,891 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:19:43,891 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:19:43,891 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:19:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:19:42Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:19:43Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:19:43Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:19:43Z', 'request-id': 'req_01TYqepgTp1nE9BBYZWnSa8E', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '92281cf478b5a476-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:19:43,891 - anthropic._base_client - DEBUG - request_id: req_01TYqepgTp1nE9BBYZWnSa8E
2025-03-19 06:19:43,894 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 06:19:43,895 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 06:19:43,895 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:19:43,895 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:19:43,895 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:19:43,895 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:19:43,895 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:19:43,895 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:19:43,898 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:19:43,898 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:19:46,733 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:19:46,834 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:19:46,834 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:19:46,834 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:19:46,834 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:19:46,834 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:19:46,838 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:19:46,838 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:19:49,672 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:19:49,673 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: fastmcp run mcp_weather.weather
2025-03-19 06:20:11,620 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:20:11,622 - process - INFO - End time: 2025-03-19 06:20:11
2025-03-19 06:20:11,671 - httpcore.connection - DEBUG - close.started
2025-03-19 06:20:11,671 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:20:44,029 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 06:20:44,030 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 06:20:44,030 - process - INFO - Start time: 2025-03-19 06:20:44
2025-03-19 06:20:44,030 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:20:44,030 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:20:44,069 - process - INFO - Sending request to adapter for processing
2025-03-19 06:20:44,069 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 06:20:44,069 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 06:20:44,070 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:20:44,095 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:20:44,095 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:20:44,109 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10619d7f0>
2025-03-19 06:20:44,110 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10611ede0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:20:44,124 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106023ed0>
2025-03-19 06:20:44,125 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:20:44,125 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:20:44,125 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:20:44,125 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:20:44,125 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:20:45,315 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:20:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:20:44Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:20:44Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:20:45Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:20:44Z'), (b'request-id', b'req_01XbjuTsM73Sh74oWjkDyzrh'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'92281e784f95cc87-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:20:45,316 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:20:45,316 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:20:45,316 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:20:45,316 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:20:45,316 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:20:45,317 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:20:45 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:20:44Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:20:44Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:20:45Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:20:44Z', 'request-id': 'req_01XbjuTsM73Sh74oWjkDyzrh', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '92281e784f95cc87-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:20:45,317 - anthropic._base_client - DEBUG - request_id: req_01XbjuTsM73Sh74oWjkDyzrh
2025-03-19 06:20:45,320 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 06:20:45,320 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 06:20:45,320 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:20:45,320 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:20:45,320 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:20:45,320 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:45,320 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:45,320 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:45,323 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:20:45,324 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:48,208 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:20:48,313 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:20:48,313 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:20:48,313 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:48,313 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:48,313 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:48,317 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:20:48,317 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:51,022 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:20:51,022 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 06:20:51,338 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 06:20:51,339 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'Paris', 'date': 'today'}
2025-03-19 06:20:51,343 - result - INFO - Request processing completed successfully
2025-03-19 06:20:51,343 - process - ERROR - Error processing request: Object of type CallToolResult is not JSON serializable
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 183, in process_llm_request
    result_logger.debug(f"Final result: {json.dumps(response, indent=2)}")
                                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ~~~~~~^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/encoder.py", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/encoder.py", line 261, in iterencode
    return _iterencode(o, 0)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
                    f'is not JSON serializable')
TypeError: Object of type CallToolResult is not JSON serializable
2025-03-19 06:20:51,401 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:20:51,401 - process - INFO - End time: 2025-03-19 06:20:51
2025-03-19 06:20:51,401 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 06:20:51,401 - process - INFO - Start time: 2025-03-19 06:20:51
2025-03-19 06:20:51,402 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:20:51,402 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:20:51,420 - process - INFO - Sending request to adapter for processing
2025-03-19 06:20:51,420 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 06:20:51,420 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 06:20:51,420 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:20:51,421 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:20:51,421 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:20:51,432 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10771afd0>
2025-03-19 06:20:51,433 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107662d50> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:20:51,450 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1075a2060>
2025-03-19 06:20:51,450 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:20:51,450 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:20:51,450 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:20:51,450 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:20:51,450 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:20:52,599 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:20:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:20:51Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:20:51Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:20:52Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:20:51Z'), (b'request-id', b'req_01TVu5qq2urrwSdCN9zbWMME'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'92281ea61fc3e54b-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:20:52,600 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:20:52,600 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:20:52,600 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:20:52,600 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:20:52,600 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:20:52,600 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:20:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:20:51Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:20:51Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:20:52Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:20:51Z', 'request-id': 'req_01TVu5qq2urrwSdCN9zbWMME', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '92281ea61fc3e54b-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:20:52,600 - anthropic._base_client - DEBUG - request_id: req_01TVu5qq2urrwSdCN9zbWMME
2025-03-19 06:20:52,601 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 06:20:52,601 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 06:20:52,601 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:20:52,601 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:20:52,601 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:20:52,601 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:52,601 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:52,601 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:52,604 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:20:52,604 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:55,382 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:20:55,382 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:20:55,382 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:20:55,382 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:55,382 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:55,382 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:55,386 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:20:55,386 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:58,114 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:20:58,114 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 06:20:58,415 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 06:20:58,415 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'London'}
2025-03-19 06:20:58,419 - result - INFO - Request processing completed successfully
2025-03-19 06:20:58,419 - process - ERROR - Error processing request: Object of type CallToolResult is not JSON serializable
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 183, in process_llm_request
    result_logger.debug(f"Final result: {json.dumps(response, indent=2)}")
                                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ~~~~~~^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/encoder.py", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/encoder.py", line 261, in iterencode
    return _iterencode(o, 0)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
                    f'is not JSON serializable')
TypeError: Object of type CallToolResult is not JSON serializable
2025-03-19 06:20:58,479 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:20:58,479 - process - INFO - End time: 2025-03-19 06:20:58
2025-03-19 06:20:58,479 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:20:58,479 - process - INFO - Start time: 2025-03-19 06:20:58
2025-03-19 06:20:58,480 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 06:20:58,480 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 06:20:58,497 - process - INFO - Sending request to adapter for processing
2025-03-19 06:20:58,497 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:20:58,497 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 06:20:58,498 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 06:20:58,498 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 06:20:58,498 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 06:20:58,510 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1075a3a80>
2025-03-19 06:20:58,510 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1076f1010> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 06:20:58,528 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1076b79b0>
2025-03-19 06:20:58,528 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 06:20:58,528 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 06:20:58,528 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 06:20:58,528 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 06:20:58,529 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 06:20:59,564 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Tue, 18 Mar 2025 22:20:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-18T22:20:58Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-18T22:20:58Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-18T22:20:59Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-18T22:20:58Z'), (b'request-id', b'req_01DHCit4a1ZqBXw4bTGobDxf'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'92281ed25cfde54f-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 06:20:59,565 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 06:20:59,565 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 06:20:59,565 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 06:20:59,565 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 06:20:59,565 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 06:20:59,565 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Tue, 18 Mar 2025 22:20:59 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-18T22:20:58Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-18T22:20:58Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-18T22:20:59Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-18T22:20:58Z', 'request-id': 'req_01DHCit4a1ZqBXw4bTGobDxf', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '92281ed25cfde54f-KUL', 'content-encoding': 'gzip'})
2025-03-19 06:20:59,566 - anthropic._base_client - DEBUG - request_id: req_01DHCit4a1ZqBXw4bTGobDxf
2025-03-19 06:20:59,566 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 06:20:59,566 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 06:20:59,566 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 06:20:59,566 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 06:20:59,566 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:20:59,566 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:59,566 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:59,566 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:20:59,570 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:20:59,570 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:21:03,051 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:21:03,051 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 06:21:03,051 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 06:21:03,051 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:21:03,051 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:21:03,051 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:21:03,055 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 06:21:03,055 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 06:21:05,794 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 06:21:05,794 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 06:21:06,101 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 06:21:06,101 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'Tokyo'}
2025-03-19 06:21:06,104 - result - INFO - Request processing completed successfully
2025-03-19 06:21:06,105 - process - ERROR - Error processing request: Object of type CallToolResult is not JSON serializable
Traceback (most recent call last):
  File "/Users/yongjoekit/dev/SoM/StateOfMika SDK/tests/test_end_to_end.py", line 183, in process_llm_request
    result_logger.debug(f"Final result: {json.dumps(response, indent=2)}")
                                         ~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ~~~~~~^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/encoder.py", line 200, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/encoder.py", line 261, in iterencode
    return _iterencode(o, 0)
  File "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
                    f'is not JSON serializable')
TypeError: Object of type CallToolResult is not JSON serializable
2025-03-19 06:21:06,161 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 06:21:06,162 - process - INFO - End time: 2025-03-19 06:21:06
2025-03-19 06:21:06,181 - httpcore.connection - DEBUG - close.started
2025-03-19 06:21:06,181 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:21:06,181 - httpcore.connection - DEBUG - close.started
2025-03-19 06:21:06,181 - httpcore.connection - DEBUG - close.complete
2025-03-19 06:21:06,181 - httpcore.connection - DEBUG - close.started
2025-03-19 06:21:06,182 - httpcore.connection - DEBUG - close.complete
2025-03-19 14:20:06,509 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 14:20:06,510 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 14:20:06,510 - process - INFO - Start time: 2025-03-19 14:20:06
2025-03-19 14:20:06,510 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 14:20:06,510 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 14:20:06,551 - process - INFO - Sending request to adapter for processing
2025-03-19 14:20:06,551 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 14:20:06,551 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 14:20:06,552 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 14:20:06,573 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 14:20:06,574 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 14:20:06,615 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11a7e1940>
2025-03-19 14:20:06,615 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x11a762de0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 14:20:06,638 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x11aa0c050>
2025-03-19 14:20:06,638 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 14:20:06,639 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 14:20:06,639 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 14:20:06,639 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 14:20:06,639 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 14:20:07,818 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 06:20:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-19T06:20:06Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-19T06:20:06Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-19T06:20:07Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-19T06:20:06Z'), (b'request-id', b'req_01Uxj71ZgBDPPZQgnkR7HEvy'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922adcad9ac5391b-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 14:20:07,819 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 14:20:07,819 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 14:20:07,820 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 14:20:07,820 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 14:20:07,820 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 14:20:07,820 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 19 Mar 2025 06:20:07 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-19T06:20:06Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-19T06:20:06Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-19T06:20:07Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-19T06:20:06Z', 'request-id': 'req_01Uxj71ZgBDPPZQgnkR7HEvy', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922adcad9ac5391b-KUL', 'content-encoding': 'gzip'})
2025-03-19 14:20:07,820 - anthropic._base_client - DEBUG - request_id: req_01Uxj71ZgBDPPZQgnkR7HEvy
2025-03-19 14:20:07,825 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 14:20:07,825 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 14:20:07,825 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 14:20:07,825 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 14:20:07,825 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 14:20:07,825 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:20:07,825 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:20:07,825 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:20:07,830 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 14:20:07,831 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:20:11,572 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 14:20:11,674 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 14:20:11,674 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 14:20:11,674 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:20:11,674 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:20:11,674 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:20:11,678 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 14:20:11,678 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:20:14,829 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 14:20:14,829 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 14:20:15,215 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 14:20:15,215 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'Paris', 'time': 'today'}
2025-03-19 14:20:15,219 - result - INFO - Request processing completed successfully
2025-03-19 14:20:15,219 - result - DEBUG - Final result: <Object of type dict - not JSON serializable>
2025-03-19 14:20:15,272 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 14:20:15,272 - process - INFO - End time: 2025-03-19 14:20:15
2025-03-19 14:20:15,294 - httpcore.connection - DEBUG - close.started
2025-03-19 14:20:15,294 - httpcore.connection - DEBUG - close.complete
2025-03-19 14:22:10,637 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 14:22:10,638 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 14:22:10,638 - process - INFO - Start time: 2025-03-19 14:22:10
2025-03-19 14:22:10,638 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 14:22:10,638 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 14:22:10,675 - process - INFO - Sending request to adapter for processing
2025-03-19 14:22:10,675 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 14:22:10,675 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 14:22:10,675 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 14:22:10,694 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 14:22:10,695 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 14:22:10,715 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1069e1940>
2025-03-19 14:22:10,716 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x106962de0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 14:22:10,738 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x106d0c050>
2025-03-19 14:22:10,738 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 14:22:10,739 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 14:22:10,739 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 14:22:10,739 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 14:22:10,739 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 14:22:11,933 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 06:22:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-19T06:22:10Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-19T06:22:11Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-19T06:22:11Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-19T06:22:11Z'), (b'request-id', b'req_01YLytPmZH6YRojoBBTwxF9D'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922adfb538a5e58c-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 14:22:11,934 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 14:22:11,934 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 14:22:11,935 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 14:22:11,935 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 14:22:11,935 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 14:22:11,935 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 19 Mar 2025 06:22:11 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-19T06:22:10Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-19T06:22:11Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-19T06:22:11Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-19T06:22:11Z', 'request-id': 'req_01YLytPmZH6YRojoBBTwxF9D', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922adfb538a5e58c-KUL', 'content-encoding': 'gzip'})
2025-03-19 14:22:11,935 - anthropic._base_client - DEBUG - request_id: req_01YLytPmZH6YRojoBBTwxF9D
2025-03-19 14:22:11,938 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 14:22:11,938 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 14:22:11,939 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 14:22:11,939 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 14:22:11,939 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 14:22:11,939 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:22:11,939 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:22:11,939 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:22:11,946 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 14:22:11,946 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:22:15,388 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 14:22:15,492 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 14:22:15,492 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 14:22:15,492 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:22:15,492 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:22:15,492 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:22:15,495 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 14:22:15,495 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:22:18,333 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 14:22:18,334 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; import os; import json; from aiohttp import ClientResponseError; async def mock_get_weather(location: str): return {'location': location, 'current_conditions': {'temperature': {'value': 22, 'unit': 'C'}, 'weather_text': 'Partly cloudy', 'relative_humidity': 65}, 'hourly_forecast': [{'relative_time': '+1 hour', 'temperature': {'value': 23, 'unit': 'C'}, 'weather_text': 'Partly cloudy', 'precipitation_probability': 10}], 'note': 'Mock data (no valid AccuWeather API key provided)'}; server = FastMCP('mcp-weather'); try: from mcp_weather.weather import get_hourly_weather; server.add_tool(get_hourly_weather); print('Using real AccuWeather API'); except Exception as e: server.add_tool(mock_get_weather); print(f'Using mock weather data: {e}'); server.run()
2025-03-19 14:23:10,389 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 14:23:10,390 - process - INFO - End time: 2025-03-19 14:23:10
2025-03-19 14:23:10,447 - httpcore.connection - DEBUG - close.started
2025-03-19 14:23:10,448 - httpcore.connection - DEBUG - close.complete
2025-03-19 14:25:37,897 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 14:25:37,897 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 14:25:37,898 - process - INFO - Start time: 2025-03-19 14:25:37
2025-03-19 14:25:37,898 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 14:25:37,898 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 14:25:37,935 - process - INFO - Sending request to adapter for processing
2025-03-19 14:25:37,936 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 14:25:37,936 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 14:25:37,936 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 14:25:37,953 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 14:25:37,953 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 14:25:37,975 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1109e1940>
2025-03-19 14:25:37,975 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x110962de0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 14:25:37,996 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x110b0c050>
2025-03-19 14:25:37,997 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 14:25:37,997 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 14:25:37,997 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 14:25:37,997 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 14:25:37,997 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 14:25:39,286 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 06:25:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-19T06:25:38Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-19T06:25:39Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-19T06:25:39Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-19T06:25:39Z'), (b'request-id', b'req_01ENcU3TjjXERWTJRNnsNeNA'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922ae4c49e22d89d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 14:25:39,287 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 14:25:39,287 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 14:25:39,287 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 14:25:39,288 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 14:25:39,288 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 14:25:39,288 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 19 Mar 2025 06:25:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-19T06:25:38Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-19T06:25:39Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-19T06:25:39Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-19T06:25:39Z', 'request-id': 'req_01ENcU3TjjXERWTJRNnsNeNA', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922ae4c49e22d89d-KUL', 'content-encoding': 'gzip'})
2025-03-19 14:25:39,288 - anthropic._base_client - DEBUG - request_id: req_01ENcU3TjjXERWTJRNnsNeNA
2025-03-19 14:25:39,292 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 14:25:39,292 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 14:25:39,292 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 14:25:39,292 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 14:25:39,292 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 14:25:39,292 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:25:39,292 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:25:39,292 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:25:39,296 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 14:25:39,296 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:25:42,493 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 14:25:42,593 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 14:25:42,593 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 14:25:42,593 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:25:42,593 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:25:42,593 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:25:42,596 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 14:25:42,596 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:25:46,070 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 14:25:46,072 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; import os; import json; from aiohttp import ClientResponseError; async def mock_get_weather(location: str): return {'location': location, 'current_conditions': {'temperature': {'value': 22, 'unit': 'C'}, 'weather_text': 'Partly cloudy', 'relative_humidity': 65}, 'hourly_forecast': [{'relative_time': '+1 hour', 'temperature': {'value': 23, 'unit': 'C'}, 'weather_text': 'Partly cloudy', 'precipitation_probability': 10}], 'note': 'Mock data (no valid AccuWeather API key provided)'}; server = FastMCP('mcp-weather'); try: from mcp_weather.weather import get_hourly_weather; server.add_tool(get_hourly_weather); print('Using real AccuWeather API'); except Exception as e: server.add_tool(mock_get_weather); print(f'Using mock weather data: {e}'); server.run()
2025-03-19 14:29:53,515 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 14:29:53,516 - process - INFO - End time: 2025-03-19 14:29:53
2025-03-19 14:29:53,577 - httpcore.connection - DEBUG - close.started
2025-03-19 14:29:53,578 - httpcore.connection - DEBUG - close.complete
2025-03-19 14:34:03,860 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 14:34:03,861 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 14:34:03,861 - process - INFO - Start time: 2025-03-19 14:34:03
2025-03-19 14:34:03,861 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 14:34:03,861 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 14:34:03,898 - process - INFO - Sending request to adapter for processing
2025-03-19 14:34:03,899 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 14:34:03,899 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 14:34:03,899 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 14:34:03,916 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 14:34:03,917 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 14:34:03,968 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1035e1940>
2025-03-19 14:34:03,968 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103562de0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 14:34:03,986 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103a0c050>
2025-03-19 14:34:03,986 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 14:34:03,986 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 14:34:03,986 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 14:34:03,986 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 14:34:03,986 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 14:34:05,201 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 06:34:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-19T06:34:04Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-19T06:34:04Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-19T06:34:05Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-19T06:34:04Z'), (b'request-id', b'req_017L1zsvonAdHZxEBFY21qpe'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922af11f0db4e58b-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 14:34:05,202 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 14:34:05,202 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 14:34:05,202 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 14:34:05,202 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 14:34:05,202 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 14:34:05,203 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 19 Mar 2025 06:34:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-19T06:34:04Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-19T06:34:04Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-19T06:34:05Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-19T06:34:04Z', 'request-id': 'req_017L1zsvonAdHZxEBFY21qpe', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922af11f0db4e58b-KUL', 'content-encoding': 'gzip'})
2025-03-19 14:34:05,203 - anthropic._base_client - DEBUG - request_id: req_017L1zsvonAdHZxEBFY21qpe
2025-03-19 14:34:05,206 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'forecast_date': 'today'}}
2025-03-19 14:34:05,206 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'forecast_date': 'today'}}
2025-03-19 14:34:05,206 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 14:34:05,206 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 14:34:05,206 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 14:34:05,206 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:05,206 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:05,206 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:05,210 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 14:34:05,210 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:08,257 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 14:34:08,358 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 14:34:08,358 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 14:34:08,358 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:08,358 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:08,359 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:08,362 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 14:34:08,362 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:11,279 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 14:34:11,279 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 14:34:11,592 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 14:34:11,592 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'Paris', 'forecast_date': 'today'}
2025-03-19 14:34:11,596 - result - INFO - Request processing completed successfully
2025-03-19 14:34:11,596 - result - DEBUG - Final result: <Object of type dict - not JSON serializable>
2025-03-19 14:34:11,652 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 14:34:11,652 - process - INFO - End time: 2025-03-19 14:34:11
2025-03-19 14:34:11,652 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 14:34:11,652 - process - INFO - Start time: 2025-03-19 14:34:11
2025-03-19 14:34:11,652 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 14:34:11,652 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 14:34:11,670 - process - INFO - Sending request to adapter for processing
2025-03-19 14:34:11,670 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 14:34:11,670 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 14:34:11,671 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 14:34:11,671 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 14:34:11,671 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 14:34:11,686 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104217110>
2025-03-19 14:34:11,686 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104166d50> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 14:34:11,706 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1040a6ea0>
2025-03-19 14:34:11,706 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 14:34:11,706 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 14:34:11,706 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 14:34:11,706 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 14:34:11,706 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 14:34:12,777 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 06:34:12 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-19T06:34:11Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-19T06:34:12Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-19T06:34:12Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-19T06:34:12Z'), (b'request-id', b'req_01QPAVtUkFVxsREq8rbcDv9y'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922af14f4e3f3951-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 14:34:12,778 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 14:34:12,778 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 14:34:12,779 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 14:34:12,779 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 14:34:12,779 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 14:34:12,779 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 19 Mar 2025 06:34:12 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-19T06:34:11Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-19T06:34:12Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-19T06:34:12Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-19T06:34:12Z', 'request-id': 'req_01QPAVtUkFVxsREq8rbcDv9y', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922af14f4e3f3951-KUL', 'content-encoding': 'gzip'})
2025-03-19 14:34:12,779 - anthropic._base_client - DEBUG - request_id: req_01QPAVtUkFVxsREq8rbcDv9y
2025-03-19 14:34:12,780 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 14:34:12,780 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 14:34:12,780 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 14:34:12,780 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 14:34:12,780 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 14:34:12,780 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:12,780 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:12,780 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:12,787 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 14:34:12,788 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:16,129 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 14:34:16,130 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 14:34:16,130 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 14:34:16,130 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:16,130 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:16,130 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:16,133 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 14:34:16,133 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:18,952 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 14:34:18,954 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 14:34:19,263 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 14:34:19,263 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'London'}
2025-03-19 14:34:19,267 - result - INFO - Request processing completed successfully
2025-03-19 14:34:19,267 - result - DEBUG - Final result: <Object of type dict - not JSON serializable>
2025-03-19 14:34:19,323 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 14:34:19,323 - process - INFO - End time: 2025-03-19 14:34:19
2025-03-19 14:34:19,324 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 14:34:19,324 - process - INFO - Start time: 2025-03-19 14:34:19
2025-03-19 14:34:19,324 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 14:34:19,324 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 14:34:19,342 - process - INFO - Sending request to adapter for processing
2025-03-19 14:34:19,342 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 14:34:19,342 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 14:34:19,343 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 14:34:19,343 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 14:34:19,343 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 14:34:19,360 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1040a7ce0>
2025-03-19 14:34:19,360 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104167650> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 14:34:19,383 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1041bb890>
2025-03-19 14:34:19,383 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 14:34:19,383 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 14:34:19,383 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 14:34:19,383 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 14:34:19,383 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 14:34:20,457 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 06:34:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-19T06:34:19Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-19T06:34:19Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-19T06:34:20Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-19T06:34:19Z'), (b'request-id', b'req_015BH4HPXvZqMAgsNgP3i9SM'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922af17f4d96d42e-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 14:34:20,457 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 14:34:20,457 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 14:34:20,458 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 14:34:20,458 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 14:34:20,458 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 14:34:20,458 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 19 Mar 2025 06:34:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-19T06:34:19Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-19T06:34:19Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-19T06:34:20Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-19T06:34:19Z', 'request-id': 'req_015BH4HPXvZqMAgsNgP3i9SM', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922af17f4d96d42e-KUL', 'content-encoding': 'gzip'})
2025-03-19 14:34:20,458 - anthropic._base_client - DEBUG - request_id: req_015BH4HPXvZqMAgsNgP3i9SM
2025-03-19 14:34:20,458 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 14:34:20,458 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 14:34:20,458 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 14:34:20,458 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 14:34:20,458 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 14:34:20,458 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:20,459 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:20,459 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:20,462 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 14:34:20,462 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:23,256 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 14:34:23,256 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 14:34:23,256 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 14:34:23,256 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:23,256 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:23,256 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:23,259 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 14:34:23,259 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 14:34:26,033 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 14:34:26,033 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 14:34:26,334 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 14:34:26,334 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'Tokyo'}
2025-03-19 14:34:26,337 - result - INFO - Request processing completed successfully
2025-03-19 14:34:26,338 - result - DEBUG - Final result: <Object of type dict - not JSON serializable>
2025-03-19 14:34:26,390 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 14:34:26,391 - process - INFO - End time: 2025-03-19 14:34:26
2025-03-19 14:34:26,411 - httpcore.connection - DEBUG - close.started
2025-03-19 14:34:26,411 - httpcore.connection - DEBUG - close.complete
2025-03-19 14:34:26,411 - httpcore.connection - DEBUG - close.started
2025-03-19 14:34:26,411 - httpcore.connection - DEBUG - close.complete
2025-03-19 14:34:26,412 - httpcore.connection - DEBUG - close.started
2025-03-19 14:34:26,412 - httpcore.connection - DEBUG - close.complete
2025-03-19 14:57:45,246 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 14:57:45,250 - process - INFO - End time: 2025-03-19 14:57:45
2025-03-19 14:57:45,353 - httpcore.connection - DEBUG - close.started
2025-03-19 14:57:45,354 - httpcore.connection - DEBUG - close.complete
2025-03-19 15:02:14,574 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 15:02:14,575 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 15:02:14,575 - process - INFO - Start time: 2025-03-19 15:02:14
2025-03-19 15:02:14,576 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 15:02:14,576 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 15:02:14,616 - process - INFO - Sending request to adapter for processing
2025-03-19 15:02:14,616 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 15:02:14,616 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 15:02:14,617 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 15:02:14,634 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 15:02:14,635 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 15:02:14,676 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1048e1940>
2025-03-19 15:02:14,676 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x104862de0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 15:02:14,693 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104c0c050>
2025-03-19 15:02:14,693 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 15:02:14,693 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 15:02:14,693 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 15:02:14,694 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 15:02:14,694 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 15:02:15,937 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 07:02:15 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-19T07:02:14Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-19T07:02:15Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-19T07:02:15Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-19T07:02:15Z'), (b'request-id', b'req_0143aiUfk4yWSdL4Fe4UvvtA'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922b1a65fcbde557-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 15:02:15,939 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 15:02:15,939 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 15:02:15,940 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 15:02:15,940 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 15:02:15,940 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 15:02:15,940 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 19 Mar 2025 07:02:15 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-19T07:02:14Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-19T07:02:15Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-19T07:02:15Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-19T07:02:15Z', 'request-id': 'req_0143aiUfk4yWSdL4Fe4UvvtA', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922b1a65fcbde557-KUL', 'content-encoding': 'gzip'})
2025-03-19 15:02:15,940 - anthropic._base_client - DEBUG - request_id: req_0143aiUfk4yWSdL4Fe4UvvtA
2025-03-19 15:02:15,946 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 15:02:15,947 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'date': 'today'}}
2025-03-19 15:02:15,947 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 15:02:15,947 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 15:02:15,947 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 15:02:15,947 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:15,947 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:15,947 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:15,955 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 15:02:15,956 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:19,225 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 15:02:19,331 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 15:02:19,331 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 15:02:19,331 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:19,331 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:19,331 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:19,334 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 15:02:19,334 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:22,219 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 15:02:22,220 - state_of_mika.connector - WARNING - Environment variable ACCUWEATHER_API_KEY not found, using empty string
2025-03-19 15:02:22,221 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 15:02:22,582 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 15:02:22,582 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'Paris', 'date': 'today'}
2025-03-19 15:02:22,586 - result - INFO - Request processing completed successfully
2025-03-19 15:02:22,586 - result - DEBUG - Final result: <Object of type dict - not JSON serializable>
2025-03-19 15:02:22,638 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 15:02:22,639 - process - INFO - End time: 2025-03-19 15:02:22
2025-03-19 15:02:22,639 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 15:02:22,639 - process - INFO - Start time: 2025-03-19 15:02:22
2025-03-19 15:02:22,640 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 15:02:22,640 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 15:02:22,658 - process - INFO - Sending request to adapter for processing
2025-03-19 15:02:22,658 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 15:02:22,658 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 15:02:22,659 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 15:02:22,659 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 15:02:22,659 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 15:02:22,673 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x105417110>
2025-03-19 15:02:22,673 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105366d50> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 15:02:22,696 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1052a6d70>
2025-03-19 15:02:22,696 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 15:02:22,696 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 15:02:22,696 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 15:02:22,696 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 15:02:22,696 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 15:02:23,755 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 07:02:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-19T07:02:22Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-19T07:02:23Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-19T07:02:23Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-19T07:02:23Z'), (b'request-id', b'req_01UgubQDsmaBAeuM9n5pfa5B'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922b1a97fb9cd435-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 15:02:23,756 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 15:02:23,756 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 15:02:23,756 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 15:02:23,756 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 15:02:23,756 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 15:02:23,756 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 19 Mar 2025 07:02:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-19T07:02:22Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-19T07:02:23Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-19T07:02:23Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-19T07:02:23Z', 'request-id': 'req_01UgubQDsmaBAeuM9n5pfa5B', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922b1a97fb9cd435-KUL', 'content-encoding': 'gzip'})
2025-03-19 15:02:23,756 - anthropic._base_client - DEBUG - request_id: req_01UgubQDsmaBAeuM9n5pfa5B
2025-03-19 15:02:23,757 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 15:02:23,757 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 15:02:23,757 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 15:02:23,757 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 15:02:23,757 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 15:02:23,757 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:23,757 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:23,757 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:23,765 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 15:02:23,765 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:26,974 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 15:02:26,975 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 15:02:26,975 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 15:02:26,975 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:26,975 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:26,975 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:26,978 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 15:02:26,978 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:29,816 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 15:02:29,817 - state_of_mika.connector - WARNING - Environment variable ACCUWEATHER_API_KEY not found, using empty string
2025-03-19 15:02:29,818 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 15:02:30,173 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 15:02:30,173 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'London'}
2025-03-19 15:02:30,176 - result - INFO - Request processing completed successfully
2025-03-19 15:02:30,176 - result - DEBUG - Final result: <Object of type dict - not JSON serializable>
2025-03-19 15:02:30,229 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 15:02:30,229 - process - INFO - End time: 2025-03-19 15:02:30
2025-03-19 15:02:30,230 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 15:02:30,230 - process - INFO - Start time: 2025-03-19 15:02:30
2025-03-19 15:02:30,231 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 15:02:30,231 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 15:02:30,249 - process - INFO - Sending request to adapter for processing
2025-03-19 15:02:30,249 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 15:02:30,249 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 15:02:30,250 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 15:02:30,250 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 15:02:30,250 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 15:02:30,264 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1052a7bb0>
2025-03-19 15:02:30,264 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x105367650> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 15:02:30,284 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1053bb890>
2025-03-19 15:02:30,284 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 15:02:30,285 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 15:02:30,285 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 15:02:30,285 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 15:02:30,285 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 15:02:31,398 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 07:02:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-19T07:02:30Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-19T07:02:30Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-19T07:02:31Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-19T07:02:30Z'), (b'request-id', b'req_01Hv2gLmKVpUnTvV31fK5EAm'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922b1ac7697ee54d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 15:02:31,399 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 15:02:31,399 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 15:02:31,399 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 15:02:31,400 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 15:02:31,400 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 15:02:31,400 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 19 Mar 2025 07:02:31 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-19T07:02:30Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-19T07:02:30Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-19T07:02:31Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-19T07:02:30Z', 'request-id': 'req_01Hv2gLmKVpUnTvV31fK5EAm', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922b1ac7697ee54d-KUL', 'content-encoding': 'gzip'})
2025-03-19 15:02:31,400 - anthropic._base_client - DEBUG - request_id: req_01Hv2gLmKVpUnTvV31fK5EAm
2025-03-19 15:02:31,400 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 15:02:31,401 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 15:02:31,401 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 15:02:31,401 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 15:02:31,401 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 15:02:31,401 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:31,401 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:31,401 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:31,408 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 15:02:31,408 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:34,424 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 15:02:34,424 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 15:02:34,424 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 15:02:34,424 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:34,424 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:34,424 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:34,427 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 15:02:34,427 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:02:37,308 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 15:02:37,308 - state_of_mika.connector - WARNING - Environment variable ACCUWEATHER_API_KEY not found, using empty string
2025-03-19 15:02:37,308 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 15:02:37,659 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 15:02:37,660 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'Tokyo'}
2025-03-19 15:02:37,663 - result - INFO - Request processing completed successfully
2025-03-19 15:02:37,663 - result - DEBUG - Final result: <Object of type dict - not JSON serializable>
2025-03-19 15:02:37,716 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 15:02:37,716 - process - INFO - End time: 2025-03-19 15:02:37
2025-03-19 15:02:37,735 - httpcore.connection - DEBUG - close.started
2025-03-19 15:02:37,735 - httpcore.connection - DEBUG - close.complete
2025-03-19 15:02:37,735 - httpcore.connection - DEBUG - close.started
2025-03-19 15:02:37,736 - httpcore.connection - DEBUG - close.complete
2025-03-19 15:02:37,736 - httpcore.connection - DEBUG - close.started
2025-03-19 15:02:37,736 - httpcore.connection - DEBUG - close.complete
2025-03-19 15:10:48,239 - asyncio - DEBUG - Using selector: KqueueSelector
2025-03-19 15:10:48,239 - process - INFO - Processing LLM request: What's the weather like in Paris today?
2025-03-19 15:10:48,239 - process - INFO - Start time: 2025-03-19 15:10:48
2025-03-19 15:10:48,240 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 15:10:48,240 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 15:10:48,279 - process - INFO - Sending request to adapter for processing
2025-03-19 15:10:48,279 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: What's the weather like in Paris today?
2025-03-19 15:10:48,279 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: What's the weather like in Paris today?
2025-03-19 15:10:48,280 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "What's the weather like in Paris today?"}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 15:10:48,298 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 15:10:48,298 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 15:10:48,341 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x103de1940>
2025-03-19 15:10:48,341 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103d66de0> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 15:10:48,358 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x10400c050>
2025-03-19 15:10:48,358 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 15:10:48,359 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 15:10:48,359 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 15:10:48,359 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 15:10:48,359 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 15:10:49,526 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 07:10:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-19T07:10:48Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-19T07:10:48Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-19T07:10:49Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-19T07:10:48Z'), (b'request-id', b'req_01LcQNdboU3HA5dgFByTk4Zr'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922b26f05ccfe541-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 15:10:49,528 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 15:10:49,528 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 15:10:49,529 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 15:10:49,529 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 15:10:49,529 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 15:10:49,529 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 19 Mar 2025 07:10:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-19T07:10:48Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-19T07:10:48Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-19T07:10:49Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-19T07:10:48Z', 'request-id': 'req_01LcQNdboU3HA5dgFByTk4Zr', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922b26f05ccfe541-KUL', 'content-encoding': 'gzip'})
2025-03-19 15:10:49,530 - anthropic._base_client - DEBUG - request_id: req_01LcQNdboU3HA5dgFByTk4Zr
2025-03-19 15:10:49,538 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 15:10:49,538 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Paris', 'time': 'today'}}
2025-03-19 15:10:49,538 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 15:10:49,538 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 15:10:49,538 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 15:10:49,538 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:49,538 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:49,538 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:49,546 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 15:10:49,546 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:52,487 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 15:10:52,586 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 15:10:52,586 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 15:10:52,586 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:52,586 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:52,586 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:52,589 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 15:10:52,590 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:55,359 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 15:10:55,360 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 15:10:55,712 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 15:10:55,712 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'Paris', 'time': 'today'}
2025-03-19 15:10:55,716 - result - INFO - Request processing completed successfully
2025-03-19 15:10:55,716 - result - DEBUG - Final result: <Object of type dict - not JSON serializable>
2025-03-19 15:10:55,768 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 15:10:55,768 - process - INFO - End time: 2025-03-19 15:10:55
2025-03-19 15:10:55,768 - process - INFO - Processing LLM request: Can you tell me the current weather in London?
2025-03-19 15:10:55,768 - process - INFO - Start time: 2025-03-19 15:10:55
2025-03-19 15:10:55,769 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 15:10:55,769 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 15:10:55,788 - process - INFO - Sending request to adapter for processing
2025-03-19 15:10:55,788 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: Can you tell me the current weather in London?
2025-03-19 15:10:55,788 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: Can you tell me the current weather in London?
2025-03-19 15:10:55,788 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': 'Can you tell me the current weather in London?'}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 15:10:55,789 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 15:10:55,789 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 15:10:55,800 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x104817110>
2025-03-19 15:10:55,801 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10476ad50> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 15:10:55,817 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1046aad70>
2025-03-19 15:10:55,817 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 15:10:55,818 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 15:10:55,818 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 15:10:55,818 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 15:10:55,818 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 15:10:56,920 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 07:10:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-19T07:10:55Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-19T07:10:56Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-19T07:10:56Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-19T07:10:56Z'), (b'request-id', b'req_01DoTrGQAgQiMHYJcWNPEct6'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922b271efc1b8697-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 15:10:56,921 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 15:10:56,922 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 15:10:56,922 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 15:10:56,922 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 15:10:56,922 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 15:10:56,922 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 19 Mar 2025 07:10:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-19T07:10:55Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-19T07:10:56Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-19T07:10:56Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-19T07:10:56Z', 'request-id': 'req_01DoTrGQAgQiMHYJcWNPEct6', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922b271efc1b8697-KUL', 'content-encoding': 'gzip'})
2025-03-19 15:10:56,923 - anthropic._base_client - DEBUG - request_id: req_01DoTrGQAgQiMHYJcWNPEct6
2025-03-19 15:10:56,923 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 15:10:56,923 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'London'}}
2025-03-19 15:10:56,923 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 15:10:56,923 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 15:10:56,924 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 15:10:56,924 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:56,924 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:56,924 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:56,932 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 15:10:56,933 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:59,734 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 15:10:59,734 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 15:10:59,734 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 15:10:59,734 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:59,735 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:59,735 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:10:59,738 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 15:10:59,738 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:11:02,635 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 15:11:02,635 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 15:11:02,994 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 15:11:02,994 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'London'}
2025-03-19 15:11:02,997 - result - INFO - Request processing completed successfully
2025-03-19 15:11:02,998 - result - DEBUG - Final result: <Object of type dict - not JSON serializable>
2025-03-19 15:11:03,049 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 15:11:03,049 - process - INFO - End time: 2025-03-19 15:11:03
2025-03-19 15:11:03,049 - process - INFO - Processing LLM request: I'd like to know the weather conditions in Tokyo.
2025-03-19 15:11:03,049 - process - INFO - Start time: 2025-03-19 15:11:03
2025-03-19 15:11:03,050 - state_of_mika.registry - INFO - Loaded 4 servers from registry
2025-03-19 15:11:03,050 - state_of_mika.adapters.claude - DEBUG - Initializing Claude client with model: claude-3-sonnet-20240229
2025-03-19 15:11:03,068 - process - INFO - Sending request to adapter for processing
2025-03-19 15:11:03,068 - state_of_mika.adapters.claude - DEBUG - Sending request to Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 15:11:03,068 - state_of_mika.adapters.claude - DEBUG - Structuring request with Claude: I'd like to know the weather conditions in Tokyo.
2025-03-19 15:11:03,069 - anthropic._base_client - DEBUG - Request options: {'method': 'post', 'url': '/v1/messages', 'timeout': Timeout(connect=5.0, read=600, write=600, pool=600), 'files': None, 'json_data': {'max_tokens': 1000, 'messages': [{'role': 'user', 'content': "I'd like to know the weather conditions in Tokyo."}], 'model': 'claude-3-sonnet-20240229', 'system': '\n        You are an AI assistant that helps extract structured information from natural language requests.\n        Your task is to identify the capability needed, the tool to use, and the parameters required.\n        \n        When a user makes a request, respond ONLY with a JSON object containing:\n        1. capability: The primary capability needed (e.g., weather, search, time)\n        2. tool_name: The specific tool to use (e.g., get_weather, search_web)\n        3. parameters: A dictionary of parameters needed for the tool\n        \n        Known capabilities:\n        - weather: For weather information\n        - search: For web search\n        - time: For time/date information\n        - general: For general conversation\n        \n        Example:\n        For "What\'s the weather like in Paris?", respond with:\n        ```json\n        {\n          "capability": "weather",\n          "tool_name": "weather_lookup",\n          "parameters": {\n            "location": "Paris"\n          }\n        }\n        ```\n        '}}
2025-03-19 15:11:03,069 - anthropic._base_client - DEBUG - Sending HTTP Request: POST https://api.anthropic.com/v1/messages
2025-03-19 15:11:03,069 - httpcore.connection - DEBUG - connect_tcp.started host='api.anthropic.com' port=443 local_address=None timeout=5.0 socket_options=[(65535, 8, True), (6, 257, 60), (6, 258, 5)]
2025-03-19 15:11:03,083 - httpcore.connection - DEBUG - connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1046abbb0>
2025-03-19 15:11:03,084 - httpcore.connection - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10476b650> server_hostname='api.anthropic.com' timeout=5.0
2025-03-19 15:11:03,102 - httpcore.connection - DEBUG - start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1047bb890>
2025-03-19 15:11:03,102 - httpcore.http11 - DEBUG - send_request_headers.started request=<Request [b'POST']>
2025-03-19 15:11:03,102 - httpcore.http11 - DEBUG - send_request_headers.complete
2025-03-19 15:11:03,102 - httpcore.http11 - DEBUG - send_request_body.started request=<Request [b'POST']>
2025-03-19 15:11:03,103 - httpcore.http11 - DEBUG - send_request_body.complete
2025-03-19 15:11:03,103 - httpcore.http11 - DEBUG - receive_response_headers.started request=<Request [b'POST']>
2025-03-19 15:11:04,216 - httpcore.http11 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Wed, 19 Mar 2025 07:11:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'anthropic-ratelimit-requests-limit', b'4000'), (b'anthropic-ratelimit-requests-remaining', b'3999'), (b'anthropic-ratelimit-requests-reset', b'2025-03-19T07:11:03Z'), (b'anthropic-ratelimit-input-tokens-limit', b'400000'), (b'anthropic-ratelimit-input-tokens-remaining', b'400000'), (b'anthropic-ratelimit-input-tokens-reset', b'2025-03-19T07:11:03Z'), (b'anthropic-ratelimit-output-tokens-limit', b'80000'), (b'anthropic-ratelimit-output-tokens-remaining', b'80000'), (b'anthropic-ratelimit-output-tokens-reset', b'2025-03-19T07:11:04Z'), (b'anthropic-ratelimit-tokens-limit', b'480000'), (b'anthropic-ratelimit-tokens-remaining', b'480000'), (b'anthropic-ratelimit-tokens-reset', b'2025-03-19T07:11:03Z'), (b'request-id', b'req_01Uj7Q8tvX9fuXcp4ZZVLryZ'), (b'anthropic-organization-id', b'62a08e83-6d22-47b4-9c86-1f223dda4d1e'), (b'via', b'1.1 google'), (b'cf-cache-status', b'DYNAMIC'), (b'X-Robots-Tag', b'none'), (b'Server', b'cloudflare'), (b'CF-RAY', b'922b274c8efbd42d-KUL'), (b'Content-Encoding', b'gzip')])
2025-03-19 15:11:04,217 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages "HTTP/1.1 200 OK"
2025-03-19 15:11:04,217 - httpcore.http11 - DEBUG - receive_response_body.started request=<Request [b'POST']>
2025-03-19 15:11:04,217 - httpcore.http11 - DEBUG - receive_response_body.complete
2025-03-19 15:11:04,217 - httpcore.http11 - DEBUG - response_closed.started
2025-03-19 15:11:04,217 - httpcore.http11 - DEBUG - response_closed.complete
2025-03-19 15:11:04,218 - anthropic._base_client - DEBUG - HTTP Response: POST https://api.anthropic.com/v1/messages "200 OK" Headers({'date': 'Wed, 19 Mar 2025 07:11:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'anthropic-ratelimit-requests-limit': '4000', 'anthropic-ratelimit-requests-remaining': '3999', 'anthropic-ratelimit-requests-reset': '2025-03-19T07:11:03Z', 'anthropic-ratelimit-input-tokens-limit': '400000', 'anthropic-ratelimit-input-tokens-remaining': '400000', 'anthropic-ratelimit-input-tokens-reset': '2025-03-19T07:11:03Z', 'anthropic-ratelimit-output-tokens-limit': '80000', 'anthropic-ratelimit-output-tokens-remaining': '80000', 'anthropic-ratelimit-output-tokens-reset': '2025-03-19T07:11:04Z', 'anthropic-ratelimit-tokens-limit': '480000', 'anthropic-ratelimit-tokens-remaining': '480000', 'anthropic-ratelimit-tokens-reset': '2025-03-19T07:11:03Z', 'request-id': 'req_01Uj7Q8tvX9fuXcp4ZZVLryZ', 'anthropic-organization-id': '62a08e83-6d22-47b4-9c86-1f223dda4d1e', 'via': '1.1 google', 'cf-cache-status': 'DYNAMIC', 'x-robots-tag': 'none', 'server': 'cloudflare', 'cf-ray': '922b274c8efbd42d-KUL', 'content-encoding': 'gzip'})
2025-03-19 15:11:04,218 - anthropic._base_client - DEBUG - request_id: req_01Uj7Q8tvX9fuXcp4ZZVLryZ
2025-03-19 15:11:04,218 - state_of_mika.adapters.claude - DEBUG - Structured data from Claude: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 15:11:04,218 - state_of_mika.adapters.claude - DEBUG - Structured request: {'capability': 'weather', 'tool_name': 'get_weather', 'parameters': {'location': 'Tokyo'}}
2025-03-19 15:11:04,218 - state_of_mika.registry - DEBUG - Finding servers for capability: weather
2025-03-19 15:11:04,218 - state_of_mika.connector - INFO - Auto-installing server for capability: weather
2025-03-19 15:11:04,218 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 15:11:04,218 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:11:04,219 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:11:04,219 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:11:04,226 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 15:11:04,227 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:11:07,832 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 15:11:07,832 - state_of_mika.connector - INFO - Installing server: mcp_weather
2025-03-19 15:11:07,832 - state_of_mika.installer - INFO - Installing server: mcp_weather
2025-03-19 15:11:07,832 - state_of_mika.installer - INFO - Installing package with uv: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:11:07,832 - state_of_mika.installer - INFO - Converted repository URL to HTTPS format: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:11:07,832 - state_of_mika.installer - INFO - Installing from repository: git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:11:07,835 - state_of_mika.installer - ERROR - Error during package installation: [Errno 2] No such file or directory: 'uv'
2025-03-19 15:11:07,835 - state_of_mika.installer - WARNING - Falling back to pip for installing git+https://github.com/adhikasp/mcp-weather.git
2025-03-19 15:11:10,721 - state_of_mika.installer - INFO - Successfully installed git+https://github.com/adhikasp/mcp-weather.git with pip
2025-03-19 15:11:10,722 - state_of_mika.connector - INFO - Starting server: mcp_weather with command: python -c from fastmcp import FastMCP; from mcp_weather.weather import get_hourly_weather; server = FastMCP('mcp-weather'); server.add_tool(get_hourly_weather); server.run()
2025-03-19 15:11:11,278 - state_of_mika.connector - INFO - Connected to server: mcp_weather
2025-03-19 15:11:11,278 - state_of_mika.connector - DEBUG - Executing tool 'get_weather' with parameters: {'location': 'Tokyo'}
2025-03-19 15:11:11,281 - result - INFO - Request processing completed successfully
2025-03-19 15:11:11,282 - result - DEBUG - Final result: <Object of type dict - not JSON serializable>
2025-03-19 15:11:11,344 - state_of_mika.connector - INFO - Disconnected from all servers
2025-03-19 15:11:11,344 - process - INFO - End time: 2025-03-19 15:11:11
2025-03-19 15:11:11,379 - httpcore.connection - DEBUG - close.started
2025-03-19 15:11:11,379 - httpcore.connection - DEBUG - close.complete
2025-03-19 15:11:11,380 - httpcore.connection - DEBUG - close.started
2025-03-19 15:11:11,380 - httpcore.connection - DEBUG - close.complete
2025-03-19 15:11:11,380 - httpcore.connection - DEBUG - close.started
2025-03-19 15:11:11,380 - httpcore.connection - DEBUG - close.complete
